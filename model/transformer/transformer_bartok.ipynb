{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ngQefdQBMh-6",
    "outputId": "184389e4-6fd5-4d87-a4c4-08c9f9809c8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ MIDI: 32522ê°œ\n",
      "bartok í›„ë³´: 307ê°œ\n",
      "ë©”íƒ€ ì—†ìŒìœ¼ë¡œ ìŠ¤í‚µ: 0ê°œ, íŒŒì¼ëª… ê·œì¹™ ë¶ˆì¼ì¹˜ ìŠ¤í‚µ: 0ê°œ\n",
      "\n",
      "=== ë¶„í•  ê²°ê³¼ ===\n",
      "train: 184, validation: 61, test: 62\n",
      "ì €ì¥(JSON): /Users/soojeoung/Desktop/SNU_ML_DL/DL_Classic/aria-midi-v1-unique-ext/bartok_dataset_TF/flattened_metadata_with_split.json\n",
      "ì €ì¥(CSV):  /Users/soojeoung/Desktop/SNU_ML_DL/DL_Classic/aria-midi-v1-unique-ext/bartok_dataset_TF/flattened_metadata_with_split.csv\n",
      "ì¶œë ¥ í´ë”: /Users/soojeoung/Desktop/SNU_ML_DL/DL_Classic/aria-midi-v1-unique-ext/bartok_dataset_TF (train/ validation/ test)\n",
      "\n",
      "(ì°¸ê³ ) optional í•„ë“œ ê²°ì¸¡ ê°œìˆ˜ â†’ {'music_period': 38, 'difficulty': 230, 'genre': 2, 'opus': 76}\n"
     ]
    }
   ],
   "source": [
    "# === bartoknë§Œ 6:2:2ë¡œ ë¶„ë¦¬ + flattened_metadata_with_split.json ìƒì„± ===\n",
    "from pathlib import Path\n",
    "import os, json, re, math, shutil, glob, random\n",
    "\n",
    "# --- ê²½ë¡œ ì„¤ì • --- # ğŸ™‚ğŸ™‚ ê°œë³„ í™˜ê²½ë”°ë¼ ë³€ê²½ ğŸ™‚ğŸ™‚ \n",
    "PROJ = Path(\"/Users/soojeoung/Desktop/SNU_ML_DL/DL_Classic/aria-midi-v1-unique-ext\").resolve()  # ğŸ™‚ğŸ™‚ ì‘ê³¡ê°€ëª…ë”°ë¼ ë³€ê²½ ğŸ™‚ğŸ™‚ \n",
    "DATA_ROOT = PROJ / \"data\"  # data/aa ~ data/ko ë‚´ë¶€ í¬í•¨ ì¬ê·€ íƒìƒ‰\n",
    "META_JSON = PROJ / \"metadata.json\"\n",
    "\n",
    "SPLIT_ROOT = PROJ / \"bartok_dataset_TF\"\n",
    "SPLIT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰ ì‹œ, ì•„ë˜ë¥¼ Trueë¡œ ë‘ë©´ train/validation/test í´ë”ë¥¼ ë¹„ìš°ê³  ì‹œì‘í•©ë‹ˆë‹¤.\n",
    "CLEAN_SPLIT = True\n",
    "if CLEAN_SPLIT:\n",
    "    for sub in [\"train\", \"validation\", \"test\"]:\n",
    "        shutil.rmtree(SPLIT_ROOT / sub, ignore_errors=True)\n",
    "\n",
    "for sub in [\"train\", \"validation\", \"test\"]:\n",
    "    (SPLIT_ROOT / sub).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- ìœ í‹¸ ---\n",
    "def parse_filename(fp: Path):\n",
    "    m = re.match(r\"^(\\d{6})_(\\d+)\\.mid$\", fp.name)\n",
    "    if not m:\n",
    "        return None, None\n",
    "    id_num = int(m.group(1))\n",
    "    take = m.group(2)\n",
    "    return str(id_num), take  # metadata.jsonì˜ í‚¤ëŠ” '4' ê°™ì€ í˜•íƒœ\n",
    "\n",
    "def pick_audio_score(meta_entry: dict, take: str):\n",
    "    aud = meta_entry.get(\"audio_scores\", {})\n",
    "    if isinstance(aud, dict) and aud:\n",
    "        if take in aud:\n",
    "            return aud[take]\n",
    "        try:\n",
    "            return next(iter(aud.values()))\n",
    "        except StopIteration:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def is_bartok(composer_val):  # ğŸ™‚ğŸ™‚ ì‘ê³¡ê°€ëª…ë”°ë¼ ë³€ê²½ ğŸ™‚ğŸ™‚ \n",
    "    if composer_val is None:\n",
    "        return False\n",
    "    return \"bartok\" in str(composer_val).lower()  # ğŸ™‚ğŸ™‚ ì‘ê³¡ê°€ëª…ë”°ë¼ ë³€ê²½ ğŸ™‚ğŸ™‚ \n",
    "\n",
    "# --- ë©”íƒ€ ë¡œë“œ ---\n",
    "assert META_JSON.exists(), f\"metadata.json not found: {META_JSON}\"\n",
    "with open(META_JSON, \"r\") as f:\n",
    "    meta_raw = json.load(f)\n",
    "\n",
    "# --- ë°ì´í„° ìŠ¤ìº”: ëª¨ë“  .mid íŒŒì¼ ---\n",
    "all_mid_paths = [Path(p) for p in glob.glob(str(DATA_ROOT / \"**\" / \"*.mid\"), recursive=True)]\n",
    "\n",
    "# --- Bartokë§Œ í•„í„°ë§ ---  # ğŸ™‚ğŸ™‚ ì‘ê³¡ê°€ëª…ë”°ë¼ ë³€ê²½ ğŸ™‚ğŸ™‚ \n",
    "beet_items = []\n",
    "skipped_no_meta = 0\n",
    "skipped_bad_name = 0\n",
    "\n",
    "for fp in all_mid_paths:\n",
    "    id_str, take = parse_filename(fp)\n",
    "    if not id_str:\n",
    "        skipped_bad_name += 1\n",
    "        continue\n",
    "    entry = meta_raw.get(id_str)\n",
    "    if not entry:\n",
    "        skipped_no_meta += 1\n",
    "        continue\n",
    "\n",
    "    md = entry.get(\"metadata\", {})\n",
    "    if not is_bartok(md.get(\"composer\")):  # ğŸ™‚ğŸ™‚ ì‘ê³¡ê°€ëª…ë”°ë¼ ë³€ê²½ ğŸ™‚ğŸ™‚ \n",
    "        continue\n",
    "\n",
    "    beet_items.append((fp, id_str, take, entry))\n",
    "\n",
    "print(f\"ì´ MIDI: {len(all_mid_paths)}ê°œ\")\n",
    "print(f\"bartok í›„ë³´: {len(beet_items)}ê°œ\")  # ğŸ™‚ğŸ™‚ ì‘ê³¡ê°€ëª…ë”°ë¼ ë³€ê²½ ğŸ™‚ğŸ™‚ \n",
    "print(f\"ë©”íƒ€ ì—†ìŒìœ¼ë¡œ ìŠ¤í‚µ: {skipped_no_meta}ê°œ, íŒŒì¼ëª… ê·œì¹™ ë¶ˆì¼ì¹˜ ìŠ¤í‚µ: {skipped_bad_name}ê°œ\")\n",
    "\n",
    "# --- 6:2:2 ë¶„í•  ---\n",
    "SEED = 42\n",
    "random.Random(SEED).shuffle(beet_items)\n",
    "\n",
    "N = len(beet_items)\n",
    "n_train = math.floor(N * 0.6)\n",
    "n_val   = math.floor(N * 0.2)\n",
    "n_test  = N - n_train - n_val\n",
    "\n",
    "splits = (\n",
    "    [(\"train\", 0.6)] * n_train +\n",
    "    [(\"validation\", 0.2)] * n_val +\n",
    "    [(\"test\", 0.2)] * n_test\n",
    ")\n",
    "\n",
    "# --- ë³µì‚¬ & í”Œë˜íŠ¼ ë©”íƒ€ êµ¬ì„± ---\n",
    "flat_meta = {}  # key: íŒŒì¼ëª…, val: ë©”íƒ€ dict\n",
    "missing_optionals = {\"music_period\": 0, \"difficulty\": 0, \"genre\": 0, \"opus\": 0}\n",
    "\n",
    "for (item, (split_name, split_ratio)) in zip(beet_items, splits):\n",
    "    fp, id_str, take, entry = item\n",
    "    md = entry.get(\"metadata\", {})\n",
    "\n",
    "    basename = fp.name\n",
    "    audio_score = pick_audio_score(entry, take)\n",
    "\n",
    "    music_period = md.get(\"music_period\")\n",
    "    difficulty   = md.get(\"difficulty\")\n",
    "    genre        = md.get(\"genre\")\n",
    "    opus         = md.get(\"opus\")\n",
    "\n",
    "    if music_period is None: missing_optionals[\"music_period\"] += 1\n",
    "    if difficulty   is None: missing_optionals[\"difficulty\"]   += 1\n",
    "    if genre        is None: missing_optionals[\"genre\"]        += 1\n",
    "    if opus         is None: missing_optionals[\"opus\"]         += 1\n",
    "\n",
    "    dst = SPLIT_ROOT / split_name / basename\n",
    "    shutil.copy2(fp, dst)  # ê°™ì€ ì´ë¦„ì´ë©´ ë®ì–´ì”€\n",
    "\n",
    "    flat_meta[basename] = {\n",
    "        \"file_path\": basename,       # ex) 000004_0.mid\n",
    "        \"split\": split_name,         # train / validation / test\n",
    "        \"composer\": md.get(\"composer\"),\n",
    "        \"music_period\": music_period,\n",
    "        \"difficulty\": difficulty,\n",
    "        \"genre\": genre,\n",
    "        \"audio_score\": audio_score,\n",
    "        \"opus\": opus,\n",
    "        \"split_ratio\": split_ratio,\n",
    "    }\n",
    "\n",
    "# --- JSON/CSV ì €ì¥: ì“°ê¸° ê°€ëŠ¥í•œ SPLIT_ROOTì— ì €ì¥ ---\n",
    "OUT_JSON = SPLIT_ROOT / \"flattened_metadata_with_split.json\"\n",
    "OUT_CSV  = SPLIT_ROOT / \"flattened_metadata_with_split.csv\"\n",
    "\n",
    "with open(OUT_JSON, \"w\") as f:\n",
    "    json.dump(flat_meta, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# CSVë„ ê°™ì´ ì €ì¥(í¸ì˜)\n",
    "import pandas as pd\n",
    "pd.DataFrame.from_dict(flat_meta, orient=\"index\").reset_index(drop=True).to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(\"\\n=== ë¶„í•  ê²°ê³¼ ===\")\n",
    "print(f\"train: {n_train}, validation: {n_val}, test: {n_test}\")\n",
    "print(f\"ì €ì¥(JSON): {OUT_JSON}\")\n",
    "print(f\"ì €ì¥(CSV):  {OUT_CSV}\")\n",
    "print(f\"ì¶œë ¥ í´ë”: {SPLIT_ROOT} (train/ validation/ test)\")\n",
    "print(\"\\n(ì°¸ê³ ) optional í•„ë“œ ê²°ì¸¡ ê°œìˆ˜ â†’\", {k:v for k,v in missing_optionals.items() if v>0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.13.5 (v3.13.5:6cb20a219a8, Jun 11 2025, 12:23:45) [Clang 16.0.0 (clang-1600.0.26.6)]\n",
      "MPS available: True\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# [1] ëŸ°íƒ€ì„ ì²´í¬ (MPS + CPU)\n",
    "import torch, platform, sys, os, subprocess, textwrap, random, numpy as np\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"MPS available:\", torch.backends.mps.is_available())\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ì¬í˜„ì„±\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if device.type == \"mps\":\n",
    "    pass  # MPSëŠ” ë³„ë„ì˜ manual_seed_all ì—†ìŒ\n",
    "else:\n",
    "    torch.cuda.manual_seed_all(seed)  # í˜¹ì‹œ cuda fallback ë  ê²½ìš°ë§Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MD9KN_NNQJF7",
    "outputId": "2d7fcbd8-96b4-47d6-a388-8dbbd9019e0c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pretty_midi in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.2.10)\n",
      "Requirement already satisfied: mido in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.3.3)\n",
      "Requirement already satisfied: einops in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.8.1)\n",
      "Requirement already satisfied: pyfluidsynth in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.3.4)\n",
      "Requirement already satisfied: music21 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (9.7.1)\n",
      "Requirement already satisfied: numpy>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pretty_midi) (2.3.2)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pretty_midi) (1.17.0)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mido) (25.0)\n",
      "Requirement already satisfied: chardet in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from music21) (5.2.0)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from music21) (1.5.2)\n",
      "Requirement already satisfied: jsonpickle in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from music21) (4.1.1)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from music21) (3.10.6)\n",
      "Requirement already satisfied: more-itertools in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from music21) (10.8.0)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from music21) (2.32.4)\n",
      "Requirement already satisfied: webcolors>=1.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from music21) (24.11.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib->music21) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib->music21) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib->music21) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib->music21) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib->music21) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib->music21) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib->music21) (2.9.0.post0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->music21) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->music21) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->music21) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->music21) (2025.7.9)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install pretty_midi mido einops pyfluidsynth music21\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "l-xZ2WxIR2FZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pretty_midi/instrument.py:11: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json, random, math, os\n",
    "import numpy as np\n",
    "import pretty_midi as pm\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from einops import rearrange\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SPLIT_META_JSON = SPLIT_ROOT / \"flattened_metadata_with_split.json\"\n",
    "assert SPLIT_META_JSON.exists(), f\"split ë©”íƒ€ê°€ ì—†ìŠµë‹ˆë‹¤: {SPLIT_META_JSON}\"\n",
    "with open(SPLIT_META_JSON, \"r\") as f:\n",
    "    META = json.load(f)\n",
    "\n",
    "# í† í°/ìºì‹œ ê²½ë¡œ\n",
    "VOCAB_JSON   = SPLIT_ROOT / \"vocab.json\"\n",
    "TOK_CACHE_DIR= SPLIT_ROOT / \"tok_cache\"\n",
    "TOK_CACHE_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "We7OVO4KXkSg"
   },
   "source": [
    "### í† í°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "P9qKqnZKX4FR"
   },
   "outputs": [],
   "source": [
    "from music21 import converter\n",
    "\n",
    "# ìŒì´ë¦„ í‘œê¸°: MIDI pitch class â†’ 'C','C#',...,'B'\n",
    "PC2NAME = ['C','C#','D','Eb','E','F','F#','G','Ab','A','Bb','B']\n",
    "\n",
    "def detect_key_with_music21(midi_path: Path):\n",
    "    \"\"\"music21ë¡œ ì „ì²´ ê³¡ì˜ ì¡°ì„±(ì¥/ë‹¨ì¡°)ì„ ì¶”ì •í•´ KEY í† í°ì„ ëŒë ¤ì¤ë‹ˆë‹¤.\"\"\"\n",
    "    try:\n",
    "        s = converter.parse(str(midi_path))\n",
    "        k = s.analyze('key')\n",
    "        tonic_name = k.tonic.name  # e.g., 'C', 'E-'\n",
    "        # music21ì˜ E- ê°™ì€ í‘œê¸°ë¥¼ ì¢€ ë” ì¼ë°˜ì ìœ¼ë¡œ ë³€í™˜\n",
    "        tonic_name = tonic_name.replace('-','b')  # E- â†’ Eb\n",
    "        mode = 'maj' if k.mode.lower().startswith('maj') else 'min'\n",
    "        return f\"{tonic_name}{'maj' if mode=='maj' else 'min'}\"  # ì˜ˆ: Cmaj, Amin, Ebmaj\n",
    "    except Exception:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xmX3QrI1X7GO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ê¸°ë³¸ í™”ìŒ í…œí”Œë¦¿(ë£¨íŠ¸=0 ê¸°ì¤€ì˜ pitch-class ì§‘í•©)\n",
    "CHORD_TEMPLATES = {\n",
    "    'maj'       : {0,4,7},\n",
    "    'min'       : {0,3,7},\n",
    "    'dim'       : {0,3,6},\n",
    "    'aug'       : {0,4,8},\n",
    "    'dom7'      : {0,4,7,10},\n",
    "    'maj7'      : {0,4,7,11},\n",
    "    'min7'      : {0,3,7,10},\n",
    "    'halfdim7'  : {0,3,6,10},\n",
    "    'dim7'      : {0,3,6,9},\n",
    "}\n",
    "\n",
    "def best_chord_label(pitches):\n",
    "    \"\"\"\n",
    "    pitches: ë¦¬ìŠ¤íŠ¸/ì…‹ (MIDI pitchë“¤) â†’ ìµœì ì˜ (root, quality) ë°˜í™˜. ì—†ìœ¼ë©´ None.\n",
    "    í‰ê°€ ê¸°ì¤€: í…œí”Œë¦¿ ì»¤ë²„ ë¹„ìœ¨ + ì‚¬ì´ì¦ˆ ê·¼ì‚¬ì„±.\n",
    "    \"\"\"\n",
    "    if not pitches:\n",
    "        return None\n",
    "    pcs = sorted({p % 12 for p in pitches})\n",
    "    if not pcs:\n",
    "        return None\n",
    "\n",
    "    best = None\n",
    "    best_score = -1e9\n",
    "    for root in range(12):\n",
    "        shifted = {(pc - root) % 12 for pc in pcs}\n",
    "        for qual, templ in CHORD_TEMPLATES.items():\n",
    "            inter = len(shifted & templ)\n",
    "            # í…œí”Œë¦¿ í¬í•¨ ë¹„ìœ¨ & ì—¬ë¶„ íŒ¨ë„í‹°\n",
    "            cover = inter / max(1, len(templ))\n",
    "            extra_penalty = -0.15 * max(0, len(shifted - templ))\n",
    "            score = cover + extra_penalty\n",
    "            if score > best_score and inter >= 2:  # ìµœì†Œ 2ìŒ ì´ìƒ ë§ì•„ì•¼ í™”ìŒìœ¼ë¡œ ì¸ì •\n",
    "                best_score = score\n",
    "                best = (root, qual)\n",
    "    if best is None:\n",
    "        return None\n",
    "    root_name = PC2NAME[best[0]]\n",
    "    return f\"{root_name}:{best[1]}\"  # ì˜ˆ: C:maj, A:min, G:dom7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "eepKPSdCX_W3"
   },
   "outputs": [],
   "source": [
    "TS_DIV = 16\n",
    "MIN_VEL, MAX_VEL = 20, 100\n",
    "MIN_DUR, MAX_DUR = 1, 16\n",
    "\n",
    "def quantize_time(pm_obj, ts_div=TS_DIV):\n",
    "    ts = pm_obj.time_signature_changes or [pm.TimeSignature(4,4,0.0)]\n",
    "    tempo_times, tempi = pm_obj.get_tempo_changes()\n",
    "    tempo = float(tempi[0]) if len(tempi) else 120.0\n",
    "    num, den = ts[0].numerator, ts[0].denominator\n",
    "    beat_len = 60.0 / tempo\n",
    "    bar_sec = (4/den) * num * beat_len\n",
    "\n",
    "    notes=[]\n",
    "    for inst in pm_obj.instruments:\n",
    "        for n in inst.notes:\n",
    "            bar = int(n.start // bar_sec)\n",
    "            pos = int(((n.start - bar*bar_sec)/bar_sec)*ts_div); pos = max(0,min(ts_div-1,pos))\n",
    "            dur = int(((n.end - n.start)/bar_sec)*ts_div); dur = max(MIN_DUR, min(MAX_DUR, dur))\n",
    "            vel = int(np.clip(n.velocity, MIN_VEL, MAX_VEL))\n",
    "            notes.append((bar,pos,n.pitch,dur,vel))\n",
    "    notes.sort(key=lambda x:(x[0],x[1],x[2]))\n",
    "    return notes, (num,den), int(tempo), bar_sec\n",
    "\n",
    "def encode_remi_harmony(midi_path: Path, add_chords=True, chord_every='pos'):\n",
    "    \"\"\"\n",
    "    chord_every: 'bar' â†’ ë°” ë‹¹ 1ê°œ, 'beat' â†’ ë°•ì ë‹¨ìœ„(ê·¼ì‚¬), 'pos' â†’ POS ë‹¨ìœ„(onset ê¸°ì¤€).\n",
    "    \"\"\"\n",
    "    pm_obj = pm.PrettyMIDI(str(midi_path))\n",
    "    notes,(num,den),tempo,bar_sec = quantize_time(pm_obj)\n",
    "\n",
    "    # 0) KEY(ì¥/ë‹¨ì¡°) í† í°\n",
    "    key_token = detect_key_with_music21(midi_path)  # ì˜ˆ: 'Cmaj', 'Amin', None\n",
    "\n",
    "    toks = []\n",
    "    toks.append(f\"TSig_{num}_{den}\")\n",
    "    toks.append(f\"TEMPO_{tempo}\")\n",
    "    if key_token:\n",
    "        toks.append(f\"KEY_{key_token}\")  # ì˜ˆ: KEY_Cmaj\n",
    "\n",
    "    # 1) í™”ìŒ ë¼ë²¨ë§ì„ ìœ„í•œ ê·¸ë£¹í•‘\n",
    "    #    - chord_every == 'bar' : ê°™ì€ bar ë‚´ ëª¨ë“  ë…¸íŠ¸ onsets\n",
    "    #    - chord_every == 'pos' : (bar,pos) ë‹¨ìœ„ ë…¸íŠ¸ onsets\n",
    "    #    - chord_every == 'beat': bar ë‚´ beat ê²½ê³„ ê·¼ì‚¬ (num ê°œ)\n",
    "    from collections import defaultdict\n",
    "    onset_map = defaultdict(list)  # key: (bar, pos or beatIndex) â†’ pitches\n",
    "\n",
    "    if chord_every == 'bar':\n",
    "        for (bar,pos,pitch,dur,vel) in notes:\n",
    "            onset_map[(bar, -1)].append(pitch)\n",
    "\n",
    "    elif chord_every == 'beat':\n",
    "        # ë°•ì ê²½ê³„(ëŒ€ëµ)ë¡œ posâ†’beat index ë§¤í•‘ (TS_DIVë¥¼ numë¡œ ë‚˜ëˆ”)\n",
    "        step_per_beat = max(1, TS_DIV // num)\n",
    "        for (bar,pos,pitch,dur,vel) in notes:\n",
    "            beat_idx = pos // step_per_beat\n",
    "            onset_map[(bar, beat_idx)].append(pitch)\n",
    "\n",
    "    else:  # 'pos'\n",
    "        for (bar,pos,pitch,dur,vel) in notes:\n",
    "            onset_map[(bar, pos)].append(pitch)\n",
    "\n",
    "    # 2) í† í° ì‹œí€€ìŠ¤ ìƒì„±\n",
    "    cur_bar = -1\n",
    "    last_chord = None\n",
    "    for (bar,pos,pitch,dur,vel) in notes:\n",
    "        # BAR í† í°\n",
    "        while cur_bar < bar:\n",
    "            toks.append(\"BAR\")\n",
    "            cur_bar += 1\n",
    "            last_chord = None  # ìƒˆ ë§ˆë””ì—ì„œ í™”ìŒ ìƒˆë¡œ íŒë‹¨\n",
    "\n",
    "        # POS í† í°\n",
    "        toks.append(f\"POS_{pos}\")\n",
    "\n",
    "        # 2-a) í™”ìŒ í† í°(ì„ íƒ)\n",
    "        if add_chords:\n",
    "            key = (bar, -1) if chord_every=='bar' else ((bar, pos) if chord_every=='pos' else (bar, pos // max(1, TS_DIV // num)))\n",
    "            chord_label = best_chord_label(onset_map.get(key, []))\n",
    "            if chord_label and chord_label != last_chord:\n",
    "                toks.append(f\"CHORD_{chord_label}\")   # ì˜ˆ: CHORD_C:maj, CHORD_A:min\n",
    "                last_chord = chord_label\n",
    "\n",
    "        # 2-b) ìŒí‘œ ì´ë²¤íŠ¸\n",
    "        toks += [f\"NOTE_ON_{pitch}\", f\"DUR_{dur}\", f\"VEL_{vel}\"]\n",
    "\n",
    "    return toks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "oUhK5vZCYD4N"
   },
   "outputs": [],
   "source": [
    "def cond_tokens(meta, midi_path_for_key: Path = None):\n",
    "    t = [\"COMPOSER_Beethoven\"]\n",
    "    if meta.get(\"music_period\"): t.append(f\"PERIOD_{meta['music_period']}\")\n",
    "    if meta.get(\"genre\"):        t.append(f\"GENRE_{meta['genre']}\")\n",
    "    if meta.get(\"difficulty\"):   t.append(f\"DIFF_{meta['difficulty']}\")\n",
    "    if meta.get(\"opus\"):         t.append(f\"OPUS_{str(meta['opus']).replace(' ','_')}\")\n",
    "    q=meta.get(\"audio_score\")\n",
    "    if q is not None:\n",
    "        t.append(f\"QUALITY_{'High' if q>=0.8 else 'Med' if q>=0.5 else 'Low'}\")\n",
    "    # KEY (ë©”íƒ€/íŒŒì¼ ê¸°ë°˜)\n",
    "    if midi_path_for_key is not None:\n",
    "        k = detect_key_with_music21(midi_path_for_key)\n",
    "        if k:\n",
    "            t.append(f\"KEY_{k}\")  # KEY_Cmaj / KEY_Amin ...\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_g9y46PUSQ4U",
    "outputId": "4a8c110e-9e41-4351-ace7-53894848360d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB_SIZE: 330\n"
     ]
    }
   ],
   "source": [
    "def build_vocab():\n",
    "    if VOCAB_JSON.exists(): return json.load(open(VOCAB_JSON))\n",
    "    vocab={\"[PAD]\":0,\"[BOS]\":1,\"[EOS]\":2,\"[UNK]\":3}\n",
    "    idx=len(vocab)\n",
    "    for fname,meta in META.items():\n",
    "        p = SPLIT_ROOT/meta[\"split\"]/meta[\"file_path\"]\n",
    "        if not p.exists(): continue\n",
    "        # vocab ë¹Œë“œ ë‹¨ê³„\n",
    "        toks = [\"[BOS]\"] + cond_tokens(meta, midi_path_for_key=p) + encode_remi_harmony(p, add_chords=True, chord_every='pos')+ [\"[EOS]\"]\n",
    "\n",
    "        json.dump(toks, open(TOK_CACHE_DIR/(fname+\".json\"),\"w\"))\n",
    "        for t in toks:\n",
    "            if t not in vocab:\n",
    "                vocab[t]=idx; idx+=1\n",
    "    json.dump(vocab, open(VOCAB_JSON,\"w\"))\n",
    "    return vocab\n",
    "\n",
    "VOCAB = build_vocab()\n",
    "IVOCAB= {i:t for t,i in VOCAB.items()}\n",
    "VOCAB_SIZE=len(VOCAB)\n",
    "print(\"VOCAB_SIZE:\", VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "wNqiWgG6SUWq"
   },
   "outputs": [],
   "source": [
    "SEQ_LEN=512\n",
    "\n",
    "def toks_to_ids(toks): return [VOCAB.get(t, VOCAB[\"[UNK]\"]) for t in toks]\n",
    "\n",
    "class BeethovenMIDIDataset(Dataset):\n",
    "    def __init__(self, split):\n",
    "        self.items=[(k,v) for k,v in META.items() if v[\"split\"]==split]\n",
    "        random.Random(42).shuffle(self.items)\n",
    "    def __len__(self): return len(self.items)\n",
    "    def __getitem__(self,i):\n",
    "        fname,meta = self.items[i]\n",
    "        cache=TOK_CACHE_DIR/(fname+\".json\")\n",
    "        if cache.exists(): toks=json.load(open(cache))\n",
    "        else:\n",
    "            p=SPLIT_ROOT/meta[\"split\"]/meta[\"file_path\"]\n",
    "            toks=[\"[BOS]\"]+cond_tokens(meta)+encode_remi_lite(p)+[\"[EOS]\"]\n",
    "        ids=toks_to_ids(toks)\n",
    "        if len(ids)>=SEQ_LEN:\n",
    "            st=random.randint(0, len(ids)-SEQ_LEN)\n",
    "            seq=ids[st:st+SEQ_LEN]\n",
    "        else:\n",
    "            seq=ids+[VOCAB[\"[PAD]\"]] * (SEQ_LEN-len(ids))\n",
    "        x=torch.tensor(seq[:-1],dtype=torch.long)\n",
    "        y=torch.tensor(seq[1:], dtype=torch.long)\n",
    "        return x,y\n",
    "\n",
    "train_dl=DataLoader(BeethovenMIDIDataset(\"train\"), batch_size=16, shuffle=True, drop_last=True)\n",
    "val_dl  =DataLoader(BeethovenMIDIDataset(\"validation\"), batch_size=16, shuffle=False, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "O_BC3kuQSf6q"
   },
   "outputs": [],
   "source": [
    "import math, torch, torch.nn as nn\n",
    "from einops import rearrange\n",
    "\n",
    "# ===== 1) RoPE (Rotary Positional Embedding) =====\n",
    "def apply_rope(q,k):\n",
    "    B,H,T,D = q.shape\n",
    "    pos = torch.arange(T, device=q.device).float()\n",
    "    inv = 1.0/(10000**(torch.arange(0,D,2,device=q.device).float()/D))\n",
    "    ang = torch.einsum('t,d->td', pos, inv)\n",
    "    sin,cos = ang.sin()[None,None], ang.cos()[None,None]\n",
    "    def rot(x):\n",
    "        x1,x2=x[...,::2],x[...,1::2]\n",
    "        return torch.stack([x1*cos - x2*sin, x1*sin + x2*cos], dim=-1).flatten(-2)\n",
    "    return rot(q), rot(k)\n",
    "\n",
    "# ===== 2) Self-Attention =====\n",
    "class CausalSelfAttn(nn.Module):\n",
    "    def __init__(self,d_model=512,n_head=8,p=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model% n_head==0\n",
    "        self.nh=n_head; self.dk=d_model//n_head\n",
    "        self.qkv=nn.Linear(d_model, d_model*3)\n",
    "        self.proj=nn.Linear(d_model, d_model)\n",
    "        self.drop=nn.Dropout(p)\n",
    "    def forward(self,x):\n",
    "        B,T,C=x.shape\n",
    "        q,k,v = self.qkv(x).chunk(3,-1)\n",
    "        q=rearrange(q,'b t (h d)->b h t d',h=self.nh)\n",
    "        k=rearrange(k,'b t (h d)->b h t d',h=self.nh)\n",
    "        v=rearrange(v,'b t (h d)->b h t d',h=self.nh)\n",
    "        q,k=apply_rope(q,k)\n",
    "        att=(q@k.transpose(-1,-2))/math.sqrt(self.dk)\n",
    "        mask=torch.triu(torch.ones(T,T,device=x.device),1).bool()\n",
    "        att=att.masked_fill(mask,float('-inf')).softmax(-1)\n",
    "        att=self.drop(att)\n",
    "        y=att@v\n",
    "        y=rearrange(y,'b h t d->b t (h d)')\n",
    "        return self.proj(y)\n",
    "\n",
    "# ===== 3) Transformer Block =====\n",
    "class Block(nn.Module):\n",
    "    def __init__(self,d=512,h=8,p=0.1,mlp=4):\n",
    "        super().__init__()\n",
    "        self.ln1=nn.LayerNorm(d); self.att=CausalSelfAttn(d,h,p)\n",
    "        self.ln2=nn.LayerNorm(d)\n",
    "        self.mlp=nn.Sequential(\n",
    "            nn.Linear(d,d*mlp), nn.GELU(), nn.Dropout(p), nn.Linear(d*mlp,d)\n",
    "        )\n",
    "        self.drop=nn.Dropout(p)\n",
    "    def forward(self,x):\n",
    "        x=x+self.drop(self.att(self.ln1(x)))\n",
    "        x=x+self.drop(self.mlp(self.ln2(x)))\n",
    "        return x\n",
    "\n",
    "# ===== 4) MiniGPT Model =====\n",
    "class MiniGPT(nn.Module):\n",
    "    def __init__(self,vocab_size, d=512, L=8, H=8, p=0.1):\n",
    "        super().__init__()\n",
    "        self.emb=nn.Embedding(vocab_size, d)\n",
    "        self.pos=nn.Parameter(torch.zeros(1, SEQ_LEN-1, d))  # ì ˆëŒ€ ìœ„ì¹˜ (RoPEì™€ ë³‘ìš©)\n",
    "        self.blocks=nn.ModuleList([Block(d,H,p) for _ in range(L)])\n",
    "        self.ln=nn.LayerNorm(d)\n",
    "        self.head=nn.Linear(d, vocab_size, bias=False)\n",
    "    def forward(self,idx):\n",
    "        x=self.emb(idx) + self.pos[:, :idx.size(1), :]\n",
    "        for b in self.blocks: x=b(x)\n",
    "        return self.head(self.ln(x))\n",
    "\n",
    "# ===== 5) ëª¨ë¸ ì´ˆê¸°í™” =====\n",
    "model = MiniGPT(VOCAB_SIZE).to(DEVICE)\n",
    "opt   = torch.optim.AdamW(model.parameters(), lr=3e-4, betas=(0.9,0.95), weight_decay=0.1)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=VOCAB[\"[PAD]\"], label_smoothing=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "HWRsoGe7apIg"
   },
   "outputs": [],
   "source": [
    "import pretty_midi as pm\n",
    "from pathlib import Path\n",
    "\n",
    "def detokenize_to_midi(tokens, out_path, ts_div=16, default_time_sig=(4,4), default_tempo=120,\n",
    "                       program=0, safe_pitch=(36,96)):\n",
    "    \"\"\"\n",
    "    REMIë¥˜ í† í° ì‹œí€€ìŠ¤ë¥¼ MIDIë¡œ ë³µì›í•©ë‹ˆë‹¤.\n",
    "    - tokens ì˜ˆì‹œ: [\"TSig_4_4\",\"TEMPO_112\",\"BAR\",\"POS_0\",\"NOTE_ON_60\",\"DUR_4\",\"VEL_80\", ...]\n",
    "    - KEY_*, CHORD_* í† í°ì€ MIDIì— ì§ì ‘ ë°˜ì˜í•˜ì§€ ì•Šê³  ê±´ë„ˆëœë‹ˆë‹¤.\n",
    "    - ts_divëŠ” í† í°í™” ë•Œ ì“´ TS_DIVì™€ ë™ì¼í•´ì•¼ í•©ë‹ˆë‹¤(ê¸°ë³¸ 16).\n",
    "    \"\"\"\n",
    "    out_path = Path(out_path) if isinstance(out_path, str) else out_path\n",
    "\n",
    "    # ì´ˆê¸° ë©”íƒ€\n",
    "    num, den = default_time_sig\n",
    "    tempo = default_tempo\n",
    "    beat_len = 60.0 / tempo\n",
    "    bar_sec = (4/den) * num * beat_len\n",
    "\n",
    "    cur_bar = -1\n",
    "    pos = 0\n",
    "\n",
    "    pm_out = pm.PrettyMIDI()\n",
    "    inst = pm.Instrument(program=program)\n",
    "    SAFE_LOW, SAFE_HIGH = safe_pitch\n",
    "\n",
    "    i = 0\n",
    "    N = len(tokens)\n",
    "    while i < N:\n",
    "        t = tokens[i]\n",
    "\n",
    "        # ë©”íƒ€ í† í°\n",
    "        if t.startswith(\"TSig_\"):\n",
    "            try:\n",
    "                _, a, b = t.split(\"_\")\n",
    "                num, den = int(a), int(b)\n",
    "                beat_len = 60.0 / tempo\n",
    "                bar_sec = (4/den) * num * beat_len\n",
    "            except Exception:\n",
    "                pass\n",
    "            i += 1; continue\n",
    "\n",
    "        if t.startswith(\"TEMPO_\"):\n",
    "            try:\n",
    "                tempo = int(t.split(\"_\")[1])\n",
    "                beat_len = 60.0 / tempo\n",
    "                bar_sec = (4/den) * num * beat_len\n",
    "            except Exception:\n",
    "                pass\n",
    "            i += 1; continue\n",
    "\n",
    "        if t.startswith(\"KEY_\") or t.startswith(\"CHORD_\"):\n",
    "            i += 1; continue  # ì¡°ì„±/í™”ìŒ í† í°ì€ MIDIì— ì§ì ‘ ë°˜ì˜í•˜ì§€ ì•ŠìŒ\n",
    "\n",
    "        # êµ¬ì¡° í† í°\n",
    "        if t == \"BAR\":\n",
    "            cur_bar += 1\n",
    "            pos = 0\n",
    "            i += 1; continue\n",
    "\n",
    "        if t.startswith(\"POS_\"):\n",
    "            try:\n",
    "                pos = int(t.split(\"_\")[1])\n",
    "                pos = max(0, min(ts_div-1, pos))\n",
    "            except Exception:\n",
    "                pos = max(0, min(ts_div-1, pos))\n",
    "            i += 1; continue\n",
    "\n",
    "        # ìŒí‘œ ì´ë²¤íŠ¸\n",
    "        if t.startswith(\"NOTE_ON_\"):\n",
    "            # NOTE_ON_p\n",
    "            try:\n",
    "                pitch = int(t.split(\"_\")[2])\n",
    "            except Exception:\n",
    "                i += 1; continue\n",
    "            i += 1\n",
    "\n",
    "            # DUR_d (ê¸°ë³¸ 4), VEL_v (ê¸°ë³¸ 80)\n",
    "            dur = 4\n",
    "            vel = 80\n",
    "            if i < N and tokens[i].startswith(\"DUR_\"):\n",
    "                try: dur = int(tokens[i].split(\"_\")[1])\n",
    "                except Exception: pass\n",
    "                i += 1\n",
    "            if i < N and (tokens[i].startswith(\"VEL_\") or tokens[i].startswith(\"VELOCITY_\")):\n",
    "                try: vel = int(tokens[i].split(\"_\")[1])\n",
    "                except Exception: pass\n",
    "                i += 1\n",
    "\n",
    "            pitch = max(SAFE_LOW, min(SAFE_HIGH, pitch))\n",
    "            start = (cur_bar * bar_sec) + (pos / ts_div) * bar_sec\n",
    "            end   = start + (dur / ts_div) * bar_sec\n",
    "            if end <= start:\n",
    "                end = start + (1 / ts_div) * bar_sec  # ìµœì†Œ 1í‹±\n",
    "\n",
    "            inst.notes.append(pm.Note(velocity=vel, pitch=pitch, start=start, end=end))\n",
    "            continue\n",
    "\n",
    "        # ì•Œ ìˆ˜ ì—†ëŠ” í† í°ì€ ë¬´ì‹œ\n",
    "        i += 1\n",
    "\n",
    "    pm_out.instruments.append(inst)\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    pm_out.write(str(out_path))\n",
    "    return out_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KbeE1fjcZg71",
    "outputId": "fa941b97-36ea-4d2b-9c38-cc2adda5ffb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/50] train 6.0087 | val 6.0071 | best 6.0071 | lr 0.000001\n",
      "[2/50] train 6.0034 | val 6.0076 | best 6.0071 | lr 0.000003\n",
      "[3/50] train 5.9803 | val 6.0146 | best 6.0071 | lr 0.000004\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 92\u001b[39m\n\u001b[32m     89\u001b[39m ckpt_path = SPLIT_ROOT / \u001b[33m\"\u001b[39m\u001b[33mminigpt_best.pt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, EPOCHS+\u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     tr = \u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m     \u001b[38;5;66;03m# âœ… EMA ê°€ì¤‘ì¹˜ë¡œ ê²€ì¦\u001b[39;00m\n\u001b[32m     95\u001b[39m     ema.store(model); ema.copy_to(model)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 75\u001b[39m, in \u001b[36mrun_epoch\u001b[39m\u001b[34m(dl, train, grad_clip)\u001b[39m\n\u001b[32m     73\u001b[39m             loss = loss / ACC\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m train:\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m step % ACC == \u001b[32m0\u001b[39m:\n\u001b[32m     77\u001b[39m         torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/_tensor.py:647\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    639\u001b[39m         Tensor.backward,\n\u001b[32m    640\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    645\u001b[39m         inputs=inputs,\n\u001b[32m    646\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/autograd/graph.py:829\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    827\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ====== 0) ì¤€ë¹„ ======\n",
    "import math, torch\n",
    "import torch.nn as nn\n",
    "from torch.amp import GradScaler, autocast  # âœ… AMP ìµœì‹  API\n",
    "\n",
    "VOCAB_SIZE = len(VOCAB)\n",
    "\n",
    "# ====== EMA ìœ í‹¸ ======\n",
    "class EMA:\n",
    "    def __init__(self, model, decay=0.999):\n",
    "        self.decay = decay\n",
    "        self.shadow = {k: p.detach().clone() for k, p in model.state_dict().items()}\n",
    "        self.backup = None\n",
    "    @torch.no_grad()\n",
    "    def update(self, model):\n",
    "        for k, p in model.state_dict().items():\n",
    "            self.shadow[k].mul_(self.decay).add_(p.detach(), alpha=1 - self.decay)\n",
    "    def store(self, model):\n",
    "        self.backup = {k: p.detach().clone() for k, p in model.state_dict().items()}\n",
    "    def copy_to(self, model):\n",
    "        model.load_state_dict(self.shadow, strict=False)\n",
    "    def restore(self, model):\n",
    "        if self.backup is not None:\n",
    "            model.load_state_dict(self.backup, strict=False)\n",
    "            self.backup = None\n",
    "\n",
    "ema = EMA(model, decay=0.999)\n",
    "\n",
    "# ====== 1) ì†ì‹¤, ì˜µí‹°ë§ˆì´ì €, ìŠ¤ì¼€ì¤„ëŸ¬, ì²´í¬í¬ì¸íŠ¸ ======\n",
    "criterion = nn.CrossEntropyLoss(\n",
    "    ignore_index=VOCAB[\"[PAD]\"],\n",
    "    label_smoothing=0.05,    # âœ… 0.05ë¡œ ë¯¸ì„¸ì¡°ì •\n",
    ")\n",
    "\n",
    "opt = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=3e-4,\n",
    "    betas=(0.9, 0.95),\n",
    "    weight_decay=0.03,       # âœ… ê³¼ê·œì œ ì™„í™”\n",
    ")\n",
    "\n",
    "EPOCHS = 50\n",
    "warmup_steps = 1000\n",
    "total_steps  = max(1, len(train_dl) * EPOCHS)\n",
    "\n",
    "def lr_lambda(step):\n",
    "    if step < warmup_steps:\n",
    "        return step / max(1, warmup_steps)\n",
    "    progress = (step - warmup_steps) / max(1, total_steps - warmup_steps)\n",
    "    progress = min(1.0, max(0.0, progress))\n",
    "    return 0.5 * (1 + math.cos(math.pi * progress))\n",
    "\n",
    "sched = torch.optim.lr_scheduler.LambdaLR(opt, lr_lambda)\n",
    "\n",
    "use_cuda_amp = (DEVICE.type == 'cuda')\n",
    "scaler = GradScaler('cuda' if use_cuda_amp else 'cpu')\n",
    "\n",
    "# ====== 2) í•™ìŠµ/ê²€ì¦ í•¨ìˆ˜ (ACC=2) ======\n",
    "ACC = 2  # âœ… ìœ íš¨ ë°°ì¹˜ x2\n",
    "\n",
    "def run_epoch(dl, train=True, grad_clip=1.0):\n",
    "    model.train(train)\n",
    "    total, n = 0.0, 0\n",
    "    if train:\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "    for step, (x, y) in enumerate(dl, 1):\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        with torch.set_grad_enabled(train):\n",
    "            with autocast('cuda' if use_cuda_amp else 'cpu'):\n",
    "                logits = model(x)\n",
    "                loss = criterion(logits.view(-1, VOCAB_SIZE), y.view(-1))\n",
    "                if train and ACC > 1:\n",
    "                    loss = loss / ACC\n",
    "        if train:\n",
    "            scaler.scale(loss).backward()\n",
    "            if step % ACC == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "                scaler.step(opt)\n",
    "                scaler.update()\n",
    "                sched.step()\n",
    "                opt.zero_grad(set_to_none=True)\n",
    "                ema.update(model)  # âœ… step ë’¤ EMA ì—…ë°ì´íŠ¸\n",
    "        total += loss.item() * (ACC if train and ACC > 1 else 1.0)\n",
    "        n += 1\n",
    "    return total / max(1, n)\n",
    "\n",
    "# ====== 3) í•™ìŠµ ë£¨í”„ + EMA ê²€ì¦ + ë² ìŠ¤íŠ¸ ì €ì¥ ======\n",
    "best_val = float('inf')\n",
    "ckpt_path = SPLIT_ROOT / \"minigpt_best.pt\"\n",
    "\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    tr = run_epoch(train_dl, train=True)\n",
    "\n",
    "    # âœ… EMA ê°€ì¤‘ì¹˜ë¡œ ê²€ì¦\n",
    "    ema.store(model); ema.copy_to(model)\n",
    "    vl = run_epoch(val_dl, train=False)\n",
    "    ema.restore(model)\n",
    "\n",
    "    if vl < best_val:\n",
    "        best_val = vl\n",
    "        torch.save(model.state_dict(), str(ckpt_path))\n",
    "    print(f\"[{ep}/{EPOCHS}] train {tr:.4f} | val {vl:.4f} | best {best_val:.4f} | lr {sched.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "# ====== 4) ë² ìŠ¤íŠ¸ ê°€ì¤‘ì¹˜ ë¡œë“œ(ì•ˆì „) ======\n",
    "_ = model.load_state_dict(torch.load(str(ckpt_path), map_location=DEVICE))\n",
    "\n",
    "# ====== 5) ê¸°ë³¸ generate (ìœˆë„ìš° ìë™ ì ìš©: pos ì„ë² ë”© ê¸¸ì´ì— ë§ì¶° crop) ======\n",
    "@torch.no_grad()\n",
    "def generate(prompt_tokens, max_new=700, top_k=50, top_p=0.95, temp=0.9):\n",
    "    model.eval()\n",
    "    unk_id = VOCAB.get(\"[UNK]\", None)\n",
    "    if unk_id is None:\n",
    "        raise ValueError(\"Vocab must contain [UNK] token.\")\n",
    "    pos_len = getattr(getattr(model, 'pos', None), 'shape', [1, 100000, 0])[1]\n",
    "    ids = torch.tensor([[VOCAB.get(t, unk_id) for t in prompt_tokens]], device=DEVICE)\n",
    "    for _ in range(max_new):\n",
    "        ids_win = ids[:, -pos_len:] if ids.size(1) > pos_len else ids\n",
    "        logits = model(ids_win)[:, -1, :] / max(temp, 1e-6)\n",
    "        probs = torch.softmax(logits, dim=-1)[0]\n",
    "        if top_k > 0:\n",
    "            topk = torch.topk(probs, top_k)\n",
    "            mask = torch.ones_like(probs, dtype=torch.bool); mask[topk.indices] = False\n",
    "            probs = probs.masked_fill(mask, 0)\n",
    "        if top_p < 1.0:\n",
    "            sprob, sidx = torch.sort(probs, descending=True)\n",
    "            keep = torch.cumsum(sprob, dim=-1) <= top_p\n",
    "            keep[0] = True\n",
    "            mask = torch.ones_like(probs, dtype=torch.bool); mask[sidx[keep]] = False\n",
    "            probs = probs.masked_fill(mask, 0)\n",
    "        probs = probs / probs.sum()\n",
    "        nxt = torch.multinomial(probs, 1)\n",
    "        ids = torch.cat([ids, nxt.view(1,1)], dim=1)\n",
    "        if nxt.item() == VOCAB[\"[EOS]\"]:\n",
    "            break\n",
    "    return [IVOCAB[i.item()] for i in ids[0]]\n",
    "\n",
    "# ====== 6) ê¸¸ê²Œ ìƒì„±: ì²­í¬ ìŠ¤í‹°ì¹­(ëª¨ë¸ ìˆ˜ì • ì—†ìŒ) ======\n",
    "def stitch_generate(prompt_tokens, total_new=512, chunk_new=700, context=480,\n",
    "                    top_k=50, top_p=0.95, temp=0.9, stop_on_eos=False):\n",
    "    all_tokens = list(prompt_tokens)\n",
    "    made = 0\n",
    "    while made < total_new:\n",
    "        this_new = min(chunk_new, total_new - made)\n",
    "        cur_prompt = all_tokens[-context:] if len(all_tokens) > context else all_tokens\n",
    "        chunk = generate(cur_prompt, max_new=this_new, top_k=top_k, top_p=top_p, temp=temp)\n",
    "        new_part = chunk[len(cur_prompt):] if len(chunk) > len(cur_prompt) else []\n",
    "        if stop_on_eos and (\"[EOS]\" in new_part):\n",
    "            eos_idx = new_part.index(\"[EOS]\"); all_tokens += new_part[:eos_idx]; break\n",
    "        all_tokens += new_part\n",
    "        made += len(new_part)\n",
    "        if len(new_part) == 0:\n",
    "            break\n",
    "    return all_tokens\n",
    "\n",
    "# ====== 7) í”„ë¡¬í”„íŠ¸ ì„¤ì • & ê¸¸ê²Œ ìƒì„± & ì €ì¥ ======\n",
    "prompt = [\"[BOS]\",\"COMPOSER_Beethoven\",\"PERIOD_Middle\",\"GENRE_Sonata\",\"KEY_Cmin\",\n",
    "          \"TSig_4_4\",\"TEMPO_112\",\"BAR\",\"POS_0\",\"BAR\",\"POS_0\",\"BAR\",\"POS_0\"]\n",
    "\n",
    "tokens_long = stitch_generate(\n",
    "    prompt_tokens=prompt,\n",
    "    total_new=512,     # ê¸¸ì´ëŠ” ìœ ì§€\n",
    "    chunk_new=700,\n",
    "    context=480,\n",
    "    top_k=50, top_p=0.95, temp=0.9,\n",
    "    stop_on_eos=False\n",
    ")\n",
    "\n",
    "out_mid_long = SPLIT_ROOT / \"sample_beethoven_long_v1.mid\"\n",
    "detokenize_to_midi(tokens_long, out_mid_long)\n",
    "print(\"Saved â†’\", out_mid_long)\n",
    "\n",
    "# ====== 8) (ì„ íƒ) í¼í”Œë ‰ì„œí‹°ë¡œ ìƒíƒœ í™•ì¸ ======\n",
    "print(\"Best val loss:\", best_val, \"| approx PPL:\", math.exp(best_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ejD7vA-HgOS0",
    "outputId": "f7fc6886-cb90-4aa3-8ec1-e7b46d0e3158"
   },
   "outputs": [],
   "source": [
    "# ====== 0) ì¤€ë¹„ ======\n",
    "import math, torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.amp import GradScaler, autocast  # AMP ìµœì‹  API\n",
    "from torch.optim.swa_utils import AveragedModel  # SWA\n",
    "\n",
    "VOCAB_SIZE = len(VOCAB)\n",
    "PAD_ID = VOCAB[\"[PAD]\"]\n",
    "UNK_ID = VOCAB.get(\"[UNK]\", None)\n",
    "assert UNK_ID is not None, \"[UNK] í† í°ì´ vocabì— í•„ìš”í•©ë‹ˆë‹¤.\"\n",
    "\n",
    "# ----- (ì„ íƒ) í† í° ë“œë¡­ì•„ì›ƒ: VEL_/DUR_ ì†ŒëŸ‰ ë§ˆìŠ¤í‚¹ -----\n",
    "DROP_PROB = 0.05  # 3~7% ê¶Œì¥\n",
    "VEL_IDS = {tid for tok, tid in VOCAB.items() if tok.startswith(\"VEL_\")}\n",
    "DUR_IDS = {tid for tok, tid in VOCAB.items() if tok.startswith(\"DUR_\")}\n",
    "DROP_SET = VEL_IDS | DUR_IDS\n",
    "\n",
    "def token_dropout(batch_ids, drop_prob=DROP_PROB):\n",
    "    # batch_ids: LongTensor [B, T]\n",
    "    if drop_prob <= 0 or not DROP_SET:\n",
    "        return batch_ids\n",
    "    dev = batch_ids.device\n",
    "    drop_ids = torch.tensor(list(DROP_SET), device=dev)\n",
    "    mask = torch.rand_like(batch_ids.float()) < drop_prob\n",
    "    sel = mask & torch.isin(batch_ids, drop_ids)\n",
    "    return batch_ids.masked_fill(sel, PAD_ID)\n",
    "\n",
    "# ====== EMA ìœ í‹¸ ======\n",
    "class EMA:\n",
    "    def __init__(self, model, decay=0.999):\n",
    "        self.decay = decay\n",
    "        self.shadow = {k: p.detach().clone() for k, p in model.state_dict().items()}\n",
    "        self.backup = None\n",
    "    @torch.no_grad()\n",
    "    def update(self, model):\n",
    "        for k, p in model.state_dict().items():\n",
    "            self.shadow[k].mul_(self.decay).add_(p.detach(), alpha=1 - self.decay)\n",
    "    def store(self, model):\n",
    "        self.backup = {k: p.detach().clone() for k, p in model.state_dict().items()}\n",
    "    def copy_to(self, model):\n",
    "        model.load_state_dict(self.shadow, strict=False)\n",
    "    def restore(self, model):\n",
    "        if self.backup is not None:\n",
    "            model.load_state_dict(self.backup, strict=False)\n",
    "            self.backup = None\n",
    "\n",
    "ema = EMA(model, decay=0.999)\n",
    "\n",
    "# ====== 1) ì†ì‹¤, ì˜µí‹°ë§ˆì´ì €, ìŠ¤ì¼€ì¤„ëŸ¬ ======\n",
    "criterion = nn.CrossEntropyLoss(\n",
    "    ignore_index=PAD_ID,\n",
    "    label_smoothing=0.05,\n",
    ")\n",
    "\n",
    "opt = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=3e-4,\n",
    "    betas=(0.9, 0.95),\n",
    "    weight_decay=0.03,\n",
    ")\n",
    "\n",
    "EPOCHS = 50\n",
    "warmup_steps = 1000\n",
    "total_steps  = max(1, len(train_dl) * EPOCHS)\n",
    "\n",
    "def lr_lambda(step):\n",
    "    if step < warmup_steps:\n",
    "        return step / max(1, warmup_steps)\n",
    "    progress = (step - warmup_steps) / max(1, total_steps - warmup_steps)\n",
    "    progress = min(1.0, max(0.0, progress))\n",
    "    return 0.5 * (1 + math.cos(math.pi * progress))\n",
    "\n",
    "sched = torch.optim.lr_scheduler.LambdaLR(opt, lr_lambda)\n",
    "\n",
    "use_cuda_amp = (DEVICE.type == 'cuda')\n",
    "scaler = GradScaler('cuda' if use_cuda_amp else 'cpu')\n",
    "\n",
    "# ====== R-Drop ì„¤ì • ======\n",
    "kl_factor = 1.0  # 0.5~2.0 ì‚¬ì´ íƒìƒ‰ ì¶”ì²œ\n",
    "\n",
    "def sym_kl(logits1, logits2, mask=None):\n",
    "    # logits: [B, T, V]; mask: [B, T] (1=valid, 0=ignore)\n",
    "    p = F.log_softmax(logits1, dim=-1)\n",
    "    q = F.log_softmax(logits2, dim=-1)\n",
    "    p_exp = p.exp(); q_exp = q.exp()\n",
    "    kl = (p_exp * (p - q)).sum(-1) + (q_exp * (q - p)).sum(-1)  # [B, T]\n",
    "    if mask is not None:\n",
    "        kl = kl * mask\n",
    "        denom = mask.sum().clamp_min(1)\n",
    "        return kl.sum() / denom\n",
    "    return kl.mean()\n",
    "\n",
    "# ====== 2) í•™ìŠµ/ê²€ì¦ í•¨ìˆ˜ (ACC=2 + R-Drop + TokenDropout) ======\n",
    "ACC = 2  # ìœ íš¨ ë°°ì¹˜ x2\n",
    "\n",
    "def run_epoch(dl, train=True, grad_clip=1.0):\n",
    "    model.train(train)\n",
    "    total, n = 0.0, 0\n",
    "    if train:\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "    for step, (x, y) in enumerate(dl, 1):\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        if train:\n",
    "            x = token_dropout(x)  # ì…ë ¥ ë…¸ì´ì¦ˆ(ì†ŒëŸ‰)ë¡œ ê°•ê±´ì„± â†‘\n",
    "\n",
    "        with torch.set_grad_enabled(train):\n",
    "            if train:\n",
    "                with autocast('cuda' if use_cuda_amp else 'cpu'):\n",
    "                    # R-Drop: dropout í™œì„± ìƒíƒœì—ì„œ ë‘ ë²ˆ forward\n",
    "                    logits1 = model(x)\n",
    "                    logits2 = model(x)\n",
    "                    ce1 = criterion(logits1.view(-1, VOCAB_SIZE), y.view(-1))\n",
    "                    ce2 = criterion(logits2.view(-1, VOCAB_SIZE), y.view(-1))\n",
    "                    y_mask = (y != PAD_ID).float()\n",
    "                    kl = sym_kl(logits1, logits2, y_mask)\n",
    "                    loss = 0.5*(ce1+ce2) + kl_factor*kl\n",
    "                    if ACC > 1:\n",
    "                        loss = loss / ACC\n",
    "            else:\n",
    "                with autocast('cuda' if use_cuda_amp else 'cpu'):\n",
    "                    logits = model(x)\n",
    "                    loss = criterion(logits.view(-1, VOCAB_SIZE), y.view(-1))\n",
    "\n",
    "        if train:\n",
    "            scaler.scale(loss).backward()\n",
    "            if step % ACC == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "                scaler.step(opt)\n",
    "                scaler.update()\n",
    "                sched.step()\n",
    "                opt.zero_grad(set_to_none=True)\n",
    "                ema.update(model)\n",
    "\n",
    "        total += loss.item() * (ACC if train and ACC > 1 else 1.0)\n",
    "        n += 1\n",
    "    return total / max(1, n)\n",
    "\n",
    "# ====== 3) SWA(ë§‰íŒ í‰ê· ) + EMA ê²€ì¦ + ë² ìŠ¤íŠ¸ ì €ì¥ ======\n",
    "best_val = float('inf')\n",
    "ckpt_path = SPLIT_ROOT / \"minigpt_best.pt\"\n",
    "\n",
    "swa_start_epoch = max(5, EPOCHS - 5)  # ë§ˆì§€ë§‰ 5ì—í­ í‰ê· \n",
    "swa_model = AveragedModel(model)\n",
    "\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    tr = run_epoch(train_dl, train=True)\n",
    "\n",
    "    # SWA í‰ê·  ëˆ„ì (ì—í­ ë‹¨ìœ„)\n",
    "    if ep >= swa_start_epoch:\n",
    "        swa_model.update_parameters(model)\n",
    "\n",
    "    # EMA ê°€ì¤‘ì¹˜ë¡œ ê²€ì¦\n",
    "    ema.store(model); ema.copy_to(model)\n",
    "    vl = run_epoch(val_dl, train=False)\n",
    "    ema.restore(model)\n",
    "\n",
    "    if vl < best_val:\n",
    "        best_val = vl\n",
    "        torch.save(model.state_dict(), str(ckpt_path))\n",
    "    print(f\"[{ep}/{EPOCHS}] train {tr:.4f} | val {vl:.4f} | best {best_val:.4f} | lr {sched.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "# ====== 4) ë² ìŠ¤íŠ¸ ê°€ì¤‘ì¹˜ ë¡œë“œ(ì•ˆì „) + (ì„ íƒ) SWA í‰ê°€/ì €ì¥ ======\n",
    "_ = model.load_state_dict(torch.load(str(ckpt_path), map_location=DEVICE))\n",
    "\n",
    "# SWA ê°€ì¤‘ì¹˜ë¡œë„ í•œ ë²ˆ í‰ê°€í•´ë³´ê³ , ë” ì¢‹ìœ¼ë©´ SWAë¡œ ì €ì¥\n",
    "try:\n",
    "    ema.store(model)\n",
    "    model.load_state_dict(swa_model.state_dict(), strict=False)\n",
    "    vl_swa = run_epoch(val_dl, train=False)\n",
    "    print(f\"[SWA] val {vl_swa:.4f}\")\n",
    "    if vl_swa < best_val:\n",
    "        torch.save(model.state_dict(), str(SPLIT_ROOT / \"minigpt_best_swa.pt\"))\n",
    "        print(\"SWA checkpoint saved (better than EMA-best).\")\n",
    "    ema.restore(model)\n",
    "except Exception as e:\n",
    "    print(\"SWA eval skipped:\", e)\n",
    "\n",
    "# ====== 5) ê¸°ë³¸ generate (ìœˆë„ìš° ìë™ crop + ê²½ëŸ‰ ë°˜ë³µ í˜ë„í‹°/ì˜¨ë„ ìŠ¤ì¼€ì¤„) ======\n",
    "def temp_schedule(step, t_max, t0=0.9, t1=0.8):\n",
    "    a = min(1.0, max(0.0, step / max(1, t_max)))\n",
    "    return t0*(1-a) + t1*a\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate(prompt_tokens, max_new=700, top_k=50, top_p=0.95, temp=0.9, rep_penalty=1.05):\n",
    "    model.eval()\n",
    "    pos_len = getattr(getattr(model, 'pos', None), 'shape', [1, 100000, 0])[1]\n",
    "    ids = torch.tensor([[VOCAB.get(t, UNK_ID) for t in prompt_tokens]], device=DEVICE)\n",
    "    for step in range(max_new):\n",
    "        ids_win = ids[:, -pos_len:] if ids.size(1) > pos_len else ids\n",
    "        cur_temp = temp_schedule(step, max_new, t0=temp, t1=max(0.6, temp-0.1))\n",
    "        logits = model(ids_win)[:, -1, :] / max(cur_temp, 1e-6)\n",
    "        probs = torch.softmax(logits, dim=-1)[0]\n",
    "\n",
    "        # ë¯¸ì„¸ ë°˜ë³µ í˜ë„í‹°(ì§ì „ í† í°ë§Œ ì•½í•˜ê²Œ)\n",
    "        last_tok = ids[0, -1]\n",
    "        probs[last_tok] = probs[last_tok] / rep_penalty\n",
    "\n",
    "        if top_k > 0:\n",
    "            topk = torch.topk(probs, top_k)\n",
    "            mask = torch.ones_like(probs, dtype=torch.bool); mask[topk.indices] = False\n",
    "            probs = probs.masked_fill(mask, 0)\n",
    "        if top_p < 1.0:\n",
    "            sprob, sidx = torch.sort(probs, descending=True)\n",
    "            keep = torch.cumsum(sprob, dim=-1) <= top_p\n",
    "            keep[0] = True\n",
    "            mask = torch.ones_like(probs, dtype=torch.bool); mask[sidx[keep]] = False\n",
    "            probs = probs.masked_fill(mask, 0)\n",
    "        probs = probs / probs.sum()\n",
    "\n",
    "        nxt = torch.multinomial(probs, 1)\n",
    "        ids = torch.cat([ids, nxt.view(1,1)], dim=1)\n",
    "        if nxt.item() == VOCAB[\"[EOS]\"]:\n",
    "            break\n",
    "    return [IVOCAB[i.item()] for i in ids[0]]\n",
    "\n",
    "# ====== 6) ê¸¸ê²Œ ìƒì„±: ì²­í¬ ìŠ¤í‹°ì¹­(ëª¨ë¸ ìˆ˜ì • ì—†ìŒ) ======\n",
    "def stitch_generate(prompt_tokens, total_new=512, chunk_new=700, context=480,\n",
    "                    top_k=50, top_p=0.95, temp=0.9, stop_on_eos=False):\n",
    "    all_tokens = list(prompt_tokens); made = 0\n",
    "    while made < total_new:\n",
    "        this_new = min(chunk_new, total_new - made)\n",
    "        cur_prompt = all_tokens[-context:] if len(all_tokens) > context else all_tokens\n",
    "        chunk = generate(cur_prompt, max_new=this_new, top_k=top_k, top_p=top_p, temp=temp)\n",
    "        new_part = chunk[len(cur_prompt):] if len(chunk) > len(cur_prompt) else []\n",
    "        if stop_on_eos and (\"[EOS]\" in new_part):\n",
    "            eos_idx = new_part.index(\"[EOS]\"); all_tokens += new_part[:eos_idx]; break\n",
    "        all_tokens += new_part; made += len(new_part)\n",
    "        if len(new_part) == 0: break\n",
    "    return all_tokens\n",
    "\n",
    "# ====== 7) í”„ë¡¬í”„íŠ¸ ì„¤ì • & ê¸¸ê²Œ ìƒì„± & ì €ì¥ ======\n",
    "prompt = [\"[BOS]\",\"COMPOSER_Beethoven\",\"PERIOD_Middle\",\"GENRE_Sonata\",\"KEY_Cmin\",\n",
    "          \"TSig_4_4\",\"TEMPO_112\",\"BAR\",\"POS_0\",\"BAR\",\"POS_0\",\"BAR\",\"POS_0\"]\n",
    "\n",
    "tokens_long = stitch_generate(\n",
    "    prompt_tokens=prompt,\n",
    "    total_new=512,   # ê¸¸ì´ëŠ” ìœ ì§€\n",
    "    chunk_new=700,\n",
    "    context=480,\n",
    "    top_k=50, top_p=0.95, temp=0.9,\n",
    "    stop_on_eos=False\n",
    ")\n",
    "\n",
    "out_mid_long = SPLIT_ROOT / \"sample_beethoven_long_v2.mid\"\n",
    "detokenize_to_midi(tokens_long, out_mid_long)\n",
    "print(\"Saved â†’\", out_mid_long)\n",
    "\n",
    "# ====== 8) (ì„ íƒ) í¼í”Œë ‰ì„œí‹°ë¡œ ìƒíƒœ í™•ì¸ ======\n",
    "print(\"Best val loss (EMA):\", best_val, \"| approx PPL:\", math.exp(best_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5pJYE9E3T3rL",
    "outputId": "710a129f-4d72-4f18-d1fe-86213c3f2cf5"
   },
   "outputs": [],
   "source": [
    "!pip install pyFluidSynth==1.3.4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yVm3SK1wkHaa"
   },
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7nApGl8Ek05d"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
