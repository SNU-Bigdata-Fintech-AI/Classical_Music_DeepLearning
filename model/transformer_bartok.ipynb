{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ngQefdQBMh-6",
    "outputId": "184389e4-6fd5-4d87-a4c4-08c9f9809c8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 MIDI: 32522개\n",
      "bartok 후보: 307개\n",
      "메타 없음으로 스킵: 0개, 파일명 규칙 불일치 스킵: 0개\n",
      "\n",
      "=== 분할 결과 ===\n",
      "train: 184, validation: 61, test: 62\n",
      "저장(JSON): /Users/soojeoung/Desktop/SNU_ML_DL/DL_Classic/aria-midi-v1-unique-ext/bartok_dataset_TF/flattened_metadata_with_split.json\n",
      "저장(CSV):  /Users/soojeoung/Desktop/SNU_ML_DL/DL_Classic/aria-midi-v1-unique-ext/bartok_dataset_TF/flattened_metadata_with_split.csv\n",
      "출력 폴더: /Users/soojeoung/Desktop/SNU_ML_DL/DL_Classic/aria-midi-v1-unique-ext/bartok_dataset_TF (train/ validation/ test)\n",
      "\n",
      "(참고) optional 필드 결측 개수 → {'music_period': 38, 'difficulty': 230, 'genre': 2, 'opus': 76}\n"
     ]
    }
   ],
   "source": [
    "# === bartokn만 6:2:2로 분리 + flattened_metadata_with_split.json 생성 ===\n",
    "from pathlib import Path\n",
    "import os, json, re, math, shutil, glob, random\n",
    "\n",
    "# --- 경로 설정 --- # 🙂🙂 개별 환경따라 변경 🙂🙂 \n",
    "PROJ = Path(\"/Users/soojeoung/Desktop/SNU_ML_DL/DL_Classic/aria-midi-v1-unique-ext\").resolve()  # 🙂🙂 작곡가명따라 변경 🙂🙂 \n",
    "DATA_ROOT = PROJ / \"data\"  # data/aa ~ data/ko 내부 포함 재귀 탐색\n",
    "META_JSON = PROJ / \"metadata.json\"\n",
    "\n",
    "SPLIT_ROOT = PROJ / \"bartok_dataset_TF\"\n",
    "SPLIT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 여러 번 실행 시, 아래를 True로 두면 train/validation/test 폴더를 비우고 시작합니다.\n",
    "CLEAN_SPLIT = True\n",
    "if CLEAN_SPLIT:\n",
    "    for sub in [\"train\", \"validation\", \"test\"]:\n",
    "        shutil.rmtree(SPLIT_ROOT / sub, ignore_errors=True)\n",
    "\n",
    "for sub in [\"train\", \"validation\", \"test\"]:\n",
    "    (SPLIT_ROOT / sub).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- 유틸 ---\n",
    "def parse_filename(fp: Path):\n",
    "    m = re.match(r\"^(\\d{6})_(\\d+)\\.mid$\", fp.name)\n",
    "    if not m:\n",
    "        return None, None\n",
    "    id_num = int(m.group(1))\n",
    "    take = m.group(2)\n",
    "    return str(id_num), take  # metadata.json의 키는 '4' 같은 형태\n",
    "\n",
    "def pick_audio_score(meta_entry: dict, take: str):\n",
    "    aud = meta_entry.get(\"audio_scores\", {})\n",
    "    if isinstance(aud, dict) and aud:\n",
    "        if take in aud:\n",
    "            return aud[take]\n",
    "        try:\n",
    "            return next(iter(aud.values()))\n",
    "        except StopIteration:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def is_bartok(composer_val):  # 🙂🙂 작곡가명따라 변경 🙂🙂 \n",
    "    if composer_val is None:\n",
    "        return False\n",
    "    return \"bartok\" in str(composer_val).lower()  # 🙂🙂 작곡가명따라 변경 🙂🙂 \n",
    "\n",
    "# --- 메타 로드 ---\n",
    "assert META_JSON.exists(), f\"metadata.json not found: {META_JSON}\"\n",
    "with open(META_JSON, \"r\") as f:\n",
    "    meta_raw = json.load(f)\n",
    "\n",
    "# --- 데이터 스캔: 모든 .mid 파일 ---\n",
    "all_mid_paths = [Path(p) for p in glob.glob(str(DATA_ROOT / \"**\" / \"*.mid\"), recursive=True)]\n",
    "\n",
    "# --- Bartok만 필터링 ---  # 🙂🙂 작곡가명따라 변경 🙂🙂 \n",
    "beet_items = []\n",
    "skipped_no_meta = 0\n",
    "skipped_bad_name = 0\n",
    "\n",
    "for fp in all_mid_paths:\n",
    "    id_str, take = parse_filename(fp)\n",
    "    if not id_str:\n",
    "        skipped_bad_name += 1\n",
    "        continue\n",
    "    entry = meta_raw.get(id_str)\n",
    "    if not entry:\n",
    "        skipped_no_meta += 1\n",
    "        continue\n",
    "\n",
    "    md = entry.get(\"metadata\", {})\n",
    "    if not is_bartok(md.get(\"composer\")):  # 🙂🙂 작곡가명따라 변경 🙂🙂 \n",
    "        continue\n",
    "\n",
    "    beet_items.append((fp, id_str, take, entry))\n",
    "\n",
    "print(f\"총 MIDI: {len(all_mid_paths)}개\")\n",
    "print(f\"bartok 후보: {len(beet_items)}개\")  # 🙂🙂 작곡가명따라 변경 🙂🙂 \n",
    "print(f\"메타 없음으로 스킵: {skipped_no_meta}개, 파일명 규칙 불일치 스킵: {skipped_bad_name}개\")\n",
    "\n",
    "# --- 6:2:2 분할 ---\n",
    "SEED = 42\n",
    "random.Random(SEED).shuffle(beet_items)\n",
    "\n",
    "N = len(beet_items)\n",
    "n_train = math.floor(N * 0.6)\n",
    "n_val   = math.floor(N * 0.2)\n",
    "n_test  = N - n_train - n_val\n",
    "\n",
    "splits = (\n",
    "    [(\"train\", 0.6)] * n_train +\n",
    "    [(\"validation\", 0.2)] * n_val +\n",
    "    [(\"test\", 0.2)] * n_test\n",
    ")\n",
    "\n",
    "# --- 복사 & 플래튼 메타 구성 ---\n",
    "flat_meta = {}  # key: 파일명, val: 메타 dict\n",
    "missing_optionals = {\"music_period\": 0, \"difficulty\": 0, \"genre\": 0, \"opus\": 0}\n",
    "\n",
    "for (item, (split_name, split_ratio)) in zip(beet_items, splits):\n",
    "    fp, id_str, take, entry = item\n",
    "    md = entry.get(\"metadata\", {})\n",
    "\n",
    "    basename = fp.name\n",
    "    audio_score = pick_audio_score(entry, take)\n",
    "\n",
    "    music_period = md.get(\"music_period\")\n",
    "    difficulty   = md.get(\"difficulty\")\n",
    "    genre        = md.get(\"genre\")\n",
    "    opus         = md.get(\"opus\")\n",
    "\n",
    "    if music_period is None: missing_optionals[\"music_period\"] += 1\n",
    "    if difficulty   is None: missing_optionals[\"difficulty\"]   += 1\n",
    "    if genre        is None: missing_optionals[\"genre\"]        += 1\n",
    "    if opus         is None: missing_optionals[\"opus\"]         += 1\n",
    "\n",
    "    dst = SPLIT_ROOT / split_name / basename\n",
    "    shutil.copy2(fp, dst)  # 같은 이름이면 덮어씀\n",
    "\n",
    "    flat_meta[basename] = {\n",
    "        \"file_path\": basename,       # ex) 000004_0.mid\n",
    "        \"split\": split_name,         # train / validation / test\n",
    "        \"composer\": md.get(\"composer\"),\n",
    "        \"music_period\": music_period,\n",
    "        \"difficulty\": difficulty,\n",
    "        \"genre\": genre,\n",
    "        \"audio_score\": audio_score,\n",
    "        \"opus\": opus,\n",
    "        \"split_ratio\": split_ratio,\n",
    "    }\n",
    "\n",
    "# --- JSON/CSV 저장: 쓰기 가능한 SPLIT_ROOT에 저장 ---\n",
    "OUT_JSON = SPLIT_ROOT / \"flattened_metadata_with_split.json\"\n",
    "OUT_CSV  = SPLIT_ROOT / \"flattened_metadata_with_split.csv\"\n",
    "\n",
    "with open(OUT_JSON, \"w\") as f:\n",
    "    json.dump(flat_meta, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# CSV도 같이 저장(편의)\n",
    "import pandas as pd\n",
    "pd.DataFrame.from_dict(flat_meta, orient=\"index\").reset_index(drop=True).to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(\"\\n=== 분할 결과 ===\")\n",
    "print(f\"train: {n_train}, validation: {n_val}, test: {n_test}\")\n",
    "print(f\"저장(JSON): {OUT_JSON}\")\n",
    "print(f\"저장(CSV):  {OUT_CSV}\")\n",
    "print(f\"출력 폴더: {SPLIT_ROOT} (train/ validation/ test)\")\n",
    "print(\"\\n(참고) optional 필드 결측 개수 →\", {k:v for k,v in missing_optionals.items() if v>0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.13.5 (v3.13.5:6cb20a219a8, Jun 11 2025, 12:23:45) [Clang 16.0.0 (clang-1600.0.26.6)]\n",
      "MPS available: True\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# [1] 런타임 체크 (MPS + CPU)\n",
    "import torch, platform, sys, os, subprocess, textwrap, random, numpy as np\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"MPS available:\", torch.backends.mps.is_available())\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# 재현성\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if device.type == \"mps\":\n",
    "    pass  # MPS는 별도의 manual_seed_all 없음\n",
    "else:\n",
    "    torch.cuda.manual_seed_all(seed)  # 혹시 cuda fallback 될 경우만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MD9KN_NNQJF7",
    "outputId": "2d7fcbd8-96b4-47d6-a388-8dbbd9019e0c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pretty_midi in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.2.10)\n",
      "Requirement already satisfied: mido in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.3.3)\n",
      "Requirement already satisfied: einops in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.8.1)\n",
      "Requirement already satisfied: pyfluidsynth in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.3.4)\n",
      "Requirement already satisfied: music21 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (9.7.1)\n",
      "Requirement already satisfied: numpy>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pretty_midi) (2.3.2)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pretty_midi) (1.17.0)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from mido) (25.0)\n",
      "Requirement already satisfied: chardet in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from music21) (5.2.0)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from music21) (1.5.2)\n",
      "Requirement already satisfied: jsonpickle in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from music21) (4.1.1)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from music21) (3.10.6)\n",
      "Requirement already satisfied: more-itertools in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from music21) (10.8.0)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from music21) (2.32.4)\n",
      "Requirement already satisfied: webcolors>=1.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from music21) (24.11.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib->music21) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib->music21) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib->music21) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib->music21) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib->music21) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib->music21) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib->music21) (2.9.0.post0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->music21) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->music21) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->music21) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->music21) (2025.7.9)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install pretty_midi mido einops pyfluidsynth music21\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "l-xZ2WxIR2FZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pretty_midi/instrument.py:11: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json, random, math, os\n",
    "import numpy as np\n",
    "import pretty_midi as pm\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from einops import rearrange\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SPLIT_META_JSON = SPLIT_ROOT / \"flattened_metadata_with_split.json\"\n",
    "assert SPLIT_META_JSON.exists(), f\"split 메타가 없습니다: {SPLIT_META_JSON}\"\n",
    "with open(SPLIT_META_JSON, \"r\") as f:\n",
    "    META = json.load(f)\n",
    "\n",
    "# 토큰/캐시 경로\n",
    "VOCAB_JSON   = SPLIT_ROOT / \"vocab.json\"\n",
    "TOK_CACHE_DIR= SPLIT_ROOT / \"tok_cache\"\n",
    "TOK_CACHE_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "We7OVO4KXkSg"
   },
   "source": [
    "### 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "P9qKqnZKX4FR"
   },
   "outputs": [],
   "source": [
    "from music21 import converter\n",
    "\n",
    "# 음이름 표기: MIDI pitch class → 'C','C#',...,'B'\n",
    "PC2NAME = ['C','C#','D','Eb','E','F','F#','G','Ab','A','Bb','B']\n",
    "\n",
    "def detect_key_with_music21(midi_path: Path):\n",
    "    \"\"\"music21로 전체 곡의 조성(장/단조)을 추정해 KEY 토큰을 돌려줍니다.\"\"\"\n",
    "    try:\n",
    "        s = converter.parse(str(midi_path))\n",
    "        k = s.analyze('key')\n",
    "        tonic_name = k.tonic.name  # e.g., 'C', 'E-'\n",
    "        # music21의 E- 같은 표기를 좀 더 일반적으로 변환\n",
    "        tonic_name = tonic_name.replace('-','b')  # E- → Eb\n",
    "        mode = 'maj' if k.mode.lower().startswith('maj') else 'min'\n",
    "        return f\"{tonic_name}{'maj' if mode=='maj' else 'min'}\"  # 예: Cmaj, Amin, Ebmaj\n",
    "    except Exception:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xmX3QrI1X7GO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 기본 화음 템플릿(루트=0 기준의 pitch-class 집합)\n",
    "CHORD_TEMPLATES = {\n",
    "    'maj'       : {0,4,7},\n",
    "    'min'       : {0,3,7},\n",
    "    'dim'       : {0,3,6},\n",
    "    'aug'       : {0,4,8},\n",
    "    'dom7'      : {0,4,7,10},\n",
    "    'maj7'      : {0,4,7,11},\n",
    "    'min7'      : {0,3,7,10},\n",
    "    'halfdim7'  : {0,3,6,10},\n",
    "    'dim7'      : {0,3,6,9},\n",
    "}\n",
    "\n",
    "def best_chord_label(pitches):\n",
    "    \"\"\"\n",
    "    pitches: 리스트/셋 (MIDI pitch들) → 최적의 (root, quality) 반환. 없으면 None.\n",
    "    평가 기준: 템플릿 커버 비율 + 사이즈 근사성.\n",
    "    \"\"\"\n",
    "    if not pitches:\n",
    "        return None\n",
    "    pcs = sorted({p % 12 for p in pitches})\n",
    "    if not pcs:\n",
    "        return None\n",
    "\n",
    "    best = None\n",
    "    best_score = -1e9\n",
    "    for root in range(12):\n",
    "        shifted = {(pc - root) % 12 for pc in pcs}\n",
    "        for qual, templ in CHORD_TEMPLATES.items():\n",
    "            inter = len(shifted & templ)\n",
    "            # 템플릿 포함 비율 & 여분 패널티\n",
    "            cover = inter / max(1, len(templ))\n",
    "            extra_penalty = -0.15 * max(0, len(shifted - templ))\n",
    "            score = cover + extra_penalty\n",
    "            if score > best_score and inter >= 2:  # 최소 2음 이상 맞아야 화음으로 인정\n",
    "                best_score = score\n",
    "                best = (root, qual)\n",
    "    if best is None:\n",
    "        return None\n",
    "    root_name = PC2NAME[best[0]]\n",
    "    return f\"{root_name}:{best[1]}\"  # 예: C:maj, A:min, G:dom7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "eepKPSdCX_W3"
   },
   "outputs": [],
   "source": [
    "TS_DIV = 16\n",
    "MIN_VEL, MAX_VEL = 20, 100\n",
    "MIN_DUR, MAX_DUR = 1, 16\n",
    "\n",
    "def quantize_time(pm_obj, ts_div=TS_DIV):\n",
    "    ts = pm_obj.time_signature_changes or [pm.TimeSignature(4,4,0.0)]\n",
    "    tempo_times, tempi = pm_obj.get_tempo_changes()\n",
    "    tempo = float(tempi[0]) if len(tempi) else 120.0\n",
    "    num, den = ts[0].numerator, ts[0].denominator\n",
    "    beat_len = 60.0 / tempo\n",
    "    bar_sec = (4/den) * num * beat_len\n",
    "\n",
    "    notes=[]\n",
    "    for inst in pm_obj.instruments:\n",
    "        for n in inst.notes:\n",
    "            bar = int(n.start // bar_sec)\n",
    "            pos = int(((n.start - bar*bar_sec)/bar_sec)*ts_div); pos = max(0,min(ts_div-1,pos))\n",
    "            dur = int(((n.end - n.start)/bar_sec)*ts_div); dur = max(MIN_DUR, min(MAX_DUR, dur))\n",
    "            vel = int(np.clip(n.velocity, MIN_VEL, MAX_VEL))\n",
    "            notes.append((bar,pos,n.pitch,dur,vel))\n",
    "    notes.sort(key=lambda x:(x[0],x[1],x[2]))\n",
    "    return notes, (num,den), int(tempo), bar_sec\n",
    "\n",
    "def encode_remi_harmony(midi_path: Path, add_chords=True, chord_every='pos'):\n",
    "    \"\"\"\n",
    "    chord_every: 'bar' → 바 당 1개, 'beat' → 박자 단위(근사), 'pos' → POS 단위(onset 기준).\n",
    "    \"\"\"\n",
    "    pm_obj = pm.PrettyMIDI(str(midi_path))\n",
    "    notes,(num,den),tempo,bar_sec = quantize_time(pm_obj)\n",
    "\n",
    "    # 0) KEY(장/단조) 토큰\n",
    "    key_token = detect_key_with_music21(midi_path)  # 예: 'Cmaj', 'Amin', None\n",
    "\n",
    "    toks = []\n",
    "    toks.append(f\"TSig_{num}_{den}\")\n",
    "    toks.append(f\"TEMPO_{tempo}\")\n",
    "    if key_token:\n",
    "        toks.append(f\"KEY_{key_token}\")  # 예: KEY_Cmaj\n",
    "\n",
    "    # 1) 화음 라벨링을 위한 그룹핑\n",
    "    #    - chord_every == 'bar' : 같은 bar 내 모든 노트 onsets\n",
    "    #    - chord_every == 'pos' : (bar,pos) 단위 노트 onsets\n",
    "    #    - chord_every == 'beat': bar 내 beat 경계 근사 (num 개)\n",
    "    from collections import defaultdict\n",
    "    onset_map = defaultdict(list)  # key: (bar, pos or beatIndex) → pitches\n",
    "\n",
    "    if chord_every == 'bar':\n",
    "        for (bar,pos,pitch,dur,vel) in notes:\n",
    "            onset_map[(bar, -1)].append(pitch)\n",
    "\n",
    "    elif chord_every == 'beat':\n",
    "        # 박자 경계(대략)로 pos→beat index 매핑 (TS_DIV를 num로 나눔)\n",
    "        step_per_beat = max(1, TS_DIV // num)\n",
    "        for (bar,pos,pitch,dur,vel) in notes:\n",
    "            beat_idx = pos // step_per_beat\n",
    "            onset_map[(bar, beat_idx)].append(pitch)\n",
    "\n",
    "    else:  # 'pos'\n",
    "        for (bar,pos,pitch,dur,vel) in notes:\n",
    "            onset_map[(bar, pos)].append(pitch)\n",
    "\n",
    "    # 2) 토큰 시퀀스 생성\n",
    "    cur_bar = -1\n",
    "    last_chord = None\n",
    "    for (bar,pos,pitch,dur,vel) in notes:\n",
    "        # BAR 토큰\n",
    "        while cur_bar < bar:\n",
    "            toks.append(\"BAR\")\n",
    "            cur_bar += 1\n",
    "            last_chord = None  # 새 마디에서 화음 새로 판단\n",
    "\n",
    "        # POS 토큰\n",
    "        toks.append(f\"POS_{pos}\")\n",
    "\n",
    "        # 2-a) 화음 토큰(선택)\n",
    "        if add_chords:\n",
    "            key = (bar, -1) if chord_every=='bar' else ((bar, pos) if chord_every=='pos' else (bar, pos // max(1, TS_DIV // num)))\n",
    "            chord_label = best_chord_label(onset_map.get(key, []))\n",
    "            if chord_label and chord_label != last_chord:\n",
    "                toks.append(f\"CHORD_{chord_label}\")   # 예: CHORD_C:maj, CHORD_A:min\n",
    "                last_chord = chord_label\n",
    "\n",
    "        # 2-b) 음표 이벤트\n",
    "        toks += [f\"NOTE_ON_{pitch}\", f\"DUR_{dur}\", f\"VEL_{vel}\"]\n",
    "\n",
    "    return toks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "oUhK5vZCYD4N"
   },
   "outputs": [],
   "source": [
    "def cond_tokens(meta, midi_path_for_key: Path = None):\n",
    "    t = [\"COMPOSER_Beethoven\"]\n",
    "    if meta.get(\"music_period\"): t.append(f\"PERIOD_{meta['music_period']}\")\n",
    "    if meta.get(\"genre\"):        t.append(f\"GENRE_{meta['genre']}\")\n",
    "    if meta.get(\"difficulty\"):   t.append(f\"DIFF_{meta['difficulty']}\")\n",
    "    if meta.get(\"opus\"):         t.append(f\"OPUS_{str(meta['opus']).replace(' ','_')}\")\n",
    "    q=meta.get(\"audio_score\")\n",
    "    if q is not None:\n",
    "        t.append(f\"QUALITY_{'High' if q>=0.8 else 'Med' if q>=0.5 else 'Low'}\")\n",
    "    # KEY (메타/파일 기반)\n",
    "    if midi_path_for_key is not None:\n",
    "        k = detect_key_with_music21(midi_path_for_key)\n",
    "        if k:\n",
    "            t.append(f\"KEY_{k}\")  # KEY_Cmaj / KEY_Amin ...\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_g9y46PUSQ4U",
    "outputId": "4a8c110e-9e41-4351-ace7-53894848360d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB_SIZE: 330\n"
     ]
    }
   ],
   "source": [
    "def build_vocab():\n",
    "    if VOCAB_JSON.exists(): return json.load(open(VOCAB_JSON))\n",
    "    vocab={\"[PAD]\":0,\"[BOS]\":1,\"[EOS]\":2,\"[UNK]\":3}\n",
    "    idx=len(vocab)\n",
    "    for fname,meta in META.items():\n",
    "        p = SPLIT_ROOT/meta[\"split\"]/meta[\"file_path\"]\n",
    "        if not p.exists(): continue\n",
    "        # vocab 빌드 단계\n",
    "        toks = [\"[BOS]\"] + cond_tokens(meta, midi_path_for_key=p) + encode_remi_harmony(p, add_chords=True, chord_every='pos')+ [\"[EOS]\"]\n",
    "\n",
    "        json.dump(toks, open(TOK_CACHE_DIR/(fname+\".json\"),\"w\"))\n",
    "        for t in toks:\n",
    "            if t not in vocab:\n",
    "                vocab[t]=idx; idx+=1\n",
    "    json.dump(vocab, open(VOCAB_JSON,\"w\"))\n",
    "    return vocab\n",
    "\n",
    "VOCAB = build_vocab()\n",
    "IVOCAB= {i:t for t,i in VOCAB.items()}\n",
    "VOCAB_SIZE=len(VOCAB)\n",
    "print(\"VOCAB_SIZE:\", VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "wNqiWgG6SUWq"
   },
   "outputs": [],
   "source": [
    "SEQ_LEN=512\n",
    "\n",
    "def toks_to_ids(toks): return [VOCAB.get(t, VOCAB[\"[UNK]\"]) for t in toks]\n",
    "\n",
    "class BeethovenMIDIDataset(Dataset):\n",
    "    def __init__(self, split):\n",
    "        self.items=[(k,v) for k,v in META.items() if v[\"split\"]==split]\n",
    "        random.Random(42).shuffle(self.items)\n",
    "    def __len__(self): return len(self.items)\n",
    "    def __getitem__(self,i):\n",
    "        fname,meta = self.items[i]\n",
    "        cache=TOK_CACHE_DIR/(fname+\".json\")\n",
    "        if cache.exists(): toks=json.load(open(cache))\n",
    "        else:\n",
    "            p=SPLIT_ROOT/meta[\"split\"]/meta[\"file_path\"]\n",
    "            toks=[\"[BOS]\"]+cond_tokens(meta)+encode_remi_lite(p)+[\"[EOS]\"]\n",
    "        ids=toks_to_ids(toks)\n",
    "        if len(ids)>=SEQ_LEN:\n",
    "            st=random.randint(0, len(ids)-SEQ_LEN)\n",
    "            seq=ids[st:st+SEQ_LEN]\n",
    "        else:\n",
    "            seq=ids+[VOCAB[\"[PAD]\"]] * (SEQ_LEN-len(ids))\n",
    "        x=torch.tensor(seq[:-1],dtype=torch.long)\n",
    "        y=torch.tensor(seq[1:], dtype=torch.long)\n",
    "        return x,y\n",
    "\n",
    "train_dl=DataLoader(BeethovenMIDIDataset(\"train\"), batch_size=16, shuffle=True, drop_last=True)\n",
    "val_dl  =DataLoader(BeethovenMIDIDataset(\"validation\"), batch_size=16, shuffle=False, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "O_BC3kuQSf6q"
   },
   "outputs": [],
   "source": [
    "import math, torch, torch.nn as nn\n",
    "from einops import rearrange\n",
    "\n",
    "# ===== 1) RoPE (Rotary Positional Embedding) =====\n",
    "def apply_rope(q,k):\n",
    "    B,H,T,D = q.shape\n",
    "    pos = torch.arange(T, device=q.device).float()\n",
    "    inv = 1.0/(10000**(torch.arange(0,D,2,device=q.device).float()/D))\n",
    "    ang = torch.einsum('t,d->td', pos, inv)\n",
    "    sin,cos = ang.sin()[None,None], ang.cos()[None,None]\n",
    "    def rot(x):\n",
    "        x1,x2=x[...,::2],x[...,1::2]\n",
    "        return torch.stack([x1*cos - x2*sin, x1*sin + x2*cos], dim=-1).flatten(-2)\n",
    "    return rot(q), rot(k)\n",
    "\n",
    "# ===== 2) Self-Attention =====\n",
    "class CausalSelfAttn(nn.Module):\n",
    "    def __init__(self,d_model=512,n_head=8,p=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model% n_head==0\n",
    "        self.nh=n_head; self.dk=d_model//n_head\n",
    "        self.qkv=nn.Linear(d_model, d_model*3)\n",
    "        self.proj=nn.Linear(d_model, d_model)\n",
    "        self.drop=nn.Dropout(p)\n",
    "    def forward(self,x):\n",
    "        B,T,C=x.shape\n",
    "        q,k,v = self.qkv(x).chunk(3,-1)\n",
    "        q=rearrange(q,'b t (h d)->b h t d',h=self.nh)\n",
    "        k=rearrange(k,'b t (h d)->b h t d',h=self.nh)\n",
    "        v=rearrange(v,'b t (h d)->b h t d',h=self.nh)\n",
    "        q,k=apply_rope(q,k)\n",
    "        att=(q@k.transpose(-1,-2))/math.sqrt(self.dk)\n",
    "        mask=torch.triu(torch.ones(T,T,device=x.device),1).bool()\n",
    "        att=att.masked_fill(mask,float('-inf')).softmax(-1)\n",
    "        att=self.drop(att)\n",
    "        y=att@v\n",
    "        y=rearrange(y,'b h t d->b t (h d)')\n",
    "        return self.proj(y)\n",
    "\n",
    "# ===== 3) Transformer Block =====\n",
    "class Block(nn.Module):\n",
    "    def __init__(self,d=512,h=8,p=0.1,mlp=4):\n",
    "        super().__init__()\n",
    "        self.ln1=nn.LayerNorm(d); self.att=CausalSelfAttn(d,h,p)\n",
    "        self.ln2=nn.LayerNorm(d)\n",
    "        self.mlp=nn.Sequential(\n",
    "            nn.Linear(d,d*mlp), nn.GELU(), nn.Dropout(p), nn.Linear(d*mlp,d)\n",
    "        )\n",
    "        self.drop=nn.Dropout(p)\n",
    "    def forward(self,x):\n",
    "        x=x+self.drop(self.att(self.ln1(x)))\n",
    "        x=x+self.drop(self.mlp(self.ln2(x)))\n",
    "        return x\n",
    "\n",
    "# ===== 4) MiniGPT Model =====\n",
    "class MiniGPT(nn.Module):\n",
    "    def __init__(self,vocab_size, d=512, L=8, H=8, p=0.1):\n",
    "        super().__init__()\n",
    "        self.emb=nn.Embedding(vocab_size, d)\n",
    "        self.pos=nn.Parameter(torch.zeros(1, SEQ_LEN-1, d))  # 절대 위치 (RoPE와 병용)\n",
    "        self.blocks=nn.ModuleList([Block(d,H,p) for _ in range(L)])\n",
    "        self.ln=nn.LayerNorm(d)\n",
    "        self.head=nn.Linear(d, vocab_size, bias=False)\n",
    "    def forward(self,idx):\n",
    "        x=self.emb(idx) + self.pos[:, :idx.size(1), :]\n",
    "        for b in self.blocks: x=b(x)\n",
    "        return self.head(self.ln(x))\n",
    "\n",
    "# ===== 5) 모델 초기화 =====\n",
    "model = MiniGPT(VOCAB_SIZE).to(DEVICE)\n",
    "opt   = torch.optim.AdamW(model.parameters(), lr=3e-4, betas=(0.9,0.95), weight_decay=0.1)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=VOCAB[\"[PAD]\"], label_smoothing=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "HWRsoGe7apIg"
   },
   "outputs": [],
   "source": [
    "import pretty_midi as pm\n",
    "from pathlib import Path\n",
    "\n",
    "def detokenize_to_midi(tokens, out_path, ts_div=16, default_time_sig=(4,4), default_tempo=120,\n",
    "                       program=0, safe_pitch=(36,96)):\n",
    "    \"\"\"\n",
    "    REMI류 토큰 시퀀스를 MIDI로 복원합니다.\n",
    "    - tokens 예시: [\"TSig_4_4\",\"TEMPO_112\",\"BAR\",\"POS_0\",\"NOTE_ON_60\",\"DUR_4\",\"VEL_80\", ...]\n",
    "    - KEY_*, CHORD_* 토큰은 MIDI에 직접 반영하지 않고 건너뜁니다.\n",
    "    - ts_div는 토큰화 때 쓴 TS_DIV와 동일해야 합니다(기본 16).\n",
    "    \"\"\"\n",
    "    out_path = Path(out_path) if isinstance(out_path, str) else out_path\n",
    "\n",
    "    # 초기 메타\n",
    "    num, den = default_time_sig\n",
    "    tempo = default_tempo\n",
    "    beat_len = 60.0 / tempo\n",
    "    bar_sec = (4/den) * num * beat_len\n",
    "\n",
    "    cur_bar = -1\n",
    "    pos = 0\n",
    "\n",
    "    pm_out = pm.PrettyMIDI()\n",
    "    inst = pm.Instrument(program=program)\n",
    "    SAFE_LOW, SAFE_HIGH = safe_pitch\n",
    "\n",
    "    i = 0\n",
    "    N = len(tokens)\n",
    "    while i < N:\n",
    "        t = tokens[i]\n",
    "\n",
    "        # 메타 토큰\n",
    "        if t.startswith(\"TSig_\"):\n",
    "            try:\n",
    "                _, a, b = t.split(\"_\")\n",
    "                num, den = int(a), int(b)\n",
    "                beat_len = 60.0 / tempo\n",
    "                bar_sec = (4/den) * num * beat_len\n",
    "            except Exception:\n",
    "                pass\n",
    "            i += 1; continue\n",
    "\n",
    "        if t.startswith(\"TEMPO_\"):\n",
    "            try:\n",
    "                tempo = int(t.split(\"_\")[1])\n",
    "                beat_len = 60.0 / tempo\n",
    "                bar_sec = (4/den) * num * beat_len\n",
    "            except Exception:\n",
    "                pass\n",
    "            i += 1; continue\n",
    "\n",
    "        if t.startswith(\"KEY_\") or t.startswith(\"CHORD_\"):\n",
    "            i += 1; continue  # 조성/화음 토큰은 MIDI에 직접 반영하지 않음\n",
    "\n",
    "        # 구조 토큰\n",
    "        if t == \"BAR\":\n",
    "            cur_bar += 1\n",
    "            pos = 0\n",
    "            i += 1; continue\n",
    "\n",
    "        if t.startswith(\"POS_\"):\n",
    "            try:\n",
    "                pos = int(t.split(\"_\")[1])\n",
    "                pos = max(0, min(ts_div-1, pos))\n",
    "            except Exception:\n",
    "                pos = max(0, min(ts_div-1, pos))\n",
    "            i += 1; continue\n",
    "\n",
    "        # 음표 이벤트\n",
    "        if t.startswith(\"NOTE_ON_\"):\n",
    "            # NOTE_ON_p\n",
    "            try:\n",
    "                pitch = int(t.split(\"_\")[2])\n",
    "            except Exception:\n",
    "                i += 1; continue\n",
    "            i += 1\n",
    "\n",
    "            # DUR_d (기본 4), VEL_v (기본 80)\n",
    "            dur = 4\n",
    "            vel = 80\n",
    "            if i < N and tokens[i].startswith(\"DUR_\"):\n",
    "                try: dur = int(tokens[i].split(\"_\")[1])\n",
    "                except Exception: pass\n",
    "                i += 1\n",
    "            if i < N and (tokens[i].startswith(\"VEL_\") or tokens[i].startswith(\"VELOCITY_\")):\n",
    "                try: vel = int(tokens[i].split(\"_\")[1])\n",
    "                except Exception: pass\n",
    "                i += 1\n",
    "\n",
    "            pitch = max(SAFE_LOW, min(SAFE_HIGH, pitch))\n",
    "            start = (cur_bar * bar_sec) + (pos / ts_div) * bar_sec\n",
    "            end   = start + (dur / ts_div) * bar_sec\n",
    "            if end <= start:\n",
    "                end = start + (1 / ts_div) * bar_sec  # 최소 1틱\n",
    "\n",
    "            inst.notes.append(pm.Note(velocity=vel, pitch=pitch, start=start, end=end))\n",
    "            continue\n",
    "\n",
    "        # 알 수 없는 토큰은 무시\n",
    "        i += 1\n",
    "\n",
    "    pm_out.instruments.append(inst)\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    pm_out.write(str(out_path))\n",
    "    return out_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KbeE1fjcZg71",
    "outputId": "fa941b97-36ea-4d2b-9c38-cc2adda5ffb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/50] train 6.0087 | val 6.0071 | best 6.0071 | lr 0.000001\n",
      "[2/50] train 6.0034 | val 6.0076 | best 6.0071 | lr 0.000003\n",
      "[3/50] train 5.9803 | val 6.0146 | best 6.0071 | lr 0.000004\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 92\u001b[39m\n\u001b[32m     89\u001b[39m ckpt_path = SPLIT_ROOT / \u001b[33m\"\u001b[39m\u001b[33mminigpt_best.pt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, EPOCHS+\u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     tr = \u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m     \u001b[38;5;66;03m# ✅ EMA 가중치로 검증\u001b[39;00m\n\u001b[32m     95\u001b[39m     ema.store(model); ema.copy_to(model)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 75\u001b[39m, in \u001b[36mrun_epoch\u001b[39m\u001b[34m(dl, train, grad_clip)\u001b[39m\n\u001b[32m     73\u001b[39m             loss = loss / ACC\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m train:\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m step % ACC == \u001b[32m0\u001b[39m:\n\u001b[32m     77\u001b[39m         torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/_tensor.py:647\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    639\u001b[39m         Tensor.backward,\n\u001b[32m    640\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    645\u001b[39m         inputs=inputs,\n\u001b[32m    646\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/autograd/graph.py:829\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    827\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ====== 0) 준비 ======\n",
    "import math, torch\n",
    "import torch.nn as nn\n",
    "from torch.amp import GradScaler, autocast  # ✅ AMP 최신 API\n",
    "\n",
    "VOCAB_SIZE = len(VOCAB)\n",
    "\n",
    "# ====== EMA 유틸 ======\n",
    "class EMA:\n",
    "    def __init__(self, model, decay=0.999):\n",
    "        self.decay = decay\n",
    "        self.shadow = {k: p.detach().clone() for k, p in model.state_dict().items()}\n",
    "        self.backup = None\n",
    "    @torch.no_grad()\n",
    "    def update(self, model):\n",
    "        for k, p in model.state_dict().items():\n",
    "            self.shadow[k].mul_(self.decay).add_(p.detach(), alpha=1 - self.decay)\n",
    "    def store(self, model):\n",
    "        self.backup = {k: p.detach().clone() for k, p in model.state_dict().items()}\n",
    "    def copy_to(self, model):\n",
    "        model.load_state_dict(self.shadow, strict=False)\n",
    "    def restore(self, model):\n",
    "        if self.backup is not None:\n",
    "            model.load_state_dict(self.backup, strict=False)\n",
    "            self.backup = None\n",
    "\n",
    "ema = EMA(model, decay=0.999)\n",
    "\n",
    "# ====== 1) 손실, 옵티마이저, 스케줄러, 체크포인트 ======\n",
    "criterion = nn.CrossEntropyLoss(\n",
    "    ignore_index=VOCAB[\"[PAD]\"],\n",
    "    label_smoothing=0.05,    # ✅ 0.05로 미세조정\n",
    ")\n",
    "\n",
    "opt = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=3e-4,\n",
    "    betas=(0.9, 0.95),\n",
    "    weight_decay=0.03,       # ✅ 과규제 완화\n",
    ")\n",
    "\n",
    "EPOCHS = 50\n",
    "warmup_steps = 1000\n",
    "total_steps  = max(1, len(train_dl) * EPOCHS)\n",
    "\n",
    "def lr_lambda(step):\n",
    "    if step < warmup_steps:\n",
    "        return step / max(1, warmup_steps)\n",
    "    progress = (step - warmup_steps) / max(1, total_steps - warmup_steps)\n",
    "    progress = min(1.0, max(0.0, progress))\n",
    "    return 0.5 * (1 + math.cos(math.pi * progress))\n",
    "\n",
    "sched = torch.optim.lr_scheduler.LambdaLR(opt, lr_lambda)\n",
    "\n",
    "use_cuda_amp = (DEVICE.type == 'cuda')\n",
    "scaler = GradScaler('cuda' if use_cuda_amp else 'cpu')\n",
    "\n",
    "# ====== 2) 학습/검증 함수 (ACC=2) ======\n",
    "ACC = 2  # ✅ 유효 배치 x2\n",
    "\n",
    "def run_epoch(dl, train=True, grad_clip=1.0):\n",
    "    model.train(train)\n",
    "    total, n = 0.0, 0\n",
    "    if train:\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "    for step, (x, y) in enumerate(dl, 1):\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        with torch.set_grad_enabled(train):\n",
    "            with autocast('cuda' if use_cuda_amp else 'cpu'):\n",
    "                logits = model(x)\n",
    "                loss = criterion(logits.view(-1, VOCAB_SIZE), y.view(-1))\n",
    "                if train and ACC > 1:\n",
    "                    loss = loss / ACC\n",
    "        if train:\n",
    "            scaler.scale(loss).backward()\n",
    "            if step % ACC == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "                scaler.step(opt)\n",
    "                scaler.update()\n",
    "                sched.step()\n",
    "                opt.zero_grad(set_to_none=True)\n",
    "                ema.update(model)  # ✅ step 뒤 EMA 업데이트\n",
    "        total += loss.item() * (ACC if train and ACC > 1 else 1.0)\n",
    "        n += 1\n",
    "    return total / max(1, n)\n",
    "\n",
    "# ====== 3) 학습 루프 + EMA 검증 + 베스트 저장 ======\n",
    "best_val = float('inf')\n",
    "ckpt_path = SPLIT_ROOT / \"minigpt_best.pt\"\n",
    "\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    tr = run_epoch(train_dl, train=True)\n",
    "\n",
    "    # ✅ EMA 가중치로 검증\n",
    "    ema.store(model); ema.copy_to(model)\n",
    "    vl = run_epoch(val_dl, train=False)\n",
    "    ema.restore(model)\n",
    "\n",
    "    if vl < best_val:\n",
    "        best_val = vl\n",
    "        torch.save(model.state_dict(), str(ckpt_path))\n",
    "    print(f\"[{ep}/{EPOCHS}] train {tr:.4f} | val {vl:.4f} | best {best_val:.4f} | lr {sched.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "# ====== 4) 베스트 가중치 로드(안전) ======\n",
    "_ = model.load_state_dict(torch.load(str(ckpt_path), map_location=DEVICE))\n",
    "\n",
    "# ====== 5) 기본 generate (윈도우 자동 적용: pos 임베딩 길이에 맞춰 crop) ======\n",
    "@torch.no_grad()\n",
    "def generate(prompt_tokens, max_new=700, top_k=50, top_p=0.95, temp=0.9):\n",
    "    model.eval()\n",
    "    unk_id = VOCAB.get(\"[UNK]\", None)\n",
    "    if unk_id is None:\n",
    "        raise ValueError(\"Vocab must contain [UNK] token.\")\n",
    "    pos_len = getattr(getattr(model, 'pos', None), 'shape', [1, 100000, 0])[1]\n",
    "    ids = torch.tensor([[VOCAB.get(t, unk_id) for t in prompt_tokens]], device=DEVICE)\n",
    "    for _ in range(max_new):\n",
    "        ids_win = ids[:, -pos_len:] if ids.size(1) > pos_len else ids\n",
    "        logits = model(ids_win)[:, -1, :] / max(temp, 1e-6)\n",
    "        probs = torch.softmax(logits, dim=-1)[0]\n",
    "        if top_k > 0:\n",
    "            topk = torch.topk(probs, top_k)\n",
    "            mask = torch.ones_like(probs, dtype=torch.bool); mask[topk.indices] = False\n",
    "            probs = probs.masked_fill(mask, 0)\n",
    "        if top_p < 1.0:\n",
    "            sprob, sidx = torch.sort(probs, descending=True)\n",
    "            keep = torch.cumsum(sprob, dim=-1) <= top_p\n",
    "            keep[0] = True\n",
    "            mask = torch.ones_like(probs, dtype=torch.bool); mask[sidx[keep]] = False\n",
    "            probs = probs.masked_fill(mask, 0)\n",
    "        probs = probs / probs.sum()\n",
    "        nxt = torch.multinomial(probs, 1)\n",
    "        ids = torch.cat([ids, nxt.view(1,1)], dim=1)\n",
    "        if nxt.item() == VOCAB[\"[EOS]\"]:\n",
    "            break\n",
    "    return [IVOCAB[i.item()] for i in ids[0]]\n",
    "\n",
    "# ====== 6) 길게 생성: 청크 스티칭(모델 수정 없음) ======\n",
    "def stitch_generate(prompt_tokens, total_new=512, chunk_new=700, context=480,\n",
    "                    top_k=50, top_p=0.95, temp=0.9, stop_on_eos=False):\n",
    "    all_tokens = list(prompt_tokens)\n",
    "    made = 0\n",
    "    while made < total_new:\n",
    "        this_new = min(chunk_new, total_new - made)\n",
    "        cur_prompt = all_tokens[-context:] if len(all_tokens) > context else all_tokens\n",
    "        chunk = generate(cur_prompt, max_new=this_new, top_k=top_k, top_p=top_p, temp=temp)\n",
    "        new_part = chunk[len(cur_prompt):] if len(chunk) > len(cur_prompt) else []\n",
    "        if stop_on_eos and (\"[EOS]\" in new_part):\n",
    "            eos_idx = new_part.index(\"[EOS]\"); all_tokens += new_part[:eos_idx]; break\n",
    "        all_tokens += new_part\n",
    "        made += len(new_part)\n",
    "        if len(new_part) == 0:\n",
    "            break\n",
    "    return all_tokens\n",
    "\n",
    "# ====== 7) 프롬프트 설정 & 길게 생성 & 저장 ======\n",
    "prompt = [\"[BOS]\",\"COMPOSER_Beethoven\",\"PERIOD_Middle\",\"GENRE_Sonata\",\"KEY_Cmin\",\n",
    "          \"TSig_4_4\",\"TEMPO_112\",\"BAR\",\"POS_0\",\"BAR\",\"POS_0\",\"BAR\",\"POS_0\"]\n",
    "\n",
    "tokens_long = stitch_generate(\n",
    "    prompt_tokens=prompt,\n",
    "    total_new=512,     # 길이는 유지\n",
    "    chunk_new=700,\n",
    "    context=480,\n",
    "    top_k=50, top_p=0.95, temp=0.9,\n",
    "    stop_on_eos=False\n",
    ")\n",
    "\n",
    "out_mid_long = SPLIT_ROOT / \"sample_beethoven_long_v1.mid\"\n",
    "detokenize_to_midi(tokens_long, out_mid_long)\n",
    "print(\"Saved →\", out_mid_long)\n",
    "\n",
    "# ====== 8) (선택) 퍼플렉서티로 상태 확인 ======\n",
    "print(\"Best val loss:\", best_val, \"| approx PPL:\", math.exp(best_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ejD7vA-HgOS0",
    "outputId": "f7fc6886-cb90-4aa3-8ec1-e7b46d0e3158"
   },
   "outputs": [],
   "source": [
    "# ====== 0) 준비 ======\n",
    "import math, torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.amp import GradScaler, autocast  # AMP 최신 API\n",
    "from torch.optim.swa_utils import AveragedModel  # SWA\n",
    "\n",
    "VOCAB_SIZE = len(VOCAB)\n",
    "PAD_ID = VOCAB[\"[PAD]\"]\n",
    "UNK_ID = VOCAB.get(\"[UNK]\", None)\n",
    "assert UNK_ID is not None, \"[UNK] 토큰이 vocab에 필요합니다.\"\n",
    "\n",
    "# ----- (선택) 토큰 드롭아웃: VEL_/DUR_ 소량 마스킹 -----\n",
    "DROP_PROB = 0.05  # 3~7% 권장\n",
    "VEL_IDS = {tid for tok, tid in VOCAB.items() if tok.startswith(\"VEL_\")}\n",
    "DUR_IDS = {tid for tok, tid in VOCAB.items() if tok.startswith(\"DUR_\")}\n",
    "DROP_SET = VEL_IDS | DUR_IDS\n",
    "\n",
    "def token_dropout(batch_ids, drop_prob=DROP_PROB):\n",
    "    # batch_ids: LongTensor [B, T]\n",
    "    if drop_prob <= 0 or not DROP_SET:\n",
    "        return batch_ids\n",
    "    dev = batch_ids.device\n",
    "    drop_ids = torch.tensor(list(DROP_SET), device=dev)\n",
    "    mask = torch.rand_like(batch_ids.float()) < drop_prob\n",
    "    sel = mask & torch.isin(batch_ids, drop_ids)\n",
    "    return batch_ids.masked_fill(sel, PAD_ID)\n",
    "\n",
    "# ====== EMA 유틸 ======\n",
    "class EMA:\n",
    "    def __init__(self, model, decay=0.999):\n",
    "        self.decay = decay\n",
    "        self.shadow = {k: p.detach().clone() for k, p in model.state_dict().items()}\n",
    "        self.backup = None\n",
    "    @torch.no_grad()\n",
    "    def update(self, model):\n",
    "        for k, p in model.state_dict().items():\n",
    "            self.shadow[k].mul_(self.decay).add_(p.detach(), alpha=1 - self.decay)\n",
    "    def store(self, model):\n",
    "        self.backup = {k: p.detach().clone() for k, p in model.state_dict().items()}\n",
    "    def copy_to(self, model):\n",
    "        model.load_state_dict(self.shadow, strict=False)\n",
    "    def restore(self, model):\n",
    "        if self.backup is not None:\n",
    "            model.load_state_dict(self.backup, strict=False)\n",
    "            self.backup = None\n",
    "\n",
    "ema = EMA(model, decay=0.999)\n",
    "\n",
    "# ====== 1) 손실, 옵티마이저, 스케줄러 ======\n",
    "criterion = nn.CrossEntropyLoss(\n",
    "    ignore_index=PAD_ID,\n",
    "    label_smoothing=0.05,\n",
    ")\n",
    "\n",
    "opt = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=3e-4,\n",
    "    betas=(0.9, 0.95),\n",
    "    weight_decay=0.03,\n",
    ")\n",
    "\n",
    "EPOCHS = 50\n",
    "warmup_steps = 1000\n",
    "total_steps  = max(1, len(train_dl) * EPOCHS)\n",
    "\n",
    "def lr_lambda(step):\n",
    "    if step < warmup_steps:\n",
    "        return step / max(1, warmup_steps)\n",
    "    progress = (step - warmup_steps) / max(1, total_steps - warmup_steps)\n",
    "    progress = min(1.0, max(0.0, progress))\n",
    "    return 0.5 * (1 + math.cos(math.pi * progress))\n",
    "\n",
    "sched = torch.optim.lr_scheduler.LambdaLR(opt, lr_lambda)\n",
    "\n",
    "use_cuda_amp = (DEVICE.type == 'cuda')\n",
    "scaler = GradScaler('cuda' if use_cuda_amp else 'cpu')\n",
    "\n",
    "# ====== R-Drop 설정 ======\n",
    "kl_factor = 1.0  # 0.5~2.0 사이 탐색 추천\n",
    "\n",
    "def sym_kl(logits1, logits2, mask=None):\n",
    "    # logits: [B, T, V]; mask: [B, T] (1=valid, 0=ignore)\n",
    "    p = F.log_softmax(logits1, dim=-1)\n",
    "    q = F.log_softmax(logits2, dim=-1)\n",
    "    p_exp = p.exp(); q_exp = q.exp()\n",
    "    kl = (p_exp * (p - q)).sum(-1) + (q_exp * (q - p)).sum(-1)  # [B, T]\n",
    "    if mask is not None:\n",
    "        kl = kl * mask\n",
    "        denom = mask.sum().clamp_min(1)\n",
    "        return kl.sum() / denom\n",
    "    return kl.mean()\n",
    "\n",
    "# ====== 2) 학습/검증 함수 (ACC=2 + R-Drop + TokenDropout) ======\n",
    "ACC = 2  # 유효 배치 x2\n",
    "\n",
    "def run_epoch(dl, train=True, grad_clip=1.0):\n",
    "    model.train(train)\n",
    "    total, n = 0.0, 0\n",
    "    if train:\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "    for step, (x, y) in enumerate(dl, 1):\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        if train:\n",
    "            x = token_dropout(x)  # 입력 노이즈(소량)로 강건성 ↑\n",
    "\n",
    "        with torch.set_grad_enabled(train):\n",
    "            if train:\n",
    "                with autocast('cuda' if use_cuda_amp else 'cpu'):\n",
    "                    # R-Drop: dropout 활성 상태에서 두 번 forward\n",
    "                    logits1 = model(x)\n",
    "                    logits2 = model(x)\n",
    "                    ce1 = criterion(logits1.view(-1, VOCAB_SIZE), y.view(-1))\n",
    "                    ce2 = criterion(logits2.view(-1, VOCAB_SIZE), y.view(-1))\n",
    "                    y_mask = (y != PAD_ID).float()\n",
    "                    kl = sym_kl(logits1, logits2, y_mask)\n",
    "                    loss = 0.5*(ce1+ce2) + kl_factor*kl\n",
    "                    if ACC > 1:\n",
    "                        loss = loss / ACC\n",
    "            else:\n",
    "                with autocast('cuda' if use_cuda_amp else 'cpu'):\n",
    "                    logits = model(x)\n",
    "                    loss = criterion(logits.view(-1, VOCAB_SIZE), y.view(-1))\n",
    "\n",
    "        if train:\n",
    "            scaler.scale(loss).backward()\n",
    "            if step % ACC == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "                scaler.step(opt)\n",
    "                scaler.update()\n",
    "                sched.step()\n",
    "                opt.zero_grad(set_to_none=True)\n",
    "                ema.update(model)\n",
    "\n",
    "        total += loss.item() * (ACC if train and ACC > 1 else 1.0)\n",
    "        n += 1\n",
    "    return total / max(1, n)\n",
    "\n",
    "# ====== 3) SWA(막판 평균) + EMA 검증 + 베스트 저장 ======\n",
    "best_val = float('inf')\n",
    "ckpt_path = SPLIT_ROOT / \"minigpt_best.pt\"\n",
    "\n",
    "swa_start_epoch = max(5, EPOCHS - 5)  # 마지막 5에폭 평균\n",
    "swa_model = AveragedModel(model)\n",
    "\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    tr = run_epoch(train_dl, train=True)\n",
    "\n",
    "    # SWA 평균 누적(에폭 단위)\n",
    "    if ep >= swa_start_epoch:\n",
    "        swa_model.update_parameters(model)\n",
    "\n",
    "    # EMA 가중치로 검증\n",
    "    ema.store(model); ema.copy_to(model)\n",
    "    vl = run_epoch(val_dl, train=False)\n",
    "    ema.restore(model)\n",
    "\n",
    "    if vl < best_val:\n",
    "        best_val = vl\n",
    "        torch.save(model.state_dict(), str(ckpt_path))\n",
    "    print(f\"[{ep}/{EPOCHS}] train {tr:.4f} | val {vl:.4f} | best {best_val:.4f} | lr {sched.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "# ====== 4) 베스트 가중치 로드(안전) + (선택) SWA 평가/저장 ======\n",
    "_ = model.load_state_dict(torch.load(str(ckpt_path), map_location=DEVICE))\n",
    "\n",
    "# SWA 가중치로도 한 번 평가해보고, 더 좋으면 SWA로 저장\n",
    "try:\n",
    "    ema.store(model)\n",
    "    model.load_state_dict(swa_model.state_dict(), strict=False)\n",
    "    vl_swa = run_epoch(val_dl, train=False)\n",
    "    print(f\"[SWA] val {vl_swa:.4f}\")\n",
    "    if vl_swa < best_val:\n",
    "        torch.save(model.state_dict(), str(SPLIT_ROOT / \"minigpt_best_swa.pt\"))\n",
    "        print(\"SWA checkpoint saved (better than EMA-best).\")\n",
    "    ema.restore(model)\n",
    "except Exception as e:\n",
    "    print(\"SWA eval skipped:\", e)\n",
    "\n",
    "# ====== 5) 기본 generate (윈도우 자동 crop + 경량 반복 페널티/온도 스케줄) ======\n",
    "def temp_schedule(step, t_max, t0=0.9, t1=0.8):\n",
    "    a = min(1.0, max(0.0, step / max(1, t_max)))\n",
    "    return t0*(1-a) + t1*a\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate(prompt_tokens, max_new=700, top_k=50, top_p=0.95, temp=0.9, rep_penalty=1.05):\n",
    "    model.eval()\n",
    "    pos_len = getattr(getattr(model, 'pos', None), 'shape', [1, 100000, 0])[1]\n",
    "    ids = torch.tensor([[VOCAB.get(t, UNK_ID) for t in prompt_tokens]], device=DEVICE)\n",
    "    for step in range(max_new):\n",
    "        ids_win = ids[:, -pos_len:] if ids.size(1) > pos_len else ids\n",
    "        cur_temp = temp_schedule(step, max_new, t0=temp, t1=max(0.6, temp-0.1))\n",
    "        logits = model(ids_win)[:, -1, :] / max(cur_temp, 1e-6)\n",
    "        probs = torch.softmax(logits, dim=-1)[0]\n",
    "\n",
    "        # 미세 반복 페널티(직전 토큰만 약하게)\n",
    "        last_tok = ids[0, -1]\n",
    "        probs[last_tok] = probs[last_tok] / rep_penalty\n",
    "\n",
    "        if top_k > 0:\n",
    "            topk = torch.topk(probs, top_k)\n",
    "            mask = torch.ones_like(probs, dtype=torch.bool); mask[topk.indices] = False\n",
    "            probs = probs.masked_fill(mask, 0)\n",
    "        if top_p < 1.0:\n",
    "            sprob, sidx = torch.sort(probs, descending=True)\n",
    "            keep = torch.cumsum(sprob, dim=-1) <= top_p\n",
    "            keep[0] = True\n",
    "            mask = torch.ones_like(probs, dtype=torch.bool); mask[sidx[keep]] = False\n",
    "            probs = probs.masked_fill(mask, 0)\n",
    "        probs = probs / probs.sum()\n",
    "\n",
    "        nxt = torch.multinomial(probs, 1)\n",
    "        ids = torch.cat([ids, nxt.view(1,1)], dim=1)\n",
    "        if nxt.item() == VOCAB[\"[EOS]\"]:\n",
    "            break\n",
    "    return [IVOCAB[i.item()] for i in ids[0]]\n",
    "\n",
    "# ====== 6) 길게 생성: 청크 스티칭(모델 수정 없음) ======\n",
    "def stitch_generate(prompt_tokens, total_new=512, chunk_new=700, context=480,\n",
    "                    top_k=50, top_p=0.95, temp=0.9, stop_on_eos=False):\n",
    "    all_tokens = list(prompt_tokens); made = 0\n",
    "    while made < total_new:\n",
    "        this_new = min(chunk_new, total_new - made)\n",
    "        cur_prompt = all_tokens[-context:] if len(all_tokens) > context else all_tokens\n",
    "        chunk = generate(cur_prompt, max_new=this_new, top_k=top_k, top_p=top_p, temp=temp)\n",
    "        new_part = chunk[len(cur_prompt):] if len(chunk) > len(cur_prompt) else []\n",
    "        if stop_on_eos and (\"[EOS]\" in new_part):\n",
    "            eos_idx = new_part.index(\"[EOS]\"); all_tokens += new_part[:eos_idx]; break\n",
    "        all_tokens += new_part; made += len(new_part)\n",
    "        if len(new_part) == 0: break\n",
    "    return all_tokens\n",
    "\n",
    "# ====== 7) 프롬프트 설정 & 길게 생성 & 저장 ======\n",
    "prompt = [\"[BOS]\",\"COMPOSER_Beethoven\",\"PERIOD_Middle\",\"GENRE_Sonata\",\"KEY_Cmin\",\n",
    "          \"TSig_4_4\",\"TEMPO_112\",\"BAR\",\"POS_0\",\"BAR\",\"POS_0\",\"BAR\",\"POS_0\"]\n",
    "\n",
    "tokens_long = stitch_generate(\n",
    "    prompt_tokens=prompt,\n",
    "    total_new=512,   # 길이는 유지\n",
    "    chunk_new=700,\n",
    "    context=480,\n",
    "    top_k=50, top_p=0.95, temp=0.9,\n",
    "    stop_on_eos=False\n",
    ")\n",
    "\n",
    "out_mid_long = SPLIT_ROOT / \"sample_beethoven_long_v2.mid\"\n",
    "detokenize_to_midi(tokens_long, out_mid_long)\n",
    "print(\"Saved →\", out_mid_long)\n",
    "\n",
    "# ====== 8) (선택) 퍼플렉서티로 상태 확인 ======\n",
    "print(\"Best val loss (EMA):\", best_val, \"| approx PPL:\", math.exp(best_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5pJYE9E3T3rL",
    "outputId": "710a129f-4d72-4f18-d1fe-86213c3f2cf5"
   },
   "outputs": [],
   "source": [
    "!pip install pyFluidSynth==1.3.4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yVm3SK1wkHaa"
   },
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7nApGl8Ek05d"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
