{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GT9D4mKwmudA"
   },
   "source": [
    "### 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YnJhqTRhZisC",
    "outputId": "f1e8c282-2d3c-46b3-f803-1f4b3fc29f09"
   },
   "outputs": [],
   "source": [
    "# [1] 런타임 체크\n",
    "import torch, platform, sys, os, subprocess, textwrap, random, numpy as np\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else None)\n",
    "\n",
    "# 재현성\n",
    "seed=42\n",
    "random.seed(seed); np.random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic=True; torch.backends.cudnn.benchmark=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jFk5LutRmy5S",
    "outputId": "6527a832-0aa5-41a8-db10-5f280193487a"
   },
   "outputs": [],
   "source": [
    "# [2] 라이브러리\n",
    "!pip -q install pretty_midi miditoolkit music21 datasets --progress-bar off\n",
    "# (선택) 시각화/로그: wandb or tensorboard 원하면 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mYUTJVHEqWpB",
    "outputId": "6cc40f98-386e-4d7a-9f4f-e2be9960295a"
   },
   "outputs": [],
   "source": [
    "### 음악 샘플 테스트\n",
    "!apt-get -q install -y fluidsynth\n",
    "!pip install midi2audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wzVQQBU1m1VO",
    "outputId": "b0848a61-b9c8-4053-c98e-c4374fef4a29"
   },
   "outputs": [],
   "source": [
    "# [3] 드라이브 마운트 & 프로젝트 폴더\n",
    "from google.colab import drive; drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vu3xjRlSQmak",
    "outputId": "ae090c87-42a8-474d-ef3f-12fe29a58551"
   },
   "outputs": [],
   "source": [
    "# 이미 Drive 마운트했다고 가정 (안했다면: from google.colab import drive; drive.mount('/content/drive'))\n",
    "\n",
    "PROJ = \"/content/drive/MyDrive/Deep_Learning_project/original_token\"\n",
    "print(\"PROJ:\", PROJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "tH94T0nmQ5Je",
    "outputId": "2644e04f-1c3a-4e09-8c77-87a209b873f6"
   },
   "outputs": [],
   "source": [
    "import os, glob, json, pandas as pd\n",
    "\n",
    "# PROJ 하위에서 메타데이터 파일 찾기 (파일명이 다르면 패턴만 바꾸면 됨)\n",
    "candidates = glob.glob(os.path.join(PROJ, \"**\", \"metadata.json\"), recursive=True)\n",
    "if not candidates:\n",
    "    raise FileNotFoundError(\"metadata.json 을 찾지 못했습니다. 위치를 확인하세요.\")\n",
    "META_JSON = candidates[0]\n",
    "print(\"META_JSON:\", META_JSON)\n",
    "\n",
    "# JSON 로드\n",
    "with open(META_JSON, \"r\") as f:\n",
    "    meta_raw = json.load(f)\n",
    "\n",
    "# JSON 구조가 {id: {metadata: {...}, audio_scores: {...}}} 형태라고 가정하고\n",
    "# 'metadata' 안의 내용을 추출하여 DataFrame 생성, JSON id를 index로 사용\n",
    "data_dict = {}\n",
    "for id, item in meta_raw.items():\n",
    "    if 'metadata' in item:\n",
    "        metadata = item['metadata']\n",
    "        row = {}\n",
    "        # 필요한 컬럼들을 직접 매핑\n",
    "        row['file_path'] = metadata.get('file_path')\n",
    "        row['split'] = metadata.get('split')\n",
    "        row['composer'] = metadata.get('composer')\n",
    "        row['music_period'] = metadata.get('music_period')\n",
    "        row['difficulty'] = metadata.get('difficulty')\n",
    "        row['genre'] = metadata.get('genre')\n",
    "        row['opus'] = metadata.get('opus')\n",
    "        # audio_scores가 top level이 아니라 metadata 안에 있는 경우\n",
    "        if 'audio_score' in metadata:\n",
    "             row['audio_score'] = metadata.get('audio_score')\n",
    "        # split_ratio가 top level이 아니라 metadata 안에 있는 경우\n",
    "        if 'split_ratio' in metadata:\n",
    "             row['split_ratio'] = metadata.get('split_ratio')\n",
    "\n",
    "        # 예시: audio_scores나 split_ratio가 metadata 레벨이 아닌 다른 곳에 있다면 아래와 같이 접근\n",
    "        # if 'audio_scores' in item:\n",
    "        #     row['audio_score'] = item['audio_scores'].get('some_score_key') # replace 'some_score_key'\n",
    "        # if 'split_ratio' in item:\n",
    "        #     row['split_ratio'] = item.get('split_ratio')\n",
    "\n",
    "        data_dict[id] = row\n",
    "\n",
    "meta_df = pd.DataFrame.from_dict(data_dict, orient=\"index\")\n",
    "\n",
    "\n",
    "# 중요한 컬럼만 보기 좋게 정렬(필요시 수정)\n",
    "cols = [c for c in [\"file_path\",\"split\",\"composer\",\"music_period\",\"difficulty\",\"genre\",\"audio_score\",\"opus\",\"split_ratio\"] if c in meta_df.columns]\n",
    "meta_df = meta_df[cols]\n",
    "display(meta_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "gVuF3BYnUg0L",
    "outputId": "909197e5-4790-4d77-83bf-fafd6ea1659f"
   },
   "outputs": [],
   "source": [
    "import os, pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import random # Import random for shuffling\n",
    "\n",
    "# NOTE: Make sure PROJ_Mozart is set correctly to the directory containing your MIDI files\n",
    "# PROJ_Mozart = \"/content/drive/MyDrive/Deep_Learning_project/original_token/mozart_midis\" # Example path\n",
    "if 'PROJ_Mozart' not in locals() and 'PROJ_Mozart' not in globals():\n",
    "    # Define a default or raise an error if PROJ_Mozart is not defined\n",
    "    # For now, using a placeholder - PLEASE UPDATE THIS TO YOUR ACTUAL MIDI DIRECTORY IF NEEDED\n",
    "    PROJ_Mozart = \"/content/drive/MyDrive/Deep_Learning_project/original_token/mozart_midis\"\n",
    "    print(f\"PROJ_Mozart was not defined, using default: {PROJ_Mozart}\")\n",
    "\n",
    "\n",
    "# PROJ 아래의 .mid/.midi 재귀 인덱싱\n",
    "all_midis = [p for p in Path(PROJ_Mozart).rglob(\"*\") if p.suffix.lower() in [\".mid\", \".midi\"]]\n",
    "print(\"Indexed MIDI files:\", len(all_midis))\n",
    "\n",
    "# 실제 파일명을 소문자로 정규화하여 인덱싱\n",
    "by_name = defaultdict(list)\n",
    "for p in all_midis:\n",
    "    by_name[p.name.lower()].append(str(p))\n",
    "\n",
    "# print(\"Sample keys in by_name:\", list(by_name.keys())[:10]) # Debugging: print sample keys from the indexed files\n",
    "\n",
    "def find_midi_for_meta(meta_index: str):\n",
    "    \"\"\"\n",
    "    메타데이터 DataFrame의 인덱스(JSON 키)를 사용하여 실제 MIDI 파일 찾기 시도.\n",
    "    파일 이름 패턴이 '{index}_0.mid' 또는 '{index}_0.midi' 형태라고 가정.\n",
    "    \"\"\"\n",
    "    # print(f\"Attempting to match index: {meta_index}\") # Debugging: print the current index being processed\n",
    "\n",
    "    if not isinstance(meta_index, str):\n",
    "        # print(\"Index is not a string, skipping.\") # Debugging\n",
    "        return None\n",
    "\n",
    "    # 예상 파일 이름 패턴 생성 (예: '4' -> '000004_0.mid')\n",
    "    # JSON 키가 숫자로 변환될 수 있다고 가정\n",
    "    try:\n",
    "        num = int(meta_index)\n",
    "        base_name_mid = f\"{str(num).zfill(6)}_0.mid\"\n",
    "        base_name_midi = f\"{str(num).zfill(6)}_0.midi\"\n",
    "        # print(f\"Expected filenames: {base_name_mid}, {base_name_midi}\") # Debugging\n",
    "    except ValueError:\n",
    "        # 인덱스가 숫자가 아니면 매칭 불가\n",
    "        # print(f\"Index '{meta_index}' is not a number, skipping.\") # Debugging\n",
    "        return None\n",
    "\n",
    "    # 인덱싱된 파일 목록에서 찾아보기\n",
    "    hits_mid = by_name.get(base_name_mid.lower(), [])\n",
    "    if hits_mid:\n",
    "        # print(f\"Match found for {base_name_mid.lower()}: {hits_mid[0]}\") # Debugging\n",
    "        return hits_mid[0]\n",
    "\n",
    "    hits_midi = by_name.get(base_name_midi.lower(), [])\n",
    "    if hits_midi:\n",
    "        # print(f\"Match found for {base_name_midi.lower()}: {hits_midi[0]}\") # Debugging\n",
    "        return hits_midi[0]\n",
    "\n",
    "    # print(f\"No match found for index: {meta_index}\") # Debugging\n",
    "    return None\n",
    "\n",
    "\n",
    "# 매칭 실행: file_path 대신 DataFrame index 사용\n",
    "print(\"\\n[EDA 실행 전 파일 목록 검토]\")\n",
    "if 'meta_df' not in locals():\n",
    "    print(\"meta_df DataFrame이 존재하지 않습니다. 이전 셀을 실행해주세요.\")\n",
    "    # EDA 관련 변수들을 빈 리스트로 초기화하여 오류 방지\n",
    "    train_files, val_files, test_files = [], [], []\n",
    "else:\n",
    "    # DataFrame의 인덱스를 사용하여 파일 경로 매칭\n",
    "    meta_df[\"full_path\"] = meta_df.index.map(find_midi_for_meta)\n",
    "\n",
    "    # Remove rows where full_path is None before splitting\n",
    "    matched_df = meta_df.dropna(subset=[\"full_path\"]).copy()\n",
    "\n",
    "    # Randomly split the matched files (60% train, 20% val, 20% test)\n",
    "    matched_files_list = matched_df[\"full_path\"].tolist()\n",
    "    random.shuffle(matched_files_list)\n",
    "\n",
    "    total_matched = len(matched_files_list)\n",
    "    train_size = int(0.6 * total_matched)\n",
    "    val_size = int(0.2 * total_matched)\n",
    "    # test_size = total_matched - train_size - val_size # remaining\n",
    "\n",
    "    train_files = matched_files_list[:train_size]\n",
    "    val_files = matched_files_list[train_size:train_size + val_size]\n",
    "    test_files = matched_files_list[train_size + val_size:] # Use remaining for test\n",
    "\n",
    "    # Update the 'split' column in the DataFrame based on the new random split\n",
    "    matched_df['split'] = None # Reset split column\n",
    "    matched_df.loc[matched_df['full_path'].isin(train_files), 'split'] = 'train'\n",
    "    matched_df.loc[matched_df['full_path'].isin(val_files), 'split'] = 'val'\n",
    "    matched_df.loc[matched_df['full_path'].isin(test_files), 'split'] = 'test'\n",
    "\n",
    "    # Now create the split dataframes from the matched_df with the new splits\n",
    "    train_df = matched_df[matched_df[\"split\"] == \"train\"]\n",
    "    val_df   = matched_df[matched_df[\"split\"] == \"val\"]\n",
    "    test_df  = matched_df[matched_df[\"split\"] == \"test\"]\n",
    "\n",
    "\n",
    "    # Result check\n",
    "    matched_count = len(matched_df) # Now this is the count of files that were successfully matched AND split\n",
    "    total_count = len(meta_df)\n",
    "    print(f\"원본 메타데이터 총 개수: {total_count}\")\n",
    "    print(f\"매칭 및 분할된 파일 수: {matched_count}\")\n",
    "\n",
    "\n",
    "    print(\"train:\", len(train_files), \" | val:\", len(val_files), \" | test:\", len(test_files))\n",
    "    display(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLmJuWbIXjfA"
   },
   "source": [
    "### EDA\n",
    "\t•\t이 데이터로 LSTM을 안정적으로 학습시킬 수 있는가?\n",
    "\t•\t토큰화 규칙(시간 분할, 벨로시티 bin, max_len)을 어떻게 정할 것인가?\n",
    "\t•\t학습 전 배제해야 할 샘플(너무 짧음/깨짐/이상치)은 있는가?\n",
    "\n",
    "  \t•\tTIME_SHIFT 분할: IOI 분포 기반 32 또는 64 결정\n",
    "\t•\tVEL bin 개수: 벨로시티 분포 기반 8/16 중 택1\n",
    "\t•\tmax_len/TBPTT: 길이 P95 기반(예: 512)\n",
    "\t•\t폴리포니 처리: 동시 발음 분포에 맞춰 간단/확장 설계\n",
    "\t•\t배제 규칙: 짧은 곡/무음/깨짐 사례 기준치 확정\n",
    "\t•\t샘플링 제약: 반복률 높으면 반복 페널티/노리핏 n-gram 도입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "REjx1JlZVzVn"
   },
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def analyze_midi(path):\n",
    "    try:\n",
    "        pm = pretty_midi.PrettyMIDI(path)\n",
    "    except Exception as e:\n",
    "        print(\"Parse error:\", path, e)\n",
    "        return None\n",
    "\n",
    "    # (B) 길이/밀도\n",
    "    duration = pm.get_end_time()\n",
    "    events = sum(len(inst.notes) for inst in pm.instruments)\n",
    "    density = events / duration if duration > 0 else 0\n",
    "\n",
    "    # (E) 리듬(IOI 분포)\n",
    "    iois = []\n",
    "    for inst in pm.instruments:\n",
    "        starts = sorted([n.start for n in inst.notes])\n",
    "        iois += np.diff(starts).tolist() if len(starts) > 1 else []\n",
    "    iois = np.array(iois)\n",
    "\n",
    "    # (D) 다이내믹스(벨로시티 분포)\n",
    "    velocities = [n.velocity for inst in pm.instruments for n in inst.notes]\n",
    "\n",
    "    # (F) 폴리포니(동시 발음 수)\n",
    "    note_times = []\n",
    "    for inst in pm.instruments:\n",
    "        for n in inst.notes:\n",
    "            note_times.append((n.start, +1))  # note_on\n",
    "            note_times.append((n.end, -1))   # note_off\n",
    "    note_times.sort()\n",
    "    active, max_poly, poly_hist = 0, 0, []\n",
    "    for t, ev in note_times:\n",
    "        active += ev\n",
    "        max_poly = max(max_poly, active)\n",
    "        poly_hist.append(active)\n",
    "\n",
    "    return {\n",
    "        \"file\": path,\n",
    "        \"duration\": duration,\n",
    "        \"events\": events,\n",
    "        \"density\": density,\n",
    "        \"iois\": iois,\n",
    "        \"velocities\": velocities,\n",
    "        \"max_poly\": max_poly,\n",
    "        \"poly_hist\": poly_hist,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "x4y1FtlpZaWK",
    "outputId": "08829d35-db73-41ae-d245-d54668663a91"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "all_files = train_files + val_files + test_files\n",
    "results = []\n",
    "ioi_all, vel_all, poly_all = [], [], []\n",
    "\n",
    "for f in tqdm(all_files[:100]):  # 처음엔 일부만 테스트 (예: 100개)\n",
    "    r = analyze_midi(f)\n",
    "    if r:\n",
    "        results.append({\n",
    "            \"file\": r[\"file\"],\n",
    "            \"duration\": r[\"duration\"],\n",
    "            \"events\": r[\"events\"],\n",
    "            \"density\": r[\"density\"],\n",
    "            \"max_poly\": r[\"max_poly\"]\n",
    "        })\n",
    "        ioi_all += r[\"iois\"].tolist()\n",
    "        vel_all += r[\"velocities\"]\n",
    "        poly_all += r[\"poly_hist\"]\n",
    "\n",
    "eda_df = pd.DataFrame(results)\n",
    "eda_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qZVj_w88aTz_"
   },
   "outputs": [],
   "source": [
    "# 필요 라이브러리\n",
    "import pretty_midi, numpy as np, math\n",
    "from collections import Counter, defaultdict\n",
    "from statistics import median\n",
    "\n",
    "# ---- 공통 유틸 ----\n",
    "def safe_load_midi(path):\n",
    "    try:\n",
    "        return pretty_midi.PrettyMIDI(path)\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def median_beat_period(pm: pretty_midi.PrettyMIDI):\n",
    "    \"\"\"곡의 박(quarter-note) 길이(초) 추정: beat 간격의 중앙값 사용.\"\"\"\n",
    "    beats = pm.get_beats()  # tempo 변화 반영됨\n",
    "    if len(beats) >= 2:\n",
    "        return float(np.median(np.diff(beats)))\n",
    "    # 예외: 비트 추정 실패 → 템포 변화에서 근사\n",
    "    times, tempi = pm.get_tempo_changes()\n",
    "    if len(tempi) > 0:\n",
    "        return float(np.median(60.0 / tempi))\n",
    "    # 최후의 기본값(120bpm)\n",
    "    return 0.5\n",
    "\n",
    "def all_notes(pm, include_drums=False):\n",
    "    notes = []\n",
    "    for inst in pm.instruments:\n",
    "        if (not include_drums) and inst.is_drum:\n",
    "            continue\n",
    "        notes.extend(inst.notes)\n",
    "    # 시작시각 기준 정렬\n",
    "    notes.sort(key=lambda n: (n.start, n.end))\n",
    "    return notes\n",
    "\n",
    "# ---- (1) TIME_SHIFT 분해능 평가: IOI 스냅 오차 ----\n",
    "def ioi_snap_report(files, limit=None):\n",
    "    \"\"\"\n",
    "    IOI(인접 note-on 간 시간차)를 박 격자(32/64분할)에 스냅했을 때\n",
    "    스텝 대비 오차의 P95를 계산해 추천 분해능을 반환.\n",
    "    \"\"\"\n",
    "    errs = {32: [], 64: []}\n",
    "    n_files = 0\n",
    "    for i, path in enumerate(files):\n",
    "        if limit and i >= limit:\n",
    "            break\n",
    "        pm = safe_load_midi(path)\n",
    "        if pm is None:\n",
    "            continue\n",
    "        n_files += 1\n",
    "        bp = median_beat_period(pm)  # one beat (quarter-note) seconds\n",
    "        starts = [n.start for n in all_notes(pm)]\n",
    "        if len(starts) < 2:\n",
    "            continue\n",
    "        iois = np.diff(sorted(starts))\n",
    "        for div in (32, 64):\n",
    "            step = bp / div  # seconds per sub-beat\n",
    "            x = iois / step  # 스텝 단위로 표시\n",
    "            frac_err = np.abs(x - np.round(x))  # 최근접 스텝과의 차이(스텝 단위)\n",
    "            errs[div].extend(frac_err.tolist())\n",
    "\n",
    "    rep = {}\n",
    "    for div in (32, 64):\n",
    "        if len(errs[div]) == 0:\n",
    "            rep[div] = np.nan\n",
    "        else:\n",
    "            rep[div] = float(np.percentile(errs[div], 95))  # P95 (스텝 단위, 0~0.5)\n",
    "    # 추천 규칙: P95 < 0.25 이면 해당 격자 OK. 둘 다 OK면 더 단순한 32를 채택.\n",
    "    if math.isnan(rep[32]) and math.isnan(rep[64]):\n",
    "        choice = None\n",
    "    elif (not math.isnan(rep[32]) and rep[32] <= 0.25) and (not math.isnan(rep[64]) and rep[64] <= 0.25):\n",
    "        choice = 32\n",
    "    elif (not math.isnan(rep[64]) and rep[64] <= 0.25):\n",
    "        choice = 64\n",
    "    else:\n",
    "        # 둘 다 크면 64가 상대적으로 유리(더 촘촘)\n",
    "        choice = 64\n",
    "\n",
    "    print(f\"[IOI 스냅 오차] P95(스텝 단위) → 32분할:{rep[32]:.3f}, 64분할:{rep[64]:.3f}  | 추천:{choice}\")\n",
    "    return {\"p95_32\": rep[32], \"p95_64\": rep[64], \"choice\": choice}\n",
    "\n",
    "# ---- (2) Velocity 분포 요약: IQR 기반 bin 추천 ----\n",
    "def velocity_report(files, limit=None):\n",
    "    vels = []\n",
    "    parsed = 0\n",
    "    for i, path in enumerate(files):\n",
    "        if limit and i >= limit:\n",
    "            break\n",
    "        pm = safe_load_midi(path)\n",
    "        if pm is None:\n",
    "            continue\n",
    "        parsed += 1\n",
    "        for n in all_notes(pm):\n",
    "            vels.append(n.velocity)\n",
    "    if len(vels) == 0:\n",
    "        print(\"[Velocity] 수집된 벨로시티가 없습니다.\")\n",
    "        return {\"iqr\": None, \"choice\": None}\n",
    "    v = np.array(vels, dtype=float)\n",
    "    q25, q75 = np.percentile(v, [25, 75])\n",
    "    iqr = float(q75 - q25)\n",
    "    # 추천 규칙: IQR < 20 → 8bin, 그 외엔 16bin\n",
    "    choice = 8 if iqr < 20 else 16\n",
    "    print(f\"[Velocity] IQR={iqr:.1f}  (Q25={q25:.1f}, Q75={q75:.1f})  | 추천 bin={choice}\")\n",
    "    return {\"iqr\": iqr, \"q25\": float(q25), \"q75\": float(q75), \"choice\": choice}\n",
    "\n",
    "# ---- (3) 반복률: 3–5그램 상위 점유율 & no-repeat 권고 ----\n",
    "def ngram_repetition_report(files, n_vals=(3,4,5), limit=None):\n",
    "    \"\"\"\n",
    "    간단 토큰열: (pitch, duration_bin) 시퀀스.\n",
    "    duration_bin은 한 박을 8등분한 스텝으로 반올림하여 사용.\n",
    "    전역 n-gram 카운트를 모아 상위 n-gram의 점유율을 계산.\n",
    "    \"\"\"\n",
    "    global_counts = {n: Counter() for n in n_vals}\n",
    "    total = {n: 0 for n in n_vals}\n",
    "\n",
    "    for i, path in enumerate(files):\n",
    "        if limit and i >= limit:\n",
    "            break\n",
    "        pm = safe_load_midi(path)\n",
    "        if pm is None:\n",
    "            continue\n",
    "        bp = median_beat_period(pm)\n",
    "        step = bp / 8.0  # 프레이즈 거칠게 보기: 1박 8분할\n",
    "        seq = []\n",
    "        for n in all_notes(pm):\n",
    "            dur_bin = int(round(max((n.end - n.start) / step, 0)))\n",
    "            dur_bin = min(dur_bin, 31)  # 과도한 길이는 클램프\n",
    "            seq.append((n.pitch, dur_bin))\n",
    "        if len(seq) == 0:\n",
    "            continue\n",
    "        # n-gram 생성\n",
    "        for n in n_vals:\n",
    "            if len(seq) < n:\n",
    "                continue\n",
    "            for j in range(len(seq) - n + 1):\n",
    "                tup = tuple(seq[j:j+n])\n",
    "                global_counts[n][tup] += 1\n",
    "                total[n] += 1\n",
    "\n",
    "    report = {}\n",
    "    for n in n_vals:\n",
    "        if total[n] == 0 or len(global_counts[n]) == 0:\n",
    "            report[n] = {\"top_ratio\": None, \"suggest\": None}\n",
    "            print(f\"[n={n}-gram] 데이터 부족\")\n",
    "            continue\n",
    "        top_ng, top_ct = global_counts[n].most_common(1)[0]\n",
    "        top_ratio = top_ct / total[n]\n",
    "        # 권고: 상위 n-gram 점유율이 2.5% 이상이면 no-repeat n-gram 적용\n",
    "        suggest = (f\"no_repeat_ngram_size={n}\" if top_ratio >= 0.025 else \"optional\")\n",
    "        print(f\"[n={n}-gram] 상위 점유율={top_ratio*100:.2f}%  | 권고: {suggest}\")\n",
    "        report[n] = {\"top_ratio\": top_ratio, \"suggest\": suggest}\n",
    "    return report\n",
    "\n",
    "# ---- 실행: 파일 목록을 넣어 한 번에 리포트 ----\n",
    "def run_added_eda(train_files, val_files, test_files, limit_per_split=None):\n",
    "    files = []\n",
    "    for L in (train_files, val_files, test_files):\n",
    "        files.extend(L[:limit_per_split] if limit_per_split else L)\n",
    "\n",
    "    print(\"파일 수:\", len(files))\n",
    "    out = {}\n",
    "    out[\"ioi\"] = ioi_snap_report(files)\n",
    "    out[\"vel\"] = velocity_report(files)\n",
    "    out[\"rep\"] = ngram_repetition_report(files)\n",
    "    print(\"\\n요약:\")\n",
    "    print(\" - TIME_SHIFT 추천:\", out['ioi']['choice'])\n",
    "    print(\" - Velocity bin 추천:\", out['vel']['choice'])\n",
    "    best_rep = max((v[\"top_ratio\"] for v in out[\"rep\"].values() if v[\"top_ratio\"] is not None), default=None)\n",
    "    if best_rep is not None and best_rep >= 0.025:\n",
    "        # 가장 강한 n-gram의 n을 찾아서 표시\n",
    "        pick_n = max(out[\"rep\"], key=lambda k: (out[\"rep\"][k][\"top_ratio\"] or -1))\n",
    "        print(f\" - 반복 억제 권고: {out['rep'][pick_n]['suggest']} (상위 점유율={out['rep'][pick_n]['top_ratio']*100:.2f}%)\")\n",
    "    else:\n",
    "        print(\" - 반복 억제: optional (강한 반복 패턴 증거 약함)\")\n",
    "    return out\n",
    "\n",
    "# 사용 예:\n",
    "# result = run_added_eda(train_files, val_files, test_files, limit_per_split=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ybnJT1tndAal",
    "outputId": "e9cff4c9-516a-4434-e55c-11ace6fac9c4"
   },
   "outputs": [],
   "source": [
    "result = run_added_eda(train_files, val_files, test_files, limit_per_split=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLqu4q99jwvj"
   },
   "source": [
    "### 토큰화\n",
    "- 이벤트 토큰 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ThayB1xIdHhJ",
    "outputId": "aaa8f57f-98bd-4810-8672-feecb5e70795"
   },
   "outputs": [],
   "source": [
    "# !pip -q install pretty_midi\n",
    "\n",
    "import math, os, json, hashlib\n",
    "import numpy as np\n",
    "import pretty_midi\n",
    "from collections import defaultdict\n",
    "\n",
    "# =======================\n",
    "# 0) 설정\n",
    "# =======================\n",
    "TS_DIV = 64          # 1박(quarter) 64분할\n",
    "VEL_BINS = 16        # velocity 0~127 → 16개 bin\n",
    "TS_MAX = 16          # 하나의 TS 토큰이 표현하는 최대 스텝(긴 간격은 여러 개로 쪼갬)\n",
    "PROGRAM = 0          # 피아노 (Acoustic Grand)\n",
    "\n",
    "# 특별 토큰 ID 고정\n",
    "PAD_ID = 0\n",
    "BOS_ID = 1\n",
    "EOS_ID = 2\n",
    "\n",
    "# NOTE/VEL/TS 토큰의 id 공간 시작점 (충돌 없게 순차 배치)\n",
    "# [PAD, BOS, EOS] 3개 예약 → id=3부터 본 토큰 시작\n",
    "VEL_BASE = 3                     # VEL_1 .. VEL_16 → 16개\n",
    "TS_BASE  = VEL_BASE + VEL_BINS   # TS_1 .. TS_16   → TS_MAX개\n",
    "NON_BASE = TS_BASE  + TS_MAX     # NOTE_ON_0 .. NOTE_ON_127\n",
    "NOFF_BASE= NON_BASE + 128        # NOTE_OFF_0 .. NOTE_OFF_127\n",
    "VOCAB_SIZE = NOFF_BASE + 128\n",
    "\n",
    "def vel_to_bin(v: int, bins: int = VEL_BINS):\n",
    "    # 0~127 → 1..bins (0은 거의 없다고 가정)\n",
    "    v = max(1, min(127, int(v)))\n",
    "    step = 128 / bins\n",
    "    b = int(math.ceil(v / step))\n",
    "    return max(1, min(bins, b))\n",
    "\n",
    "def bin_to_vel(b: int, bins: int = VEL_BINS):\n",
    "    # bin 번호의 \"중앙값\"으로 되돌림\n",
    "    step = 128 / bins\n",
    "    lo = int((b - 1) * step)\n",
    "    hi = int(b * step - 1)\n",
    "    return int((lo + hi) // 2)\n",
    "\n",
    "def beat_period_seconds(pm: pretty_midi.PrettyMIDI):\n",
    "    \"\"\"한 박(quarter-note) 길이(초). 비트가 있으면 beat 간격의 중앙값, 아니면 템포 기반.\"\"\"\n",
    "    beats = pm.get_beats()\n",
    "    if len(beats) >= 2:\n",
    "        return float(np.median(np.diff(beats)))\n",
    "    t, tempi = pm.get_tempo_changes()\n",
    "    if len(tempi):\n",
    "        return float(np.median(60.0 / tempi))\n",
    "    return 0.5  # fallback = 120bpm\n",
    "\n",
    "def _id_vel(b):          return VEL_BASE + (b - 1)          # 1..16 → VEL_BASE..VEL_BASE+15\n",
    "def _id_ts(k):           return TS_BASE  + (k - 1)          # 1..TS_MAX\n",
    "def _id_non(pitch):      return NON_BASE + pitch            # 0..127\n",
    "def _id_noff(pitch):     return NOFF_BASE + pitch           # 0..127\n",
    "def _is_vel(tok):        return VEL_BASE <= tok < VEL_BASE + VEL_BINS\n",
    "def _is_ts(tok):         return TS_BASE  <= tok < TS_BASE  + TS_MAX\n",
    "def _is_non(tok):        return NON_BASE <= tok < NON_BASE + 128\n",
    "def _is_noff(tok):       return NOFF_BASE<= tok < NOFF_BASE+ 128\n",
    "\n",
    "# =======================\n",
    "# 1) 토큰화 (MIDI → ids)\n",
    "# =======================\n",
    "def tokenize_midi(path, ts_div=TS_DIV, vel_bins=VEL_BINS, ts_max=TS_MAX):\n",
    "    \"\"\"\n",
    "    - 1박을 ts_div로 등분 (64)\n",
    "    - velocity를 vel_bins로 양자화 (16)\n",
    "    - 같은 타임스텝에 여러 NOTE_ON/NOTE_OFF 가능(폴리포니)\n",
    "    - 이벤트 순서: (필요한 TS들) → [VEL → NOTE_ON]* → [NOTE_OFF]*\n",
    "    반환: ids(list[int]), aux(dict: step_sec 등)\n",
    "    \"\"\"\n",
    "    pm = pretty_midi.PrettyMIDI(path)\n",
    "    bp = beat_period_seconds(pm)\n",
    "    step_sec = bp / ts_div\n",
    "\n",
    "    # 모든 노트 수집 (드럼 제외)\n",
    "    notes = []\n",
    "    for inst in pm.instruments:\n",
    "        if inst.is_drum:\n",
    "            continue\n",
    "        for n in inst.notes:\n",
    "            notes.append(n)\n",
    "    # 시작·끝 스냅(반올림)\n",
    "    for n in notes:\n",
    "        n._grid_start = int(round(n.start / step_sec))\n",
    "        n._grid_end   = max(n._grid_start + 1, int(round(n.end / step_sec)))  # 최소 1스텝은 유지\n",
    "\n",
    "    # 타임스텝별 버킷팅\n",
    "    bucket_on  = defaultdict(list)  # timestep → [(pitch, vel_bin), ...]\n",
    "    bucket_off = defaultdict(list)  # timestep → [pitch, ...]\n",
    "    for n in notes:\n",
    "        vb = vel_to_bin(n.velocity, vel_bins)\n",
    "        bucket_on[n._grid_start].append((n.pitch, vb))\n",
    "        bucket_off[n._grid_end].append(n.pitch)\n",
    "\n",
    "    # 시간 진행\n",
    "    tokens = [BOS_ID]\n",
    "    cur_t = 0\n",
    "    timeline = sorted(set(list(bucket_on.keys()) + list(bucket_off.keys())))\n",
    "    for t in timeline:\n",
    "        if t < cur_t:\n",
    "            continue\n",
    "        gap = t - cur_t\n",
    "        # gap을 TS 토큰으로 분해 (예: 17 → 16 + 1)\n",
    "        while gap > 0:\n",
    "            step = min(ts_max, gap)\n",
    "            tokens.append(_id_ts(step))\n",
    "            gap -= step\n",
    "        cur_t = t\n",
    "\n",
    "        # 동시 발음: pitch 오름차순, \"VEL → NOTE_ON\" 반복\n",
    "        if t in bucket_on:\n",
    "            for pitch, vb in sorted(bucket_on[t], key=lambda x: x[0]):\n",
    "                tokens.append(_id_vel(vb))\n",
    "                tokens.append(_id_non(pitch))\n",
    "\n",
    "        # NOTE_OFF는 같은 타임스텝에서 한 번에 방출 (pitch 오름차순)\n",
    "        if t in bucket_off:\n",
    "            for pitch in sorted(bucket_off[t]):\n",
    "                tokens.append(_id_noff(pitch))\n",
    "\n",
    "    tokens.append(EOS_ID)\n",
    "    aux = {\"step_sec\": step_sec, \"program\": PROGRAM, \"ts_div\": ts_div, \"vel_bins\": vel_bins, \"ts_max\": ts_max}\n",
    "    return tokens, aux\n",
    "\n",
    "# =======================\n",
    "# 2) 디토큰화 (ids → MIDI)\n",
    "# =======================\n",
    "def detokenize_to_pretty_midi(tokens, aux):\n",
    "    \"\"\"\n",
    "    - TS_k로 그리드 인덱스를 전진\n",
    "    - VEL_b → NOTE_ON_p 순서로 온음 생성 (현재 velocity 상태 반영)\n",
    "    - NOTE_OFF_p에서 해당 음 종료\n",
    "    - 남은 온음은 마지막 그리드 시점에서 정리\n",
    "    \"\"\"\n",
    "    step_sec = float(aux.get(\"step_sec\", 0.5/TS_DIV))  # 기본 120bpm\n",
    "    program  = int(aux.get(\"program\", PROGRAM))\n",
    "\n",
    "    pm = pretty_midi.PrettyMIDI()\n",
    "    inst = pretty_midi.Instrument(program=program, is_drum=False)\n",
    "    pm.instruments.append(inst)\n",
    "\n",
    "    cur_grid = 0\n",
    "    current_vel_bin = vel_to_bin(64, VEL_BINS)  # 초기값(중간 세기)\n",
    "    open_notes = {}  # pitch → start_time_sec\n",
    "\n",
    "    def grid_to_time(g): return g * step_sec\n",
    "\n",
    "    i = 0\n",
    "    N = len(tokens)\n",
    "    while i < N:\n",
    "        tok = tokens[i]\n",
    "        i += 1\n",
    "        if tok == BOS_ID:\n",
    "            continue\n",
    "        if tok == EOS_ID:\n",
    "            break\n",
    "\n",
    "        if _is_ts(tok):\n",
    "            k = (tok - TS_BASE) + 1\n",
    "            cur_grid += k\n",
    "            continue\n",
    "\n",
    "        if _is_vel(tok):\n",
    "            current_vel_bin = (tok - VEL_BASE) + 1\n",
    "            continue\n",
    "\n",
    "        if _is_non(tok):\n",
    "            pitch = (tok - NON_BASE)\n",
    "            # 같은 그리드에서 NOTE_ON이 연달아 나와도 허용\n",
    "            start = grid_to_time(cur_grid)\n",
    "            vel = bin_to_vel(current_vel_bin, VEL_BINS)\n",
    "            if pitch in open_notes:\n",
    "                # 이미 열려 있으면, 일단 닫고 다시 시작(비정상 케이스 방지)\n",
    "                inst.notes.append(pretty_midi.Note(\n",
    "                    velocity=bin_to_vel(current_vel_bin, VEL_BINS), pitch=pitch,\n",
    "                    start=open_notes[pitch], end=start + step_sec\n",
    "                ))\n",
    "            open_notes[pitch] = start\n",
    "            continue\n",
    "\n",
    "        if _is_noff(tok):\n",
    "            pitch = (tok - NOFF_BASE)\n",
    "            if pitch in open_notes:\n",
    "                start = open_notes.pop(pitch)\n",
    "                end = max(start + 1e-3, grid_to_time(cur_grid))  # 최소 길이 확보\n",
    "                vel = bin_to_vel(current_vel_bin, VEL_BINS)\n",
    "                inst.notes.append(pretty_midi.Note(velocity=vel, pitch=pitch, start=start, end=end))\n",
    "            # 열리지 않은 음에 대한 off는 무시\n",
    "            continue\n",
    "\n",
    "        # 알 수 없는 토큰은 무시\n",
    "\n",
    "    # 남은 음들 정리: 마지막 그리드 시점에서 최소 길이만큼 닫기\n",
    "    end_time = grid_to_time(cur_grid)\n",
    "    for pitch, st in list(open_notes.items()):\n",
    "        inst.notes.append(pretty_midi.Note(\n",
    "            velocity=bin_to_vel(current_vel_bin, VEL_BINS), pitch=pitch,\n",
    "            start=st, end=max(st + step_sec, end_time)\n",
    "        ))\n",
    "    return pm\n",
    "\n",
    "def detokenize_to_midi_file(tokens, aux, out_path):\n",
    "    pm = detokenize_to_pretty_midi(tokens, aux)\n",
    "    pm.write(out_path)\n",
    "    return out_path\n",
    "\n",
    "# =======================\n",
    "# 3) 간단 라운드트립 테스트/리포트\n",
    "# =======================\n",
    "def tokenize_and_reconstruct(path, out_midi_path=None):\n",
    "    \"\"\"\n",
    "    1) 토큰화 → 2) 디토큰 → 3) 원본/복원 길이, 이벤트 수 비교 리포트\n",
    "    \"\"\"\n",
    "    toks, aux = tokenize_midi(path)\n",
    "    pm_orig = pretty_midi.PrettyMIDI(path)\n",
    "    pm_recon = detokenize_to_pretty_midi(toks, aux)\n",
    "\n",
    "    dur_o = pm_orig.get_end_time()\n",
    "    dur_r = pm_recon.get_end_time()\n",
    "    cnt_o = sum(len(inst.notes) for inst in pm_orig.instruments if not inst.is_drum)\n",
    "    cnt_r = sum(len(inst.notes) for inst in pm_recon.instruments if not inst.is_drum)\n",
    "\n",
    "    report = {\n",
    "        \"tokens\": len(toks),\n",
    "        \"orig_duration\": dur_o,\n",
    "        \"recon_duration\": dur_r,\n",
    "        \"dur_rel_err_%\": (abs(dur_o - dur_r) / max(1e-6, dur_o)) * 100.0,\n",
    "        \"orig_events\": cnt_o,\n",
    "        \"recon_events\": cnt_r,\n",
    "        \"evt_rel_err_%\": (abs(cnt_o - cnt_r) / max(1, cnt_o)) * 100.0\n",
    "    }\n",
    "\n",
    "    if out_midi_path:\n",
    "        pm_recon.write(out_midi_path)\n",
    "        report[\"saved\"] = out_midi_path\n",
    "    return toks, aux, report\n",
    "\n",
    "print(\"VOCAB_SIZE:\", VOCAB_SIZE, \"| TS_DIV:\", TS_DIV, \"| VEL_BINS:\", VEL_BINS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v4n4ruNmj0fr",
    "outputId": "27859ce8-86af-4e42-89d3-440e9842508f"
   },
   "outputs": [],
   "source": [
    "# 예: train_files[0] 를 하나 집어 왕복 검증\n",
    "sample_path = train_files[0]\n",
    "tokens, aux, rep = tokenize_and_reconstruct(sample_path, out_midi_path=None)\n",
    "print(rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Idf-qIXHlMpS"
   },
   "source": [
    "### Dataset/DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rV_zQNZCj88V"
   },
   "outputs": [],
   "source": [
    "# 전제: 앞서 정의한 tokenize_midi()가 이미 세션에 존재한다고 가정합니다.\n",
    "# 필요시: from your_module import tokenize_midi\n",
    "\n",
    "import os, csv, json, math, hashlib, random, time\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import numpy as np\n",
    "import pretty_midi\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# =========================\n",
    "# 설정(필요시 수정)\n",
    "# =========================\n",
    "PAD_ID = 0\n",
    "BOS_ID = 1\n",
    "EOS_ID = 2\n",
    "\n",
    "# 토큰화 규칙 버전(캐시 구분용): 토큰 규칙 바뀌면 꼭 바꿔주세요.\n",
    "TOKEN_RULE_VERSION = \"evt_ts64_vel16_tsm16_v1\"\n",
    "\n",
    "# 필터 규칙(권장 기본)\n",
    "MIN_EVENTS = 200          # 너무 짧은 곡 제외\n",
    "MAX_DENSITY = 10.0        # events/sec 상한\n",
    "MIN_DURATION_SEC = 30.0   # 30초 미만 제외\n",
    "\n",
    "# 캐시/로그 디렉토리\n",
    "PROJ = \"/content/drive/MyDrive/Deep_Learning_project/original_token\"\n",
    "CACHE_DIR = f\"{PROJ}/data/processed\"\n",
    "LOG_DIR   = f\"{PROJ}/logs\"\n",
    "REPORT_DIR= f\"{PROJ}/reports\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "os.makedirs(REPORT_DIR, exist_ok=True)\n",
    "\n",
    "FILTER_REPORT_CSV = f\"{LOG_DIR}/filter_report.csv\"\n",
    "\n",
    "# =========================\n",
    "# 유틸\n",
    "# =========================\n",
    "def sha1_text(s: str) -> str:\n",
    "    return hashlib.sha1(s.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "def safe_midi_stats(path: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    필터 판단을 위한 빠른 통계: duration, events(#notes), density.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pm = pretty_midi.PrettyMIDI(path)\n",
    "        duration = pm.get_end_time()\n",
    "        events = sum(len(inst.notes) for inst in pm.instruments if not inst.is_drum)\n",
    "        density = (events / max(1e-6, duration)) if duration > 0 else float(\"inf\")\n",
    "        return {\"ok\": True, \"duration\": duration, \"events\": events, \"density\": density}\n",
    "    except Exception as e:\n",
    "        return {\"ok\": False, \"error\": str(e)}\n",
    "\n",
    "def cache_paths_for(midipath: str) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    캐시 파일 경로: .npy(토큰), .json(aux)\n",
    "    캐시 키 = sha1(토큰규칙버전 + 절대경로 + 최종수정시각)\n",
    "    \"\"\"\n",
    "    p = Path(midipath)\n",
    "    stat = p.stat()\n",
    "    key_src = f\"{TOKEN_RULE_VERSION}|{str(p.resolve())}|{stat.st_mtime_ns}\"\n",
    "    key = sha1_text(key_src)\n",
    "    npy_path = os.path.join(CACHE_DIR, f\"{key}.npy\")\n",
    "    js_path  = os.path.join(CACHE_DIR, f\"{key}.json\")\n",
    "    return npy_path, js_path\n",
    "\n",
    "def load_or_tokenize(midipath: str):\n",
    "    \"\"\"\n",
    "    캐시가 있으면 로드, 없으면 토큰화 후 저장.\n",
    "    반환: (tokens: np.ndarray[int], aux: dict)\n",
    "    \"\"\"\n",
    "    npy_path, js_path = cache_paths_for(midipath)\n",
    "    if os.path.exists(npy_path) and os.path.exists(js_path):\n",
    "        toks = np.load(npy_path)\n",
    "        with open(js_path, \"r\") as f:\n",
    "            aux = json.load(f)\n",
    "        return toks, aux, True  # from_cache=True\n",
    "\n",
    "    # 캐시 없음 → 토큰화\n",
    "    tokens, aux = tokenize_midi(midipath)  # 앞서 제공한 함수 사용\n",
    "    tokens = np.asarray(tokens, dtype=np.int32)\n",
    "\n",
    "    # 저장\n",
    "    np.save(npy_path, tokens)\n",
    "    with open(js_path, \"w\") as f:\n",
    "        json.dump(aux, f)\n",
    "\n",
    "    return tokens, aux, False\n",
    "\n",
    "def append_filter_report(rows: List[Dict[str, Any]]):\n",
    "    \"\"\"\n",
    "    제외된 파일/사유를 CSV로 기록.\n",
    "    \"\"\"\n",
    "    write_header = not os.path.exists(FILTER_REPORT_CSV)\n",
    "    with open(FILTER_REPORT_CSV, \"a\", newline=\"\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=[\"path\", \"reason\", \"duration\", \"events\", \"density\", \"error\"])\n",
    "        if write_header:\n",
    "            w.writeheader()\n",
    "        for r in rows:\n",
    "            w.writerow(r)\n",
    "\n",
    "# =========================\n",
    "# Dataset\n",
    "# =========================\n",
    "class MidiTokenDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 paths: List[str],\n",
    "                 max_len: int = 512,\n",
    "                 pad_id: int = PAD_ID,\n",
    "                 apply_filters: bool = True,\n",
    "                 seed: int = 42):\n",
    "        \"\"\"\n",
    "        paths: MIDI 파일 경로 리스트\n",
    "        max_len: Truncated BPTT 창 길이\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.paths_all = list(paths)\n",
    "        self.max_len = int(max_len)\n",
    "        self.pad_id = int(pad_id)\n",
    "        self.rng = random.Random(seed)\n",
    "\n",
    "        # 1) 필터(선택)\n",
    "        self.paths = []\n",
    "        filtered_rows = []\n",
    "        if apply_filters:\n",
    "            for p in self.paths_all:\n",
    "                st = safe_midi_stats(p)\n",
    "                if not st[\"ok\"]:\n",
    "                    filtered_rows.append({\"path\": p, \"reason\": \"parse_error\",\n",
    "                                          \"duration\": None, \"events\": None, \"density\": None,\n",
    "                                          \"error\": st.get(\"error\")})\n",
    "                    continue\n",
    "                if st[\"events\"] < MIN_EVENTS:\n",
    "                    filtered_rows.append({\"path\": p, \"reason\": \"too_few_events\",\n",
    "                                          \"duration\": st[\"duration\"], \"events\": st[\"events\"],\n",
    "                                          \"density\": st[\"density\"], \"error\": None})\n",
    "                    continue\n",
    "                if st[\"duration\"] < MIN_DURATION_SEC:\n",
    "                    filtered_rows.append({\"path\": p, \"reason\": \"too_short_duration\",\n",
    "                                          \"duration\": st[\"duration\"], \"events\": st[\"events\"],\n",
    "                                          \"density\": st[\"density\"], \"error\": None})\n",
    "                    continue\n",
    "                if st[\"density\"] > MAX_DENSITY:\n",
    "                    filtered_rows.append({\"path\": p, \"reason\": \"too_high_density\",\n",
    "                                          \"duration\": st[\"duration\"], \"events\": st[\"events\"],\n",
    "                                          \"density\": st[\"density\"], \"error\": None})\n",
    "                    continue\n",
    "                # 통과\n",
    "                self.paths.append(p)\n",
    "        else:\n",
    "            self.paths = self.paths_all\n",
    "\n",
    "        # 로그 기록\n",
    "        if filtered_rows:\n",
    "            append_filter_report(filtered_rows)\n",
    "\n",
    "        if len(self.paths) == 0:\n",
    "            raise RuntimeError(\"유효한 학습 샘플이 없습니다. 필터 기준을 조정하세요.\")\n",
    "\n",
    "        # 2) 각 파일의 토큰 길이 메타(빠른 슬라이싱을 위해)\n",
    "        #    (캐시가 없으면 생성하면서 길이 파악)\n",
    "        self.lengths = []\n",
    "        t0 = time.time()\n",
    "        for p in self.paths:\n",
    "            toks, aux, from_cache = load_or_tokenize(p)\n",
    "            self.lengths.append(int(len(toks)))\n",
    "        t1 = time.time()\n",
    "        print(f\"[MidiTokenDataset] 캐시/토큰 길이 준비 완료: {len(self.paths)}개, {t1-t0:.1f}s\")\n",
    "\n",
    "    def __len__(self):\n",
    "        # 샘플 = \"파일 단위\"가 아니라 \"슬라이스 단위\"로 보려면 IterableDataset 설계가 필요하지만,\n",
    "        # 여기선 간단히 파일 단위로 두고, __getitem__에서 무작위 슬라이스를 뽑습니다.\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        toks, aux, _ = load_or_tokenize(path)\n",
    "        L = len(toks)\n",
    "\n",
    "        # 최소 길이: BOS, ..., EOS → 학습 시 x=t[:-1], y=t[1:]\n",
    "        if L < 2:\n",
    "            # 빈에 가까운 곡이면, 아주 짧은 더미 반환(필터에서 걸러지는 게 일반적)\n",
    "            x = np.array([BOS_ID], dtype=np.int64)\n",
    "            y = np.array([EOS_ID], dtype=np.int64)\n",
    "            mask = np.array([1], dtype=np.int64)\n",
    "            return torch.from_numpy(x), torch.from_numpy(y), torch.from_numpy(mask)\n",
    "\n",
    "        # Truncated BPTT: max_len+1 창을 랜덤 연속 슬라이스로 선택\n",
    "        T = self.max_len + 1\n",
    "        if L <= T:\n",
    "            slice_tokens = toks  # 짧으면 전체 사용\n",
    "        else:\n",
    "            start = self.rng.randint(0, L - T)\n",
    "            slice_tokens = toks[start:start+T]\n",
    "\n",
    "        # x, y 분리\n",
    "        x = slice_tokens[:-1].astype(np.int64)\n",
    "        y = slice_tokens[1: ].astype(np.int64)\n",
    "\n",
    "        # 아직 패딩 전(개별 시퀀스) → collate에서 패딩\n",
    "        return torch.from_numpy(x), torch.from_numpy(y), torch.tensor(1, dtype=torch.int64)  # dummy mask flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUy3plKrlpYL"
   },
   "outputs": [],
   "source": [
    "def collate_pad(batch, pad_id: int = PAD_ID):\n",
    "    \"\"\"\n",
    "    batch: list of (x, y, _)\n",
    "    - 동적 패딩: 배치 내 최장 길이에 맞춰 PAD 채움\n",
    "    - 마스크: (x != PAD)\n",
    "    반환: xpad, ypad, mask  (shape: [B, T])\n",
    "    \"\"\"\n",
    "    xs, ys, _ = zip(*batch)\n",
    "    lens = [len(x) for x in xs]\n",
    "    T = max(lens)\n",
    "    B = len(xs)\n",
    "\n",
    "    xpad = torch.full((B, T), pad_id, dtype=torch.long)\n",
    "    ypad = torch.full((B, T), pad_id, dtype=torch.long)\n",
    "\n",
    "    for i, (x, y) in enumerate(zip(xs, ys)):\n",
    "        t = len(x)\n",
    "        xpad[i, :t] = x\n",
    "        ypad[i, :t] = y\n",
    "\n",
    "    mask = (xpad != pad_id).to(torch.bool)\n",
    "    return xpad, ypad, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SuA4hcLDlr1o",
    "outputId": "5b3aa1e1-e747-4d1a-e8ff-7b19cf1ab3a7"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 예: 앞서 만든 리스트\n",
    "# train_files, val_files, test_files\n",
    "\n",
    "max_len = 512\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = MidiTokenDataset(train_files, max_len=max_len, apply_filters=True, seed=42)\n",
    "val_ds   = MidiTokenDataset(val_files,   max_len=max_len, apply_filters=True, seed=43)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
    "                      num_workers=2, pin_memory=True, collate_fn=lambda b: collate_pad(b, PAD_ID))\n",
    "\n",
    "val_dl   = DataLoader(val_ds, batch_size=batch_size, shuffle=False,\n",
    "                      num_workers=2, pin_memory=True, collate_fn=lambda b: collate_pad(b, PAD_ID))\n",
    "\n",
    "xb, yb, mb = next(iter(train_dl))\n",
    "xb.shape, yb.shape, mb.shape, xb.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OjBQdUl4lvle",
    "outputId": "0b72a6b1-8ee7-4fe8-86a7-733e80ff8508"
   },
   "outputs": [],
   "source": [
    "import os, json, numpy as np, pandas as pd, torch, time\n",
    "from collections import Counter\n",
    "\n",
    "# 0) 환경 요약\n",
    "print(\"CUDA:\", torch.cuda.is_available(), \"| device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 1) split 파일/경로 확인\n",
    "print(\"\\n[split CSV 확인]\")\n",
    "for name, df in [(\"train\", train_df), (\"val\", val_df), (\"test\", test_df)]:\n",
    "    print(f\"{name:<5} rows={len(df):4d},  has_full_path={df['full_path'].notna().sum():4d}\")\n",
    "\n",
    "# 2) 캐시 디렉토리 요약\n",
    "print(\"\\n[캐시 파일 요약]\")\n",
    "cache_dir = CACHE_DIR  # 당신이 설정한 CACHE_DIR 사용\n",
    "n_npy = len([f for f in os.listdir(cache_dir) if f.endswith(\".npy\")])\n",
    "n_js  = len([f for f in os.listdir(cache_dir) if f.endswith(\".json\")])\n",
    "print(\"CACHE_DIR:\", cache_dir)\n",
    "print(\"npy:\", n_npy, \"json:\", n_js)\n",
    "\n",
    "# 3) 토큰 길이 통계(샘플 200곡)\n",
    "print(\"\\n[토큰 길이 통계 (샘플)]\")\n",
    "sample_files = (train_files[:100] + val_files[:50] + test_files[:50])[:200]\n",
    "lens = []\n",
    "t0=time.time()\n",
    "for p in sample_files:\n",
    "    toks, aux, from_cache = load_or_tokenize(p)\n",
    "    lens.append(len(toks))\n",
    "print(f\"샘플 {len(lens)}개, 로드 {time.time()-t0:.1f}s  |  P50={np.percentile(lens,50):.0f}, P95={np.percentile(lens,95):.0f}, MAX={np.max(lens)}\")\n",
    "\n",
    "# 4) DataLoader 배치 무결성\n",
    "print(\"\\n[DataLoader 배치 무결성]\")\n",
    "xb, yb, mb = next(iter(train_dl))\n",
    "print(\"xb/yb/mb shapes:\", xb.shape, yb.shape, mb.shape, \"| dtype:\", xb.dtype)\n",
    "assert xb.shape == yb.shape == mb.shape, \"배치 텐서 shape 불일치\"\n",
    "assert xb.dtype == torch.long, \"토큰 dtype은 torch.long이어야 합니다\"\n",
    "pad_id = PAD_ID\n",
    "pad_frac = (xb==pad_id).float().mean().item()\n",
    "print(f\"PAD 비율(배치 평균): {pad_frac*100:.1f}%\")\n",
    "\n",
    "# 5) 라운드트립(토큰화↔복원) 빠른 점검 3곡\n",
    "print(\"\\n[라운드트립 테스트 3곡]\")\n",
    "from random import sample\n",
    "for p in sample(train_files, k=min(3,len(train_files))):\n",
    "    _, aux, rep = tokenize_and_reconstruct(p, out_midi_path=None)\n",
    "    print(os.path.basename(p), \"| dur_err%={:.2f}, evt_err%={:.2f}, tokens={}\".format(\n",
    "        rep[\"dur_rel_err_%\"], rep[\"evt_rel_err_%\"], rep[\"tokens\"]))\n",
    "\n",
    "# 6) 간단 손실계산 드라이런(모델 없이 mask/ignore 논리 확인)\n",
    "print(\"\\n[ignore_index 논리 점검]\")\n",
    "ce = torch.nn.CrossEntropyLoss(ignore_index=pad_id, reduction=\"mean\")\n",
    "# vocab_size는 당신의 VOCAB_SIZE 변수 사용\n",
    "vocab_size = VOCAB_SIZE\n",
    "with torch.no_grad():\n",
    "    # 가짜 로짓: [B,T,V]\n",
    "    logits = torch.randn(xb.size(0), xb.size(1), vocab_size)\n",
    "    loss = ce(logits.view(-1, vocab_size), yb.reshape(-1))\n",
    "print(\"dummy CE(loss, ignore PAD) =\", float(loss))\n",
    "\n",
    "print(\"\\n[요약]\")\n",
    "print(\"- split CSV/파일 경로 OK\")\n",
    "print(\"- 캐시 파일 개수:\", n_npy, \"(npy) /\", n_js, \"(json)\")\n",
    "print(\"- DataLoader 배치/마스크 OK, PAD ignore CE OK\")\n",
    "print(\"- 라운드트립 dur/evt 오차가 매우 크면 토큰화 규칙 재점검 필요\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJ6PaGngTWVu"
   },
   "source": [
    "## 모델링 (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UCyAq40UTYnx"
   },
   "outputs": [],
   "source": [
    "# ===== 하이퍼파라미터/경로 =====\n",
    "import os, math, csv, time, random\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# 기본 경로 (필요시 수정)\n",
    "PROJ = \"/content/drive/MyDrive/Deep_Learning_project/original_token\"\n",
    "CKPT_DIR   = f\"{PROJ}/ckpt\"\n",
    "LOG_DIR    = f\"{PROJ}/logs\"\n",
    "SAMPLES_DIR= f\"{PROJ}/samples\"\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "os.makedirs(SAMPLES_DIR, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 필수 토큰 상수 (없을 때의 안전 장치)\n",
    "try: PAD_ID\n",
    "except NameError: PAD_ID = 0\n",
    "try: BOS_ID\n",
    "except NameError: BOS_ID = 1\n",
    "try: EOS_ID\n",
    "except NameError: EOS_ID = 2\n",
    "try: VOCAB_SIZE\n",
    "except NameError: VOCAB_SIZE = 3 + 16 + 16 + 128 + 128  # 폴백\n",
    "\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    vocab_size: int = VOCAB_SIZE\n",
    "    pad_id: int = PAD_ID\n",
    "    d_model: int = 512\n",
    "    lstm_hidden: int = 768\n",
    "    lstm_layers: int = 2\n",
    "    dropout: float = 0.25\n",
    "    max_len: int = 512\n",
    "    lr: float = 3e-4\n",
    "    weight_decay: float = 0.01\n",
    "    grad_clip: float = 1.0\n",
    "    epochs: int = 100\n",
    "    log_every: int = 200\n",
    "    val_every: int = 1000\n",
    "    amp: bool = True\n",
    "    seed: int = 42\n",
    "cfg = TrainConfig()\n",
    "\n",
    "# ===== 모델 정의 =====\n",
    "class EventLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=512, hidden=768, layers=2, dropout=0.2, pad_id=0):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, d_model, padding_idx=pad_id)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=d_model,\n",
    "            hidden_size=hidden,\n",
    "            num_layers=layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(hidden)\n",
    "        self.head = nn.Linear(hidden, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        x = self.embed(x)\n",
    "        x = self.dropout(x)\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = self.norm(out)\n",
    "        logits = self.head(out)\n",
    "        return logits, hidden\n",
    "\n",
    "# ===== 유틸 =====\n",
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def perplexity(nll):\n",
    "    try: return math.exp(nll)\n",
    "    except OverflowError: return float(\"inf\")\n",
    "\n",
    "def save_checkpoint(model, opt, scaler, step, path):\n",
    "    torch.save({\n",
    "        \"model\": model.state_dict(),\n",
    "        \"opt\": opt.state_dict(),\n",
    "        \"scaler\": scaler.state_dict() if scaler is not None else None,\n",
    "        \"step\": step\n",
    "    }, path)\n",
    "\n",
    "def sample_and_save(model, start_token=BOS_ID, max_tokens=1024, temperature=1.0, top_k: Optional[int]=50,\n",
    "                    out_midi_path: Optional[str]=None, aux_for_detok: Optional[dict]=None):\n",
    "    model.eval()\n",
    "    toks = [start_token]\n",
    "    hidden = None\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_tokens-1):\n",
    "            x = torch.tensor(toks[-cfg.max_len:], dtype=torch.long, device=device).unsqueeze(0)\n",
    "            logits, hidden = model(x, hidden=None)\n",
    "            logits = logits[:, -1, :] / max(1e-6, temperature)\n",
    "            if top_k is not None and top_k > 0:\n",
    "                topv, topi = torch.topk(logits, k=min(top_k, logits.size(-1)), dim=-1)\n",
    "                probs = torch.softmax(topv, dim=-1)\n",
    "                idx = topi.gather(-1, torch.multinomial(probs, num_samples=1))\n",
    "                next_id = int(idx.item())\n",
    "            else:\n",
    "                probs = torch.softmax(logits, dim=-1)\n",
    "                next_id = int(torch.multinomial(probs, num_samples=1).item())\n",
    "            toks.append(next_id)\n",
    "            if next_id == EOS_ID:\n",
    "                break\n",
    "    if out_midi_path is not None and aux_for_detok is not None:\n",
    "        try: detokenize_to_midi_file(toks, aux_for_detok, out_midi_path)\n",
    "        except Exception as e: print(\"[WARN] detokenize failed:\", e)\n",
    "    return toks\n",
    "\n",
    "# ===== 학습/검증 루프 =====\n",
    "def train_one_epoch(model, dl, opt, scheduler, scaler, ce, step0=0,\n",
    "                    log_path=f\"{LOG_DIR}/train_val_curve.csv\"):\n",
    "    model.train()  # 매 epoch 시작 시 학습 모드 보장\n",
    "    running_loss, step = 0.0, step0\n",
    "    t0 = time.time()\n",
    "\n",
    "    for xb, yb, mb in dl:\n",
    "        xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "\n",
    "        if cfg.amp:\n",
    "            with autocast():\n",
    "                logits, _ = model(xb)\n",
    "                loss = ce(logits.reshape(-1, cfg.vocab_size), yb.reshape(-1))\n",
    "            # backward\n",
    "            scaler.scale(loss).backward()\n",
    "            if cfg.grad_clip is not None:\n",
    "                scaler.unscale_(opt)\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            logits, _ = model(xb)\n",
    "            loss = ce(logits.reshape(-1, cfg.vocab_size), yb.reshape(-1))\n",
    "            loss.backward()\n",
    "            if cfg.grad_clip is not None:\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)\n",
    "            opt.step()\n",
    "\n",
    "        # ✅ 스케줄러는 항상 optimizer.step() 이후\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        step += 1\n",
    "        running_loss += float(loss.item())\n",
    "\n",
    "        # 로깅\n",
    "        if step % cfg.log_every == 0:\n",
    "            avg_nll = running_loss / cfg.log_every\n",
    "            ppl = perplexity(avg_nll)\n",
    "            print(f\"[train] step {step}  nll={avg_nll:.3f}  ppl={ppl:.1f}  ({time.time()-t0:.1f}s)\")\n",
    "            append_log(log_path, {\"step\": step, \"split\": \"train\", \"nll\": avg_nll, \"ppl\": ppl})\n",
    "            running_loss = 0.0\n",
    "\n",
    "        # 중간 검증\n",
    "        if step % cfg.val_every == 0:\n",
    "            nll, ppl = evaluate(model, val_dl)  # evaluate 내부에서 model.eval()\n",
    "            print(f\"[val]   step {step}  nll={nll:.3f}  ppl={ppl:.1f}\")\n",
    "            append_log(log_path, {\"step\": step, \"split\": \"val\", \"nll\": nll, \"ppl\": ppl})\n",
    "\n",
    "            # (옵션) 샘플 저장\n",
    "            aux = {\"step_sec\": 0.5/64, \"program\": 0}\n",
    "            out_mid = os.path.join(SAMPLES_DIR, f\"step{step}_sample.mid\")\n",
    "            _ = sample_and_save(model, out_midi_path=out_mid, aux_for_detok=aux)\n",
    "\n",
    "            model.train()  # 🔑 아주 중요: 평가 후 반드시 학습 모드로 복귀\n",
    "    return step\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, dl):\n",
    "    model.eval()\n",
    "    ce = nn.CrossEntropyLoss(ignore_index=cfg.pad_id, reduction=\"mean\")\n",
    "    total_loss, total_tokens = 0.0, 0\n",
    "    for xb, yb, mb in dl:\n",
    "        xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
    "        logits, _ = model(xb)\n",
    "        loss = ce(logits.reshape(-1, cfg.vocab_size), yb.reshape(-1))\n",
    "        total_loss += float(loss.item()) * xb.size(0)\n",
    "        total_tokens += xb.size(0)\n",
    "    nll = total_loss / max(1, total_tokens)\n",
    "    ppl = perplexity(nll)\n",
    "    return nll, ppl\n",
    "\n",
    "def append_log(csv_path, row: dict):\n",
    "    write_header = not os.path.exists(csv_path)\n",
    "    with open(csv_path, \"a\", newline=\"\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=[\"step\", \"split\", \"nll\", \"ppl\"])\n",
    "        if write_header: w.writeheader()\n",
    "        w.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P2E_DgmueUlk",
    "outputId": "11a5c569-e95b-4fb5-9867-6d894ddfe5a7"
   },
   "outputs": [],
   "source": [
    "# ===== 실제 실행 =====\n",
    "torch.manual_seed(cfg.seed)\n",
    "random.seed(cfg.seed)\n",
    "\n",
    "model = EventLSTM(\n",
    "    vocab_size=cfg.vocab_size,\n",
    "    d_model=cfg.d_model,\n",
    "    hidden=cfg.lstm_hidden,\n",
    "    layers=cfg.lstm_layers,\n",
    "    dropout=cfg.dropout,\n",
    "    pad_id=cfg.pad_id\n",
    ").to(device)\n",
    "\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "\n",
    "# ✅ 스케줄러 추가 (Cosine, T_max는 \"총 스텝 수\" 기준)\n",
    "steps_per_epoch = len(train_dl)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=max(1, cfg.epochs * steps_per_epoch))\n",
    "\n",
    "# 기존 AMP도 그대로 사용 가능 (경고는 떠도 동작 OK)\n",
    "scaler = GradScaler(enabled=cfg.amp)\n",
    "ce = nn.CrossEntropyLoss(ignore_index=cfg.pad_id, reduction=\"mean\")\n",
    "\n",
    "print(f\"Model params: {count_params(model)/1e6:.2f}M\")\n",
    "print(f\"steps/epoch: {steps_per_epoch}\")\n",
    "\n",
    "global_step = 0\n",
    "for ep in range(1, cfg.epochs+1):\n",
    "    print(f\"\\n=== EPOCH {ep}/{cfg.epochs} ===\")\n",
    "    # ✅ 스케줄러를 train_one_epoch에 인자로 전달\n",
    "    global_step = train_one_epoch(model, train_dl, opt, scheduler, scaler, ce, step0=global_step)\n",
    "\n",
    "    # 에폭 끝 검증 + 체크포인트\n",
    "    nll, ppl = evaluate(model, val_dl)\n",
    "    print(f\"[val @epoch{ep}] nll={nll:.3f}  ppl={ppl:.1f}\")\n",
    "    append_log(f\"{LOG_DIR}/train_val_curve.csv\",\n",
    "               {\"step\": global_step, \"split\": f\"val_ep{ep}\", \"nll\": nll, \"ppl\": ppl})\n",
    "    save_checkpoint(model, opt, scaler, global_step,\n",
    "                    os.path.join(CKPT_DIR, f\"lstm_ep{ep}_step{global_step}.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCR06MdV0YQ3"
   },
   "source": [
    "### 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114
    },
    "id": "Lbbl3iGueZ8r",
    "outputId": "b820086a-9550-494a-d564-de59e69abbc4"
   },
   "outputs": [],
   "source": [
    "# 2) 샘플 토큰 → MIDI → WAV → 재생\n",
    "from IPython.display import Audio, display\n",
    "import tempfile, os\n",
    "from midi2audio import FluidSynth\n",
    "\n",
    "toks = sample_and_save(\n",
    "    model,\n",
    "    start_token=BOS_ID,\n",
    "    max_tokens=512,\n",
    "    temperature=1.0,\n",
    "    top_k=50,\n",
    "    out_midi_path=None, # 여기서는 저장하지 않고 토큰만 받음\n",
    "    aux_for_detok={\"step_sec\": 0.5/64, \"program\": 0}\n",
    ")\n",
    "\n",
    "# 저장할 파일 경로 지정 (SAMPLES_DIR 사용)\n",
    "sample_idx = int(time.time()) # 파일명 충돌 방지를 위해 타임스탬프 사용\n",
    "out_mid_path = os.path.join(SAMPLES_DIR, f\"generated_sample_{sample_idx}.mid\")\n",
    "out_wav_path = out_mid_path.replace(\".mid\", \".wav\")\n",
    "\n",
    "\n",
    "detokenize_to_midi_file(toks, {\"step_sec\": 0.5/64, \"program\": 0}, out_mid_path)\n",
    "\n",
    "sf2_path = \"/usr/share/sounds/sf2/FluidR3_GM.sf2\"\n",
    "fs = FluidSynth(sf2_path)\n",
    "fs.midi_to_audio(out_mid_path, out_wav_path)\n",
    "\n",
    "display(Audio(out_wav_path))\n",
    "print(\"MIDI:\", out_mid_path, \"| WAV:\", out_wav_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gE_HhigNqO0R",
    "outputId": "a8b79177-2eda-47d5-96cd-5e7bdc87c947"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "def _read_log_safe(log_path):\n",
    "    if not os.path.exists(log_path):\n",
    "        raise FileNotFoundError(f\"로그 파일을 찾을 수 없습니다: {log_path}\")\n",
    "    # 잘못된 행 스킵, 파이썬 엔진 사용\n",
    "    df = pd.read_csv(\n",
    "        log_path,\n",
    "        engine=\"python\",\n",
    "        on_bad_lines=\"skip\"\n",
    "    )\n",
    "    # 필요한 컬럼만 남기기 (여분 헤더/깨진 행 제거)\n",
    "    keep = [c for c in [\"step\", \"split\", \"nll\", \"ppl\"] if c in df.columns]\n",
    "    df = df[keep]\n",
    "    # 숫자형 강제 변환\n",
    "    if \"step\" in df.columns:\n",
    "        df[\"step\"] = pd.to_numeric(df[\"step\"], errors=\"coerce\")\n",
    "    if \"nll\" in df.columns:\n",
    "        df[\"nll\"] = pd.to_numeric(df[\"nll\"], errors=\"coerce\")\n",
    "    if \"ppl\" in df.columns:\n",
    "        df[\"ppl\"] = pd.to_numeric(df[\"ppl\"], errors=\"coerce\")\n",
    "    # 유효한 행만\n",
    "    df = df.dropna(subset=[\"step\", \"split\", \"nll\", \"ppl\"])\n",
    "    # step 정렬\n",
    "    df = df.sort_values(\"step\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def plot_training_curves(log_path=f\"{LOG_DIR}/train_val_curve.csv\", save_path=None):\n",
    "    df = _read_log_safe(log_path)\n",
    "\n",
    "    train_data = df[df['split'] == 'train']\n",
    "    val_data   = df[df['split'].str.contains('val', na=False)]\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('LSTM Music Generation Training Results', fontsize=16, fontweight='bold')\n",
    "\n",
    "    # 1) NLL\n",
    "    ax1 = axes[0, 0]\n",
    "    if len(train_data): ax1.plot(train_data['step'], train_data['nll'], 'b-', label='Train NLL', alpha=0.7, linewidth=1)\n",
    "    if len(val_data):   ax1.plot(val_data['step'],   val_data['nll'],   'r-', label='Validation NLL', linewidth=2)\n",
    "    ax1.set_xlabel('Training Steps'); ax1.set_ylabel('NLL'); ax1.set_title('Loss Curve (NLL)')\n",
    "    ax1.legend(); ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # 2) PPL\n",
    "    ax2 = axes[0, 1]\n",
    "    if len(train_data): ax2.plot(train_data['step'], train_data['ppl'], 'b-', label='Train PPL', alpha=0.7, linewidth=1)\n",
    "    if len(val_data):   ax2.plot(val_data['step'],   val_data['ppl'],   'r-', label='Validation PPL', linewidth=2)\n",
    "    ax2.set_xlabel('Training Steps'); ax2.set_ylabel('Perplexity'); ax2.set_title('Perplexity Curve')\n",
    "    ax2.legend(); ax2.grid(True, alpha=0.3); ax2.set_yscale('log')\n",
    "\n",
    "    # 3) Epoch-wise validation (raw string으로 정규식)\n",
    "    ax3 = axes[1, 0]\n",
    "    epoch_val_data = df[df['split'].str.contains('val_ep', na=False)].copy()\n",
    "    if len(epoch_val_data):\n",
    "        epoch_val_data['epoch'] = epoch_val_data['split'].str.extract(r'val_ep(\\d+)').astype(int)\n",
    "        epoch_val_data = epoch_val_data.sort_values('epoch')\n",
    "        ax3.plot(epoch_val_data['epoch'], epoch_val_data['nll'], 'ro-', label='Val NLL', linewidth=2, markersize=6)\n",
    "        ax3_twin = ax3.twinx()\n",
    "        ax3_twin.plot(epoch_val_data['epoch'], epoch_val_data['ppl'], 'go-', label='Val PPL', linewidth=2, markersize=6)\n",
    "        ax3.set_xlabel('Epoch'); ax3.set_ylabel('Validation NLL', color='red')\n",
    "        ax3_twin.set_ylabel('Validation Perplexity', color='green')\n",
    "        ax3.set_title('Epoch-wise Validation Performance'); ax3.grid(True, alpha=0.3)\n",
    "\n",
    "    # 4) 최근 10 에폭 PPL\n",
    "    ax4 = axes[1, 1]\n",
    "    if len(epoch_val_data):\n",
    "        recent = epoch_val_data.tail(10)\n",
    "        x = np.arange(len(recent))\n",
    "        bars = ax4.bar(x, recent['ppl'], alpha=0.7, color='skyblue', edgecolor='navy')\n",
    "        ax4.set_xlabel('Recent Epochs'); ax4.set_ylabel('Perplexity')\n",
    "        ax4.set_title('Recent Validation Perplexity (Last 10 Epochs)')\n",
    "        ax4.set_xticks(x); ax4.set_xticklabels(recent['epoch'], rotation=45)\n",
    "        for bar, v in zip(bars, recent['ppl']):\n",
    "            ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, f'{v:.1f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path is None:\n",
    "        save_path = os.path.join(LOG_DIR, 'training_curves.png')\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"그래프가 저장되었습니다: {save_path}\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_detailed_analysis(log_path=f\"{LOG_DIR}/train_val_curve.csv\"):\n",
    "    df = _read_log_safe(log_path)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Detailed Training Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "    # 1) 이동평균 손실\n",
    "    ax1 = axes[0, 0]\n",
    "    train_data = df[df['split'] == 'train']\n",
    "    val_data   = df[df['split'].str.contains('val', na=False)]\n",
    "    if len(train_data):\n",
    "        window = max(1, len(train_data) // 20)\n",
    "        smooth = train_data['nll'].rolling(window=window, center=True).mean()\n",
    "        ax1.plot(train_data['step'], smooth, 'b-', linewidth=2, label=f'Train NLL (MA-{window})')\n",
    "        ax1.plot(train_data['step'], train_data['nll'], 'b-', alpha=0.3, linewidth=0.5)\n",
    "    if len(val_data):\n",
    "        ax1.plot(val_data['step'], val_data['nll'], 'r-', linewidth=2, label='Validation NLL')\n",
    "    ax1.set_xlabel('Training Steps'); ax1.set_ylabel('NLL'); ax1.set_title('Loss Convergence (with Moving Average)')\n",
    "    ax1.legend(); ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # 2) Val PPL 분포\n",
    "    ax2 = axes[0, 1]\n",
    "    val_only = df[df['split'].str.contains('val', na=False)]\n",
    "    if len(val_only):\n",
    "        ax2.hist(val_only['ppl'], bins=20, alpha=0.7, color='red', edgecolor='black')\n",
    "        ax2.axvline(val_only['ppl'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {val_only[\"ppl\"].mean():.1f}')\n",
    "        ax2.axvline(val_only['ppl'].median(), color='orange', linestyle='--', linewidth=2, label=f'Median: {val_only[\"ppl\"].median():.1f}')\n",
    "    ax2.set_xlabel('Perplexity'); ax2.set_ylabel('Frequency'); ax2.set_title('Validation Perplexity Distribution')\n",
    "    ax2.legend(); ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    # 3) 에폭별 개선률\n",
    "    ax3 = axes[1, 0]\n",
    "    epoch_val = df[df['split'].str.contains('val_ep', na=False)].copy()\n",
    "    if len(epoch_val):\n",
    "        epoch_val['epoch'] = epoch_val['split'].str.extract(r'val_ep(\\d+)').astype(int)\n",
    "        epoch_val = epoch_val.sort_values('epoch')\n",
    "        epoch_val['ppl_impr'] = epoch_val['ppl'].diff()\n",
    "        ax3.bar(epoch_val['epoch'][1:], epoch_val['ppl_impr'][1:], alpha=0.7, color='green')\n",
    "        ax3.axhline(0, color='black', linestyle='-', alpha=0.5)\n",
    "        ax3.set_xlabel('Epoch'); ax3.set_ylabel('Perplexity Change'); ax3.set_title('Epoch-wise Perplexity Improvement')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "\n",
    "    # 4) 학습 안정성\n",
    "    ax4 = axes[1, 1]\n",
    "    if len(train_data) > 10:\n",
    "        group_size = max(1, len(train_data) // 10)\n",
    "        groups = [train_data['nll'].iloc[i:i+group_size] for i in range(0, len(train_data), group_size)]\n",
    "        stds = [g.std() for g in groups if len(g) > 1]\n",
    "        xs = [i * group_size for i in range(len(stds))]\n",
    "        ax4.plot(xs, stds, 'bo-', linewidth=2, markersize=6)\n",
    "        ax4.set_xlabel('Training Steps (Grouped)'); ax4.set_ylabel('NLL Std'); ax4.set_title('Training Stability (Loss Variance)')\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"=== 학습 곡선 시각화 ===\")\n",
    "plot_training_curves()\n",
    "\n",
    "print(\"\\n=== 상세 분석 ===\")\n",
    "plot_detailed_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6z1KrVUYuB2"
   },
   "source": [
    "## 모델링 (2)\n",
    "- 어텐션 (o)\n",
    "- 계층적 구조 (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iJtpr-5Yx4YZ",
    "outputId": "0dda667a-3cf5-4351-9188-522f1b473fc6"
   },
   "outputs": [],
   "source": [
    "# ===== 개선버전: LSTM(+Attention) 실험 프레임 (Colab-ready) =====\n",
    "import os, math, csv, time, json, random, itertools\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Dict, Any, List, Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# ========== 경로/디바이스 ==========\n",
    "PROJ = \"/content/drive/MyDrive/Deep_Learning_project/original_token\"\n",
    "CKPT_DIR    = f\"{PROJ}/ckpt\"\n",
    "LOG_DIR     = f\"{PROJ}/logs\"\n",
    "SAMPLES_DIR = f\"{PROJ}/samples\"\n",
    "RESULTS_DIR = f\"{PROJ}/results\"\n",
    "for d in [CKPT_DIR, LOG_DIR, SAMPLES_DIR, RESULTS_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ===== 필수 토큰 상수 (폴백) =====\n",
    "try: PAD_ID\n",
    "except NameError: PAD_ID = 0\n",
    "try: BOS_ID\n",
    "except NameError: BOS_ID = 1\n",
    "try: EOS_ID\n",
    "except NameError: EOS_ID = 2\n",
    "try: VOCAB_SIZE\n",
    "except NameError: VOCAB_SIZE = 3 + 16 + 16 + 128 + 128  # PAD/BOS/EOS + VEL(16) + TS(16) + ON(128) + OFF(128)\n",
    "\n",
    "# ========== 설정 ==========\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    vocab_size: int = VOCAB_SIZE\n",
    "    pad_id: int = PAD_ID\n",
    "    d_model: int = 512\n",
    "    lstm_hidden: int = 768\n",
    "    lstm_layers: int = 2\n",
    "    max_len: int = 512\n",
    "\n",
    "    # lr/opt\n",
    "    lr: float = 3e-4\n",
    "    weight_decay: float = 0.01\n",
    "    epochs: int = 50\n",
    "    grad_clip: float = 1.0\n",
    "    amp: bool = True\n",
    "\n",
    "    # logging\n",
    "    log_every: int = 200\n",
    "    val_every: int = 1000\n",
    "    seed: int = 42\n",
    "\n",
    "    # dropout (분리)\n",
    "    dropout_emb: float = 0.1\n",
    "    dropout_lstm: float = 0.25\n",
    "    dropout_attn: float = 0.1\n",
    "    dropout_ffn: float = 0.1\n",
    "\n",
    "    # Attention 옵션\n",
    "    use_attention: bool = False\n",
    "    num_attention_heads: int = 8\n",
    "\n",
    "    # 랜덤 서치\n",
    "    n_trials: int = 6   # 실험 개수 (시간 절약용 소수)\n",
    "    # 샘플링\n",
    "    default_temperature: float = 1.0\n",
    "    default_top_k: int = 50\n",
    "    default_top_p: float = 0.0\n",
    "    default_no_repeat_ngram: int = 0\n",
    "\n",
    "cfg = TrainConfig()\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "set_seed(cfg.seed)\n",
    "\n",
    "# ========== 모델 ==========\n",
    "class EventLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=512, hidden=768, layers=2,\n",
    "                 dropout_emb=0.1, dropout_lstm=0.25, pad_id=0):\n",
    "        super().__init__()\n",
    "        self.use_attention = False\n",
    "        self.embed = nn.Embedding(vocab_size, d_model, padding_idx=pad_id)\n",
    "        self.drop_emb = nn.Dropout(dropout_emb)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=d_model, hidden_size=hidden, num_layers=layers,\n",
    "            batch_first=True, dropout=dropout_lstm if layers > 1 else 0.0\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(hidden)\n",
    "        self.drop_out = nn.Dropout(dropout_lstm)\n",
    "        self.head = nn.Linear(hidden, vocab_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, hidden: Optional[Tuple[torch.Tensor,torch.Tensor]]=None):\n",
    "        # x: (B, T)\n",
    "        x = self.drop_emb(self.embed(x))      # (B,T,d_model)\n",
    "        out, hidden = self.lstm(x, hidden)    # (B,T,H)\n",
    "        out = self.drop_out(self.norm(out))   # (B,T,H)\n",
    "        logits = self.head(out)               # (B,T,V)\n",
    "        return logits, hidden\n",
    "\n",
    "class EventLSTMWithAttention(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=512, hidden=768, layers=2,\n",
    "                 dropout_emb=0.1, dropout_lstm=0.25,\n",
    "                 num_heads=8, dropout_attn=0.1, dropout_ffn=0.1, pad_id=0):\n",
    "        super().__init__()\n",
    "        self.use_attention = True\n",
    "        self.embed = nn.Embedding(vocab_size, d_model, padding_idx=pad_id)\n",
    "        self.drop_emb = nn.Dropout(dropout_emb)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=d_model, hidden_size=hidden, num_layers=layers,\n",
    "            batch_first=True, dropout=dropout_lstm if layers > 1 else 0.0\n",
    "        )\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=hidden, num_heads=num_heads,\n",
    "                                          dropout=dropout_attn, batch_first=True)\n",
    "        self.dropout_attn = nn.Dropout(dropout_attn)\n",
    "        self.dropout_ffn  = nn.Dropout(dropout_ffn)\n",
    "\n",
    "        # Transformer-style: (Attn -> Residual+Norm) then (FFN -> Residual+Norm)\n",
    "        self.norm1 = nn.LayerNorm(hidden)\n",
    "        self.norm2 = nn.LayerNorm(hidden)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(hidden, 4*hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4*hidden, hidden)\n",
    "        )\n",
    "        self.head = nn.Linear(hidden, vocab_size)\n",
    "\n",
    "    def _causal_mask(self, T: int, device):\n",
    "        # True=mask (차단). 2D (T,T) boolean mask\n",
    "        return torch.triu(torch.ones(T, T, dtype=torch.bool, device=device), diagonal=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, hidden: Optional[Tuple[torch.Tensor,torch.Tensor]]=None):\n",
    "        # x: (B,T)\n",
    "        x = self.drop_emb(self.embed(x))            # (B,T,d_model)\n",
    "        lstm_out, hidden = self.lstm(x, hidden)     # (B,T,H)\n",
    "\n",
    "        T = lstm_out.size(1)\n",
    "        attn_mask = self._causal_mask(T, lstm_out.device)  # (T,T) boolean\n",
    "\n",
    "        attn_out, _ = self.attn(lstm_out, lstm_out, lstm_out, attn_mask=attn_mask)  # (B,T,H)\n",
    "        y = self.norm1(lstm_out + self.dropout_attn(attn_out))                      # (B,T,H)\n",
    "\n",
    "        ffn_out = self.ffn(y)                                   # (B,T,H)\n",
    "        y = self.norm2(y + self.dropout_ffn(ffn_out))           # (B,T,H)\n",
    "\n",
    "        logits = self.head(y)                                   # (B,T,V)\n",
    "        return logits, hidden\n",
    "\n",
    "# ========== 유틸 ==========\n",
    "def count_params(model): return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def perplexity(nll):\n",
    "    try:\n",
    "        return math.exp(nll)\n",
    "    except OverflowError:\n",
    "        return float(\"inf\")\n",
    "\n",
    "def save_checkpoint(model, opt, scaler, step, path):\n",
    "    torch.save({\n",
    "        \"model\": model.state_dict(),\n",
    "        \"opt\": opt.state_dict(),\n",
    "        \"scaler\": scaler.state_dict() if scaler is not None else None,\n",
    "        \"step\": step\n",
    "    }, path)\n",
    "\n",
    "# nucleus(top-p) & top-k & no-repeat-ngram\n",
    "def _apply_sampling_filters(logits: torch.Tensor, top_k: int=0, top_p: float=0.0) -> torch.Tensor:\n",
    "    # logits: (V,)\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "\n",
    "    # top-k\n",
    "    if top_k and top_k > 0 and top_k < probs.numel():\n",
    "        topv, topi = torch.topk(probs, k=top_k)\n",
    "        filtered = torch.full_like(probs, 0.0)\n",
    "        filtered.scatter_(0, topi, topv)\n",
    "        probs = filtered\n",
    "\n",
    "    # top-p (nucleus)\n",
    "    if top_p and 0.0 < top_p < 1.0:\n",
    "        sorted_probs, sorted_idx = torch.sort(probs, descending=True)\n",
    "        cumsum = torch.cumsum(sorted_probs, dim=-1)\n",
    "        mask = cumsum > top_p\n",
    "        # keep first element even if > top_p (to ensure at least one token)\n",
    "        mask[0] = False\n",
    "        sorted_probs[mask] = 0.0\n",
    "        probs = torch.zeros_like(probs)\n",
    "        probs.scatter_(0, sorted_idx, sorted_probs)\n",
    "\n",
    "    # renormalize\n",
    "    s = probs.sum()\n",
    "    if s.item() > 0:\n",
    "        probs = probs / s\n",
    "    else:\n",
    "        # fallback to uniform if all zero\n",
    "        probs = torch.full_like(probs, 1.0 / probs.numel())\n",
    "\n",
    "    return probs\n",
    "\n",
    "def _forbidden_next_tokens_by_ngram(prefix: List[int], n: int) -> set:\n",
    "    \"\"\"prefix 내에서 길이 n의 n-gram이 이미 나타난 경우,\n",
    "       현재 마지막 (n-1)-gram 뒤에 올 수 있는 금지 토큰 집합을 반환\"\"\"\n",
    "    if n <= 1 or len(prefix) < n-1:\n",
    "        return set()\n",
    "    mapping = {}\n",
    "    for i in range(len(prefix)-n+1):\n",
    "        key = tuple(prefix[i:i+n-1])\n",
    "        nxt = prefix[i+n-1]\n",
    "        mapping.setdefault(key, set()).add(nxt)\n",
    "    key = tuple(prefix[-(n-1):])\n",
    "    return mapping.get(key, set())\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample_and_save(model, start_token=BOS_ID, max_tokens=1024,\n",
    "                    temperature: float=1.0, top_k: Optional[int]=50, top_p: float=0.0,\n",
    "                    no_repeat_ngram_size: int=0,\n",
    "                    out_midi_path: Optional[str]=None, aux_for_detok: Optional[dict]=None):\n",
    "    model.eval()\n",
    "    toks: List[int] = [start_token]\n",
    "    hidden = None\n",
    "\n",
    "    for _ in range(max_tokens-1):\n",
    "        if getattr(model, \"use_attention\", False):\n",
    "            # 어텐션 사용하는 경우: 프리픽스 전체 재계산(정확성 우선)\n",
    "            x = torch.tensor(toks[-cfg.max_len:], dtype=torch.long, device=device).unsqueeze(0)\n",
    "            logits, hidden = model(x, hidden=None)\n",
    "            last = logits[:, -1, :].squeeze(0)  # (V,)\n",
    "        else:\n",
    "            # LSTM-only: 1토큰씩 hidden carry (효율)\n",
    "            x = torch.tensor([[toks[-1]]], dtype=torch.long, device=device)\n",
    "            logits, hidden = model(x, hidden)\n",
    "            last = logits.squeeze(0).squeeze(0)  # (V,)\n",
    "\n",
    "        last = last / max(1e-6, temperature)\n",
    "\n",
    "        # n-gram 금지 토큰 마스킹\n",
    "        if no_repeat_ngram_size and no_repeat_ngram_size > 1:\n",
    "            forbids = _forbidden_next_tokens_by_ngram(toks, no_repeat_ngram_size)\n",
    "        else:\n",
    "            forbids = set()\n",
    "\n",
    "        # 필터링(top-k, top-p)\n",
    "        probs = _apply_sampling_filters(last, top_k=top_k or 0, top_p=top_p)\n",
    "\n",
    "        if forbids:\n",
    "            probs[list(forbids)] = 0.0\n",
    "            s = probs.sum()\n",
    "            probs = probs / s if s.item() > 0 else torch.full_like(probs, 1.0 / probs.numel())\n",
    "\n",
    "        next_id = int(torch.multinomial(probs, num_samples=1).item())\n",
    "        toks.append(next_id)\n",
    "        if next_id == EOS_ID:\n",
    "            break\n",
    "\n",
    "    if out_midi_path is not None and aux_for_detok is not None:\n",
    "        try:\n",
    "            detokenize_to_midi_file(toks, aux_for_detok, out_midi_path)\n",
    "        except Exception as e:\n",
    "            print(\"[WARN] detokenize failed:\", e)\n",
    "\n",
    "    return toks\n",
    "\n",
    "# ========== 학습/검증 루프 ==========\n",
    "def append_log(csv_path, row: Dict[str, Any]):\n",
    "    write_header = not os.path.exists(csv_path)\n",
    "    with open(csv_path, \"a\", newline=\"\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=[\"step\", \"split\", \"nll\", \"ppl\"])\n",
    "        if write_header: w.writeheader()\n",
    "        w.writerow(row)\n",
    "\n",
    "def train_one_epoch(model, dl, opt, scheduler, scaler, ce, step0=0, log_path=f\"{LOG_DIR}/train_val_curve.csv\",\n",
    "                    val_dl=None):\n",
    "    model.train()\n",
    "    running_loss, step = 0.0, step0\n",
    "    t0 = time.time()\n",
    "\n",
    "    for xb, yb, mb in dl:\n",
    "        xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "\n",
    "        if cfg.amp:\n",
    "            with autocast():\n",
    "                logits, _ = model(xb)\n",
    "                loss = ce(logits.reshape(-1, cfg.vocab_size), yb.reshape(-1))\n",
    "            scaler.scale(loss).backward()\n",
    "            if cfg.grad_clip is not None:\n",
    "                scaler.unscale_(opt)\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            logits, _ = model(xb)\n",
    "            loss = ce(logits.reshape(-1, cfg.vocab_size), yb.reshape(-1))\n",
    "            loss.backward()\n",
    "            if cfg.grad_clip is not None:\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), cfg.grad_clip)\n",
    "            opt.step()\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        step += 1\n",
    "        running_loss += float(loss.item())\n",
    "\n",
    "        if step % cfg.log_every == 0:\n",
    "            avg_nll = running_loss / cfg.log_every\n",
    "            ppl = perplexity(avg_nll)\n",
    "            print(f\"[train] step {step}  nll={avg_nll:.3f}  ppl={ppl:.1f}  ({time.time()-t0:.1f}s)\")\n",
    "            append_log(log_path, {\"step\": step, \"split\": \"train\", \"nll\": avg_nll, \"ppl\": ppl})\n",
    "            running_loss = 0.0\n",
    "\n",
    "        if (val_dl is not None) and (step % cfg.val_every == 0):\n",
    "            nll, ppl = evaluate(model, val_dl)\n",
    "            print(f\"[val]   step {step}  nll={nll:.3f}  ppl={ppl:.1f}\")\n",
    "            append_log(log_path, {\"step\": step, \"split\": \"val\", \"nll\": nll, \"ppl\": ppl})\n",
    "            model.train()\n",
    "    return step\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, dl):\n",
    "    model.eval()\n",
    "    ce = nn.CrossEntropyLoss(ignore_index=cfg.pad_id, reduction=\"none\")\n",
    "    total_loss, total_tokens = 0.0, 0\n",
    "\n",
    "    for xb, yb, mb in dl:\n",
    "        xb, yb = xb.to(device, non_blocking=True), yb.to(device, non_blocking=True)\n",
    "        logits, _ = model(xb)  # (B,T,V)\n",
    "        V = cfg.vocab_size\n",
    "        loss_vec = ce(logits.reshape(-1, V), yb.reshape(-1))  # (B*T,)\n",
    "        mask = (yb.reshape(-1) != cfg.pad_id)\n",
    "        total_loss += float(loss_vec[mask].sum().item())\n",
    "        total_tokens += int(mask.sum().item())\n",
    "\n",
    "    nll = total_loss / max(1, total_tokens)\n",
    "    ppl = perplexity(nll)\n",
    "    return nll, ppl\n",
    "\n",
    "# ========== 랜덤 서치 ==========\n",
    "def sample_config_space() -> Dict[str, Any]:\n",
    "    return {\n",
    "        \"use_attention\": random.choice([False, True]),\n",
    "        \"num_attention_heads\": random.choice([4, 8, 16]),\n",
    "        \"lr\": random.choice([1e-4, 3e-4, 1e-3]),\n",
    "        \"weight_decay\": random.choice([0.01, 0.1, 0.5]),\n",
    "        \"dropout_emb\": random.choice([0.05, 0.1, 0.2]),\n",
    "        \"dropout_lstm\": random.choice([0.2, 0.25, 0.3]),\n",
    "        \"dropout_attn\": random.choice([0.05, 0.1, 0.2]),\n",
    "        \"dropout_ffn\": random.choice([0.05, 0.1, 0.2]),\n",
    "    }\n",
    "\n",
    "def build_model_from_cfg() -> nn.Module:\n",
    "    if cfg.use_attention:\n",
    "        model = EventLSTMWithAttention(\n",
    "            vocab_size=cfg.vocab_size,\n",
    "            d_model=cfg.d_model,\n",
    "            hidden=cfg.lstm_hidden,\n",
    "            layers=cfg.lstm_layers,\n",
    "            dropout_emb=cfg.dropout_emb,\n",
    "            dropout_lstm=cfg.dropout_lstm,\n",
    "            num_heads=cfg.num_attention_heads,\n",
    "            dropout_attn=cfg.dropout_attn,\n",
    "            dropout_ffn=cfg.dropout_ffn,\n",
    "            pad_id=cfg.pad_id\n",
    "        ).to(device)\n",
    "    else:\n",
    "        model = EventLSTM(\n",
    "            vocab_size=cfg.vocab_size,\n",
    "            d_model=cfg.d_model,\n",
    "            hidden=cfg.lstm_hidden,\n",
    "            layers=cfg.lstm_layers,\n",
    "            dropout_emb=cfg.dropout_emb,\n",
    "            dropout_lstm=cfg.dropout_lstm,\n",
    "            pad_id=cfg.pad_id\n",
    "        ).to(device)\n",
    "    return model\n",
    "\n",
    "def run_random_search(train_dl, val_dl, n_trials: int = None):\n",
    "    n_trials = n_trials or cfg.n_trials\n",
    "    results = []\n",
    "    best_perplexity = float(\"inf\")\n",
    "    best_config = None\n",
    "\n",
    "    print(f\"총 {n_trials}개 랜덤 서치를 실행합니다...\")\n",
    "\n",
    "    for i in range(1, n_trials+1):\n",
    "        # 샘플 설정\n",
    "        conf = sample_config_space()\n",
    "        # 어텐션 off일 때도 헤드/attn 드롭아웃 값은 유지하지만 사용 안 함(무시)\n",
    "        cfg.use_attention     = conf[\"use_attention\"]\n",
    "        cfg.num_attention_heads = conf[\"num_attention_heads\"]\n",
    "        cfg.lr               = conf[\"lr\"]\n",
    "        cfg.weight_decay     = conf[\"weight_decay\"]\n",
    "        cfg.dropout_emb      = conf[\"dropout_emb\"]\n",
    "        cfg.dropout_lstm     = conf[\"dropout_lstm\"]\n",
    "        cfg.dropout_attn     = conf[\"dropout_attn\"]\n",
    "        cfg.dropout_ffn      = conf[\"dropout_ffn\"]\n",
    "\n",
    "        print(f\"\\n=== 실험 {i}/{n_trials} ===\")\n",
    "        print(f\"설정: {conf}\")\n",
    "\n",
    "        set_seed(cfg.seed + i)  # 실험별 시드 변이\n",
    "        model = build_model_from_cfg()\n",
    "        print(f\"모델 파라미터: {count_params(model)/1e6:.2f}M\")\n",
    "\n",
    "        opt = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "        steps_per_epoch = max(1, len(train_dl))\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=max(1, cfg.epochs * steps_per_epoch))\n",
    "        scaler = GradScaler(enabled=cfg.amp)\n",
    "        ce = nn.CrossEntropyLoss(ignore_index=cfg.pad_id, reduction=\"mean\")\n",
    "\n",
    "        global_step = 0\n",
    "        best_val_ppl = float(\"inf\")\n",
    "\n",
    "        for ep in range(1, cfg.epochs + 1):\n",
    "            global_step = train_one_epoch(model, train_dl, opt, scheduler, scaler, ce, step0=global_step, val_dl=val_dl)\n",
    "            nll, ppl = evaluate(model, val_dl)\n",
    "            print(f\"[val @epoch{ep}] nll={nll:.3f}  ppl={ppl:.2f}\")\n",
    "            if ppl < best_val_ppl:\n",
    "                best_val_ppl = ppl\n",
    "\n",
    "        results.append({\n",
    "            \"config\": conf,\n",
    "            \"best_val_perplexity\": float(best_val_ppl),\n",
    "            \"model_params\": int(count_params(model)),\n",
    "            \"experiment_id\": i\n",
    "        })\n",
    "        print(f\"최고 검증 Perplexity: {best_val_ppl:.2f}\")\n",
    "\n",
    "        if best_val_ppl < best_perplexity:\n",
    "            best_perplexity = best_val_ppl\n",
    "            best_config = conf\n",
    "            print(f\"★ 새로운 최고 성능! Perplexity: {best_perplexity:.2f}\")\n",
    "\n",
    "    results_file = f\"{RESULTS_DIR}/random_search_results.json\"\n",
    "    with open(results_file, \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "\n",
    "    print(\"\\n=== 랜덤 서치 완료 ===\")\n",
    "    print(f\"총 {len(results)}개 실험 완료\")\n",
    "    print(f\"최고 성능: Perplexity {best_perplexity:.2f}\")\n",
    "    print(f\"최고 설정: {best_config}\")\n",
    "    print(f\"결과 저장: {results_file}\")\n",
    "\n",
    "    analyze_results(results)\n",
    "    return results, best_config\n",
    "\n",
    "def analyze_results(results: List[Dict[str,Any]]):\n",
    "    print(\"\\n=== 결과 분석 ===\")\n",
    "    attn = [r for r in results if r[\"config\"][\"use_attention\"]]\n",
    "    base = [r for r in results if not r[\"config\"][\"use_attention\"]]\n",
    "    if attn and base:\n",
    "        avg_attn = sum(r[\"best_val_perplexity\"] for r in attn) / len(attn)\n",
    "        avg_base = sum(r[\"best_val_perplexity\"] for r in base) / len(base)\n",
    "        imp = (avg_base - avg_attn) / max(1e-9, avg_base) * 100.0\n",
    "        print(f\"Baseline 평균 PPL: {avg_base:.2f}\")\n",
    "        print(f\"Attention 평균 PPL: {avg_attn:.2f}\")\n",
    "        print(f\"개선율: {imp:.1f}%\")\n",
    "\n",
    "    top5 = sorted(results, key=lambda x: x[\"best_val_perplexity\"])[:5]\n",
    "    print(\"\\n상위 5개 결과:\")\n",
    "    for i, r in enumerate(top5, 1):\n",
    "        print(f\"{i}. PPL {r['best_val_perplexity']:.2f}  | 설정: {r['config']}\")\n",
    "\n",
    "# ========== 메인 ==========\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"🔥 LSTM 업그레이드 1차: Attention + 랜덤 서치\")\n",
    "    print(f\"디바이스: {device}\")\n",
    "    print(f\"VOCAB_SIZE: {VOCAB_SIZE}\")\n",
    "    # NOTE: train_dl / val_dl 은 사전에 준비되어 있어야 합니다.\n",
    "    # 예) train_dl, val_dl = ...\n",
    "    results, best_config = run_random_search(train_dl, val_dl, n_trials=cfg.n_trials)\n",
    "\n",
    "    # 샘플 생성 예시\n",
    "    # sample_and_save(model, start_token=BOS_ID, max_tokens=1024,\n",
    "    #                 temperature=cfg.default_temperature, top_k=cfg.default_top_k,\n",
    "    #                 top_p=cfg.default_top_p, no_repeat_ngram_size=cfg.default_no_repeat_ngram,\n",
    "    #                 out_midi_path=f\"{SAMPLES_DIR}/sample.mid\", aux_for_detok=aux_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gbhGkSzUaEeQ",
    "outputId": "bcc46148-b886-4472-c962-9d99623db530"
   },
   "outputs": [],
   "source": [
    "# === 베스트 설정으로 단일 학습 → 베스트 가중치 저장/로드 → 샘플 생성/재생 (Colab-ready) ===\n",
    "import os, json, time\n",
    "from IPython.display import Audio, display\n",
    "from midi2audio import FluidSynth\n",
    "import torch\n",
    "from torch.cuda.amp import GradScaler\n",
    "import torch.nn as nn\n",
    "\n",
    "# 경로\n",
    "PROJ = \"/content/drive/MyDrive/Deep_Learning_project/original_token\"\n",
    "CKPT_DIR = f\"{PROJ}/ckpt\"\n",
    "RESULTS_JSON = f\"{PROJ}/results/random_search_results.json\"\n",
    "SAMPLES_DIR = f\"{PROJ}/samples\"\n",
    "\n",
    "\n",
    "BEST_CKPT_PATH = f\"{CKPT_DIR}/best_model.pt\"\n",
    "\n",
    "\n",
    "# 0) best_config 확보: 우선 변수, 없으면 results.json에서 최저 PPL 항목 자동 선택\n",
    "try:\n",
    "    best_config  # 이미 변수로 존재하는 경우\n",
    "except NameError:\n",
    "    with open(RESULTS_JSON, \"r\") as f:\n",
    "        results = json.load(f)\n",
    "    best_row = min(results, key=lambda r: r[\"best_val_perplexity\"])\n",
    "    best_config = best_row[\"config\"]\n",
    "print(\"[best_config]\", best_config)\n",
    "\n",
    "# 1) cfg 적용\n",
    "cfg.use_attention       = best_config['use_attention']\n",
    "cfg.num_attention_heads = best_config['num_attention_heads']\n",
    "cfg.lr                  = best_config['lr']\n",
    "cfg.weight_decay        = best_config['weight_decay']\n",
    "cfg.dropout_emb         = best_config['dropout_emb']\n",
    "cfg.dropout_lstm        = best_config['dropout_lstm']\n",
    "cfg.dropout_attn        = best_config['dropout_attn']\n",
    "cfg.dropout_ffn         = best_config['dropout_ffn']\n",
    "\n",
    "# 2) 모델 생성\n",
    "best_model = build_model_from_cfg()\n",
    "opt = torch.optim.AdamW(best_model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "steps_per_epoch = max(1, len(train_dl))\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=max(1, cfg.epochs * steps_per_epoch))\n",
    "scaler = GradScaler(enabled=cfg.amp)\n",
    "ce = nn.CrossEntropyLoss(ignore_index=cfg.pad_id, reduction=\"mean\")\n",
    "\n",
    "# 3) 단일 학습 루프 + 최고 PPL 가중치만 저장\n",
    "best_val_ppl = float(\"inf\")\n",
    "global_step = 0\n",
    "for ep in range(1, cfg.epochs + 1):\n",
    "    global_step = train_one_epoch(best_model, train_dl, opt, scheduler, scaler, ce, step0=global_step, val_dl=val_dl)\n",
    "    nll, ppl = evaluate(best_model, val_dl)\n",
    "    print(f\"[single-train @epoch{ep}] nll={nll:.3f}  ppl={ppl:.2f}\")\n",
    "    if ppl < best_val_ppl:\n",
    "        best_val_ppl = ppl\n",
    "        torch.save(best_model.state_dict(), BEST_CKPT_PATH)\n",
    "        print(f\"✔ 베스트 갱신: PPL={best_val_ppl:.2f}  → 저장: {BEST_CKPT_PATH}\")\n",
    "\n",
    "# 4) 가장 좋은 가중치 로드(안전)\n",
    "best_model.load_state_dict(torch.load(BEST_CKPT_PATH, map_location=device))\n",
    "best_model.eval()\n",
    "print(\"✅ 베스트 모델 준비 완료\")\n",
    "\n",
    "# 5) 토큰 생성 → MIDI/WAV 저장 → 재생 (여러 샘플)\n",
    "import random\n",
    "\n",
    "# 생성 설정\n",
    "N_SAMPLES = 3\n",
    "temps = [0.9, 1.0, 1.1]              # 다양성 확보용 (개수 < N이면 순환 사용)\n",
    "topks = [50, 64, 32]                 # top-k도 살짝 바꿔서 컬러 다변화\n",
    "program = 0                          # GM Acoustic Grand Piano\n",
    "aux_base = {\"step_sec\": 0.5/64, \"program\": program}  # 학습 설정과 일치 필요\n",
    "sf2 = \"/usr/share/sounds/sf2/FluidR3_GM.sf2\"        # Colab 기본 SoundFont 경로\n",
    "\n",
    "os.makedirs(SAMPLES_DIR, exist_ok=True)\n",
    "\n",
    "def generate_one(idx, temperature, top_k, seed=None):\n",
    "    if seed is None:\n",
    "        seed = int(time.time()) + idx * 1234567\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    # 5-1) 토큰 샘플링\n",
    "    toks = sample_and_save(\n",
    "        best_model,\n",
    "        start_token=BOS_ID,\n",
    "        max_tokens=512,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        out_midi_path=None,                 # 직접 detokenize 할거라 None\n",
    "        aux_for_detok=aux_base\n",
    "    )\n",
    "\n",
    "    # 5-2) 파일 경로 준비\n",
    "    tag = f\"t{temperature:.1f}_k{top_k}_s{seed % 100000}\"\n",
    "    mid = os.path.join(SAMPLES_DIR, f\"best_{int(time.time())}_{idx+1}_{tag}.mid\")\n",
    "    wav = mid.replace(\".mid\", \".wav\")\n",
    "\n",
    "    # 5-3) detokenize (BOS/PAD 제거)\n",
    "    toks = [t for t in toks if t not in (PAD_ID, BOS_ID)]\n",
    "    detokenize_to_midi_file(toks, aux_base, mid)\n",
    "\n",
    "    # 5-4) WAV 변환 & 재생\n",
    "    FluidSynth(sf2).midi_to_audio(mid, wav)\n",
    "    display(Audio(wav))\n",
    "    print(f\"[{idx+1}/{N_SAMPLES}] TEMP={temperature}, TOPK={top_k}, SEED={seed}\")\n",
    "    print(\"MIDI:\", mid, \"| WAV:\", wav, \"\\n\")\n",
    "\n",
    "# === 생성 실행 ===\n",
    "for i in range(N_SAMPLES):\n",
    "    temperature = temps[i % len(temps)]\n",
    "    top_k = topks[i % len(topks)]\n",
    "    generate_one(i, temperature, top_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1CZRs0uq77M"
   },
   "source": [
    "### 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113
    },
    "id": "JV0saibNnEf5",
    "outputId": "b651aca2-cce7-428b-ed0c-6dc01c4d5663"
   },
   "outputs": [],
   "source": [
    "# 5) 토큰 생성 → MIDI/WAV 저장 → 재생 (최소 옵션)\n",
    "toks = sample_and_save(\n",
    "    best_model,\n",
    "    start_token=BOS_ID,\n",
    "    max_tokens=1024,\n",
    "    temperature=1.0,\n",
    "    top_k=50,\n",
    "    out_midi_path=None,\n",
    "    aux_for_detok={\"step_sec\": 0.5/64, \"program\": 0}  # TS_DIV=64 가정(학습 설정과 일치 필요)\n",
    ")\n",
    "\n",
    "# 파일 경로\n",
    "os.makedirs(SAMPLES_DIR, exist_ok=True)\n",
    "mid = os.path.join(SAMPLES_DIR, f\"best_{int(time.time())}.mid\")\n",
    "wav = mid.replace(\".mid\", \".wav\")\n",
    "\n",
    "# detokenize (BOS/PAD 최소 정리)\n",
    "toks = [t for t in toks if t not in (PAD_ID, BOS_ID)]\n",
    "detokenize_to_midi_file(toks, {\"step_sec\": 0.5/64, \"program\": 0}, mid)\n",
    "\n",
    "# WAV 변환 & 재생 (SoundFont 경로만 확인)\n",
    "sf2 = \"/usr/share/sounds/sf2/FluidR3_GM.sf2\"  # Colab 기본 경로(없으면 apt 설치 필요)\n",
    "FluidSynth(sf2).midi_to_audio(mid, wav)\n",
    "\n",
    "display(Audio(wav))\n",
    "print(\"MIDI:\", mid, \"| WAV:\", wav)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZfD8mgxiqjuP"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
