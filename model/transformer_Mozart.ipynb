{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngQefdQBMh-6",
        "outputId": "55bfe4f3-0d5a-4902-c00c-e2e6158d8af5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 MIDI: 536개\n",
            "mozart 후보: 536개\n",
            "메타 없음으로 스킵: 0개, 파일명 규칙 불일치 스킵: 0개\n",
            "\n",
            "=== 분할 결과 ===\n",
            "train: 321, validation: 107, test: 108\n",
            "저장(JSON): /content/drive/MyDrive/Deep_Learning_project/mozart_dataset_TF/flattened_metadata_with_split.json\n",
            "저장(CSV):  /content/drive/MyDrive/Deep_Learning_project/mozart_dataset_TF/flattened_metadata_with_split.csv\n",
            "출력 폴더: /content/drive/MyDrive/Deep_Learning_project/mozart_dataset_TF (train/ validation/ test)\n",
            "\n",
            "(참고) optional 필드 결측 개수 → {'music_period': 37, 'difficulty': 393, 'opus': 27}\n"
          ]
        }
      ],
      "source": [
        "# === mozart만 6:2:2로 분리 + flattened_metadata_with_split.json 생성 ===\n",
        "from pathlib import Path\n",
        "import os, json, re, math, shutil, glob, random\n",
        "\n",
        "# --- 경로 설정 --- # 🙂🙂 개별 환경따라 변경 🙂🙂\n",
        "# Google Drive가 마운트된 경로 및 프로젝트 폴더 설정\n",
        "PROJ = Path(\"/content/drive/MyDrive/Deep_Learning_project\")\n",
        "\n",
        "# metadata.json 파일 경로 설정\n",
        "META_JSON = PROJ / \"metadata.json\"\n",
        "\n",
        "# MIDI 파일들이 있는 데이터 루트 폴더 설정\n",
        "DATA_ROOT = PROJ / \"original_token\" / \"mozart_midis\"\n",
        "\n",
        "\n",
        "SPLIT_ROOT = PROJ / \"mozart_dataset_TF\"\n",
        "SPLIT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 여러 번 실행 시, 아래를 True로 두면 train/validation/test 폴더를 비우고 시작합니다.\n",
        "CLEAN_SPLIT = True\n",
        "if CLEAN_SPLIT:\n",
        "    for sub in [\"train\", \"validation\", \"test\"]:\n",
        "        shutil.rmtree(SPLIT_ROOT / sub, ignore_errors=True)\n",
        "\n",
        "for sub in [\"train\", \"validation\", \"test\"]:\n",
        "    (SPLIT_ROOT / sub).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# --- 유틸 ---\n",
        "def parse_filename(fp: Path):\n",
        "    m = re.match(r\"^(\\d{6})_(\\d+)\\.mid$\", fp.name)\n",
        "    if not m:\n",
        "        return None, None\n",
        "    id_num = int(m.group(1))\n",
        "    take = m.group(2)\n",
        "    return str(id_num), take  # metadata.json의 키는 '4' 같은 형태\n",
        "\n",
        "def pick_audio_score(meta_entry: dict, take: str):\n",
        "    aud = meta_entry.get(\"audio_scores\", {})\n",
        "    if isinstance(aud, dict) and aud:\n",
        "        if take in aud:\n",
        "            return aud[take]\n",
        "        try:\n",
        "            return next(iter(aud.values()))\n",
        "        except StopIteration:\n",
        "            return None\n",
        "    return None\n",
        "\n",
        "def is_mozart(composer_val):  # 🙂🙂 작곡가명따라 변경 🙂🙂\n",
        "    if composer_val is None:\n",
        "        return False\n",
        "    return \"mozart\" in str(composer_val).lower()  # 🙂🙂 작곡가명따라 변경 🙂🙂\n",
        "\n",
        "# --- 메타 로드 ---\n",
        "assert META_JSON.exists(), f\"metadata.json not found: {META_JSON}\"\n",
        "with open(META_JSON, \"r\") as f:\n",
        "    meta_raw = json.load(f)\n",
        "\n",
        "# --- 데이터 스캔: 모든 .mid 파일 ---\n",
        "all_mid_paths = [Path(p) for p in glob.glob(str(DATA_ROOT / \"**\" / \"*.mid\"), recursive=True)]\n",
        "\n",
        "# --- mozart만 필터링 ---  # 🙂🙂 작곡가명따라 변경 🙂🙂\n",
        "beet_items = []\n",
        "skipped_no_meta = 0\n",
        "skipped_bad_name = 0\n",
        "\n",
        "for fp in all_mid_paths:\n",
        "    id_str, take = parse_filename(fp)\n",
        "    if not id_str:\n",
        "        skipped_bad_name += 1\n",
        "        continue\n",
        "    entry = meta_raw.get(id_str)\n",
        "    if not entry:\n",
        "        skipped_no_meta += 1\n",
        "        continue\n",
        "\n",
        "    md = entry.get(\"metadata\", {})\n",
        "    if not is_mozart(md.get(\"composer\")):  # 🙂🙂 작곡가명따라 변경 🙂🙂\n",
        "        continue\n",
        "\n",
        "    beet_items.append((fp, id_str, take, entry))\n",
        "\n",
        "print(f\"총 MIDI: {len(all_mid_paths)}개\")\n",
        "print(f\"mozart 후보: {len(beet_items)}개\")  # 🙂🙂 작곡가명따라 변경 🙂🙂\n",
        "print(f\"메타 없음으로 스킵: {skipped_no_meta}개, 파일명 규칙 불일치 스킵: {skipped_bad_name}개\")\n",
        "\n",
        "# --- 6:2:2 분할 ---\n",
        "SEED = 42\n",
        "random.Random(SEED).shuffle(beet_items)\n",
        "\n",
        "N = len(beet_items)\n",
        "n_train = math.floor(N * 0.6)\n",
        "n_val   = math.floor(N * 0.2)\n",
        "n_test  = N - n_train - n_val\n",
        "\n",
        "splits = (\n",
        "    [(\"train\", 0.6)] * n_train +\n",
        "    [(\"validation\", 0.2)] * n_val +\n",
        "    [(\"test\", 0.2)] * n_test\n",
        ")\n",
        "\n",
        "# --- 복사 & 플래튼 메타 구성 ---\n",
        "flat_meta = {}  # key: 파일명, val: 메타 dict\n",
        "missing_optionals = {\"music_period\": 0, \"difficulty\": 0, \"genre\": 0, \"opus\": 0}\n",
        "\n",
        "for (item, (split_name, split_ratio)) in zip(beet_items, splits):\n",
        "    fp, id_str, take, entry = item\n",
        "    md = entry.get(\"metadata\", {})\n",
        "\n",
        "    basename = fp.name\n",
        "    audio_score = pick_audio_score(entry, take)\n",
        "\n",
        "    music_period = md.get(\"music_period\")\n",
        "    difficulty   = md.get(\"difficulty\")\n",
        "    genre        = md.get(\"genre\")\n",
        "    opus         = md.get(\"opus\")\n",
        "\n",
        "    if music_period is None: missing_optionals[\"music_period\"] += 1\n",
        "    if difficulty   is None: missing_optionals[\"difficulty\"]   += 1\n",
        "    if genre        is None: missing_optionals[\"genre\"]        += 1\n",
        "    if opus         is None: missing_optionals[\"opus\"]         += 1\n",
        "\n",
        "    dst = SPLIT_ROOT / split_name / basename\n",
        "    shutil.copy2(fp, dst)  # 같은 이름이면 덮어씀\n",
        "\n",
        "    flat_meta[basename] = {\n",
        "        \"file_path\": basename,       # ex) 000004_0.mid\n",
        "        \"split\": split_name,         # train / validation / test\n",
        "        \"composer\": md.get(\"composer\"),\n",
        "        \"music_period\": music_period,\n",
        "        \"difficulty\": difficulty,\n",
        "        \"genre\": genre,\n",
        "        \"audio_score\": audio_score,\n",
        "        \"opus\": opus,\n",
        "        \"split_ratio\": split_ratio,\n",
        "    }\n",
        "\n",
        "# --- JSON/CSV 저장: 쓰기 가능한 SPLIT_ROOT에 저장 ---\n",
        "OUT_JSON = SPLIT_ROOT / \"flattened_metadata_with_split.json\"\n",
        "OUT_CSV  = SPLIT_ROOT / \"flattened_metadata_with_split.csv\"\n",
        "\n",
        "with open(OUT_JSON, \"w\") as f:\n",
        "    json.dump(flat_meta, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# CSV도 같이 저장(편의)\n",
        "import pandas as pd\n",
        "pd.DataFrame.from_dict(flat_meta, orient=\"index\").reset_index(drop=True).to_csv(OUT_CSV, index=False)\n",
        "\n",
        "print(\"\\n=== 분할 결과 ===\")\n",
        "print(f\"train: {n_train}, validation: {n_val}, test: {n_test}\")\n",
        "print(f\"저장(JSON): {OUT_JSON}\")\n",
        "print(f\"저장(CSV):  {OUT_CSV}\")\n",
        "print(f\"출력 폴더: {SPLIT_ROOT} (train/ validation/ test)\")\n",
        "print(\"\\n(참고) optional 필드 결측 개수 →\", {k:v for k,v in missing_optionals.items() if v>0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks6yyzFEVcEZ",
        "outputId": "42120390-ed02-4e14-c6b2-2c36a7917052"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n",
            "MPS available: False\n",
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# [1] 런타임 체크 (MPS + CPU)\n",
        "import torch, platform, sys, os, subprocess, textwrap, random, numpy as np\n",
        "\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"MPS available:\", torch.backends.mps.is_available())\n",
        "\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# 재현성\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if device.type == \"mps\":\n",
        "    pass  # MPS는 별도의 manual_seed_all 없음\n",
        "else:\n",
        "    torch.cuda.manual_seed_all(seed)  # 혹시 cuda fallback 될 경우만"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MD9KN_NNQJF7",
        "outputId": "30bba47f-dfc7-48dc-f5ff-725c7415a913",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pretty_midi\n",
            "  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/5.6 MB\u001b[0m \u001b[31m168.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m4.2/5.6 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m5.4/5.6 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mido\n",
            "  Downloading mido-1.3.3-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (0.8.1)\n",
            "Collecting pyfluidsynth\n",
            "  Downloading pyfluidsynth-1.3.4-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: music21 in /usr/local/lib/python3.12/dist-packages (9.3.0)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from pretty_midi) (2.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from pretty_midi) (1.17.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mido) (25.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.12/dist-packages (from music21) (5.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from music21) (1.5.2)\n",
            "Requirement already satisfied: jsonpickle in /usr/local/lib/python3.12/dist-packages (from music21) (4.1.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from music21) (3.10.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from music21) (10.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from music21) (2.32.4)\n",
            "Requirement already satisfied: webcolors>=1.5 in /usr/local/lib/python3.12/dist-packages (from music21) (24.11.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->music21) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->music21) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->music21) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->music21) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->music21) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->music21) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->music21) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->music21) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->music21) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->music21) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->music21) (2025.8.3)\n",
            "Downloading mido-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyfluidsynth-1.3.4-py3-none-any.whl (22 kB)\n",
            "Building wheels for collected packages: pretty_midi\n",
            "  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty_midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592286 sha256=aebb13f2893ca2d41ab346684e83a4dc870c723865e9a39f5793d25a29dcc99d\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/f9/9e/08350c27e386558df0ae234e28a8facd145ba45506ddd1b989\n",
            "Successfully built pretty_midi\n",
            "Installing collected packages: pyfluidsynth, mido, pretty_midi\n",
            "Successfully installed mido-1.3.3 pretty_midi-0.2.10 pyfluidsynth-1.3.4\n"
          ]
        }
      ],
      "source": [
        "!{sys.executable} -m pip install pretty_midi mido einops pyfluidsynth music21\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-xZ2WxIR2FZ"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import json, random, math, os\n",
        "import numpy as np\n",
        "import pretty_midi as pm\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from einops import rearrange\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "SPLIT_META_JSON = SPLIT_ROOT / \"flattened_metadata_with_split.json\"\n",
        "assert SPLIT_META_JSON.exists(), f\"split 메타가 없습니다: {SPLIT_META_JSON}\"\n",
        "with open(SPLIT_META_JSON, \"r\") as f:\n",
        "    META = json.load(f)\n",
        "\n",
        "# 토큰/캐시 경로\n",
        "VOCAB_JSON   = SPLIT_ROOT / \"vocab.json\"\n",
        "TOK_CACHE_DIR= SPLIT_ROOT / \"tok_cache\"\n",
        "TOK_CACHE_DIR.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "We7OVO4KXkSg"
      },
      "source": [
        "### 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9qKqnZKX4FR"
      },
      "outputs": [],
      "source": [
        "from music21 import converter\n",
        "\n",
        "# 음이름 표기: MIDI pitch class → 'C','C#',...,'B'\n",
        "PC2NAME = ['C','C#','D','Eb','E','F','F#','G','Ab','A','Bb','B']\n",
        "\n",
        "def detect_key_with_music21(midi_path: Path):\n",
        "    \"\"\"music21로 전체 곡의 조성(장/단조)을 추정해 KEY 토큰을 돌려줍니다.\"\"\"\n",
        "    try:\n",
        "        s = converter.parse(str(midi_path))\n",
        "        k = s.analyze('key')\n",
        "        tonic_name = k.tonic.name  # e.g., 'C', 'E-'\n",
        "        # music21의 E- 같은 표기를 좀 더 일반적으로 변환\n",
        "        tonic_name = tonic_name.replace('-','b')  # E- → Eb\n",
        "        mode = 'maj' if k.mode.lower().startswith('maj') else 'min'\n",
        "        return f\"{tonic_name}{'maj' if mode=='maj' else 'min'}\"  # 예: Cmaj, Amin, Ebmaj\n",
        "    except Exception:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmX3QrI1X7GO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 기본 화음 템플릿(루트=0 기준의 pitch-class 집합)\n",
        "CHORD_TEMPLATES = {\n",
        "    'maj'       : {0,4,7},\n",
        "    'min'       : {0,3,7},\n",
        "    'dim'       : {0,3,6},\n",
        "    'aug'       : {0,4,8},\n",
        "    'dom7'      : {0,4,7,10},\n",
        "    'maj7'      : {0,4,7,11},\n",
        "    'min7'      : {0,3,7,10},\n",
        "    'halfdim7'  : {0,3,6,10},\n",
        "    'dim7'      : {0,3,6,9},\n",
        "}\n",
        "\n",
        "def best_chord_label(pitches):\n",
        "    \"\"\"\n",
        "    pitches: 리스트/셋 (MIDI pitch들) → 최적의 (root, quality) 반환. 없으면 None.\n",
        "    평가 기준: 템플릿 커버 비율 + 사이즈 근사성.\n",
        "    \"\"\"\n",
        "    if not pitches:\n",
        "        return None\n",
        "    pcs = sorted({p % 12 for p in pitches})\n",
        "    if not pcs:\n",
        "        return None\n",
        "\n",
        "    best = None\n",
        "    best_score = -1e9\n",
        "    for root in range(12):\n",
        "        shifted = {(pc - root) % 12 for pc in pcs}\n",
        "        for qual, templ in CHORD_TEMPLATES.items():\n",
        "            inter = len(shifted & templ)\n",
        "            # 템플릿 포함 비율 & 여분 패널티\n",
        "            cover = inter / max(1, len(templ))\n",
        "            extra_penalty = -0.15 * max(0, len(shifted - templ))\n",
        "            score = cover + extra_penalty\n",
        "            if score > best_score and inter >= 2:  # 최소 2음 이상 맞아야 화음으로 인정\n",
        "                best_score = score\n",
        "                best = (root, qual)\n",
        "    if best is None:\n",
        "        return None\n",
        "    root_name = PC2NAME[best[0]]\n",
        "    return f\"{root_name}:{best[1]}\"  # 예: C:maj, A:min, G:dom7\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eepKPSdCX_W3"
      },
      "outputs": [],
      "source": [
        "TS_DIV = 16\n",
        "MIN_VEL, MAX_VEL = 20, 100\n",
        "MIN_DUR, MAX_DUR = 1, 16\n",
        "\n",
        "def quantize_time(pm_obj, ts_div=TS_DIV):\n",
        "    ts = pm_obj.time_signature_changes or [pm.TimeSignature(4,4,0.0)]\n",
        "    tempo_times, tempi = pm_obj.get_tempo_changes()\n",
        "    tempo = float(tempi[0]) if len(tempi) else 120.0\n",
        "    num, den = ts[0].numerator, ts[0].denominator\n",
        "    beat_len = 60.0 / tempo\n",
        "    bar_sec = (4/den) * num * beat_len\n",
        "\n",
        "    notes=[]\n",
        "    for inst in pm_obj.instruments:\n",
        "        for n in inst.notes:\n",
        "            bar = int(n.start // bar_sec)\n",
        "            pos = int(((n.start - bar*bar_sec)/bar_sec)*ts_div); pos = max(0,min(ts_div-1,pos))\n",
        "            dur = int(((n.end - n.start)/bar_sec)*ts_div); dur = max(MIN_DUR, min(MAX_DUR, dur))\n",
        "            vel = int(np.clip(n.velocity, MIN_VEL, MAX_VEL))\n",
        "            notes.append((bar,pos,n.pitch,dur,vel))\n",
        "    notes.sort(key=lambda x:(x[0],x[1],x[2]))\n",
        "    return notes, (num,den), int(tempo), bar_sec\n",
        "\n",
        "def encode_remi_harmony(midi_path: Path, add_chords=True, chord_every='pos'):\n",
        "    \"\"\"\n",
        "    chord_every: 'bar' → 바 당 1개, 'beat' → 박자 단위(근사), 'pos' → POS 단위(onset 기준).\n",
        "    \"\"\"\n",
        "    pm_obj = pm.PrettyMIDI(str(midi_path))\n",
        "    notes,(num,den),tempo,bar_sec = quantize_time(pm_obj)\n",
        "\n",
        "    # 0) KEY(장/단조) 토큰\n",
        "    key_token = detect_key_with_music21(midi_path)  # 예: 'Cmaj', 'Amin', None\n",
        "\n",
        "    toks = []\n",
        "    toks.append(f\"TSig_{num}_{den}\")\n",
        "    toks.append(f\"TEMPO_{tempo}\")\n",
        "    if key_token:\n",
        "        toks.append(f\"KEY_{key_token}\")  # 예: KEY_Cmaj\n",
        "\n",
        "    # 1) 화음 라벨링을 위한 그룹핑\n",
        "    #    - chord_every == 'bar' : 같은 bar 내 모든 노트 onsets\n",
        "    #    - chord_every == 'pos' : (bar,pos) 단위 노트 onsets\n",
        "    #    - chord_every == 'beat': bar 내 beat 경계 근사 (num 개)\n",
        "    from collections import defaultdict\n",
        "    onset_map = defaultdict(list)  # key: (bar, pos or beatIndex) → pitches\n",
        "\n",
        "    if chord_every == 'bar':\n",
        "        for (bar,pos,pitch,dur,vel) in notes:\n",
        "            onset_map[(bar, -1)].append(pitch)\n",
        "\n",
        "    elif chord_every == 'beat':\n",
        "        # 박자 경계(대략)로 pos→beat index 매핑 (TS_DIV를 num로 나눔)\n",
        "        step_per_beat = max(1, TS_DIV // num)\n",
        "        for (bar,pos,pitch,dur,vel) in notes:\n",
        "            beat_idx = pos // step_per_beat\n",
        "            onset_map[(bar, beat_idx)].append(pitch)\n",
        "\n",
        "    else:  # 'pos'\n",
        "        for (bar,pos,pitch,dur,vel) in notes:\n",
        "            onset_map[(bar, pos)].append(pitch)\n",
        "\n",
        "    # 2) 토큰 시퀀스 생성\n",
        "    cur_bar = -1\n",
        "    last_chord = None\n",
        "    for (bar,pos,pitch,dur,vel) in notes:\n",
        "        # BAR 토큰\n",
        "        while cur_bar < bar:\n",
        "            toks.append(\"BAR\")\n",
        "            cur_bar += 1\n",
        "            last_chord = None  # 새 마디에서 화음 새로 판단\n",
        "\n",
        "        # POS 토큰\n",
        "        toks.append(f\"POS_{pos}\")\n",
        "\n",
        "        # 2-a) 화음 토큰(선택)\n",
        "        if add_chords:\n",
        "            key = (bar, -1) if chord_every=='bar' else ((bar, pos) if chord_every=='pos' else (bar, pos // max(1, TS_DIV // num)))\n",
        "            chord_label = best_chord_label(onset_map.get(key, []))\n",
        "            if chord_label and chord_label != last_chord:\n",
        "                toks.append(f\"CHORD_{chord_label}\")   # 예: CHORD_C:maj, CHORD_A:min\n",
        "                last_chord = chord_label\n",
        "\n",
        "        # 2-b) 음표 이벤트\n",
        "        toks += [f\"NOTE_ON_{pitch}\", f\"DUR_{dur}\", f\"VEL_{vel}\"]\n",
        "\n",
        "    return toks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUhK5vZCYD4N"
      },
      "outputs": [],
      "source": [
        "def cond_tokens(meta, midi_path_for_key: Path = None):\n",
        "    t = [\"COMPOSER_Beethoven\"]\n",
        "    if meta.get(\"music_period\"): t.append(f\"PERIOD_{meta['music_period']}\")\n",
        "    if meta.get(\"genre\"):        t.append(f\"GENRE_{meta['genre']}\")\n",
        "    if meta.get(\"difficulty\"):   t.append(f\"DIFF_{meta['difficulty']}\")\n",
        "    if meta.get(\"opus\"):         t.append(f\"OPUS_{str(meta['opus']).replace(' ','_')}\")\n",
        "    q=meta.get(\"audio_score\")\n",
        "    if q is not None:\n",
        "        t.append(f\"QUALITY_{'High' if q>=0.8 else 'Med' if q>=0.5 else 'Low'}\")\n",
        "    # KEY (메타/파일 기반)\n",
        "    if midi_path_for_key is not None:\n",
        "        k = detect_key_with_music21(midi_path_for_key)\n",
        "        if k:\n",
        "            t.append(f\"KEY_{k}\")  # KEY_Cmaj / KEY_Amin ...\n",
        "    return t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_g9y46PUSQ4U",
        "outputId": "5fd3ec82-022f-40d0-fa04-03c6720e8508"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VOCAB_SIZE: 471\n"
          ]
        }
      ],
      "source": [
        "def build_vocab():\n",
        "    if VOCAB_JSON.exists(): return json.load(open(VOCAB_JSON))\n",
        "    vocab={\"[PAD]\":0,\"[BOS]\":1,\"[EOS]\":2,\"[UNK]\":3}\n",
        "    idx=len(vocab)\n",
        "    for fname,meta in META.items():\n",
        "        p = SPLIT_ROOT/meta[\"split\"]/meta[\"file_path\"]\n",
        "        if not p.exists(): continue\n",
        "        # vocab 빌드 단계\n",
        "        toks = [\"[BOS]\"] + cond_tokens(meta, midi_path_for_key=p) + encode_remi_harmony(p, add_chords=True, chord_every='pos')+ [\"[EOS]\"]\n",
        "\n",
        "        json.dump(toks, open(TOK_CACHE_DIR/(fname+\".json\"),\"w\"))\n",
        "        for t in toks:\n",
        "            if t not in vocab:\n",
        "                vocab[t]=idx; idx+=1\n",
        "    json.dump(vocab, open(VOCAB_JSON,\"w\"))\n",
        "    return vocab\n",
        "\n",
        "VOCAB = build_vocab()\n",
        "IVOCAB= {i:t for t,i in VOCAB.items()}\n",
        "VOCAB_SIZE=len(VOCAB)\n",
        "print(\"VOCAB_SIZE:\", VOCAB_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNqiWgG6SUWq"
      },
      "outputs": [],
      "source": [
        "SEQ_LEN=512\n",
        "\n",
        "def toks_to_ids(toks): return [VOCAB.get(t, VOCAB[\"[UNK]\"]) for t in toks]\n",
        "\n",
        "class BeethovenMIDIDataset(Dataset):\n",
        "    def __init__(self, split):\n",
        "        self.items=[(k,v) for k,v in META.items() if v[\"split\"]==split]\n",
        "        random.Random(42).shuffle(self.items)\n",
        "    def __len__(self): return len(self.items)\n",
        "    def __getitem__(self,i):\n",
        "        fname,meta = self.items[i]\n",
        "        cache=TOK_CACHE_DIR/(fname+\".json\")\n",
        "        if cache.exists(): toks=json.load(open(cache))\n",
        "        else:\n",
        "            p=SPLIT_ROOT/meta[\"split\"]/meta[\"file_path\"]\n",
        "            toks=[\"[BOS]\"]+cond_tokens(meta)+encode_remi_lite(p)+[\"[EOS]\"]\n",
        "        ids=toks_to_ids(toks)\n",
        "        if len(ids)>=SEQ_LEN:\n",
        "            st=random.randint(0, len(ids)-SEQ_LEN)\n",
        "            seq=ids[st:st+SEQ_LEN]\n",
        "        else:\n",
        "            seq=ids+[VOCAB[\"[PAD]\"]] * (SEQ_LEN-len(ids))\n",
        "        x=torch.tensor(seq[:-1],dtype=torch.long)\n",
        "        y=torch.tensor(seq[1:], dtype=torch.long)\n",
        "        return x,y\n",
        "\n",
        "train_dl=DataLoader(BeethovenMIDIDataset(\"train\"), batch_size=16, shuffle=True, drop_last=True)\n",
        "val_dl  =DataLoader(BeethovenMIDIDataset(\"validation\"), batch_size=16, shuffle=False, drop_last=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_BC3kuQSf6q"
      },
      "outputs": [],
      "source": [
        "import math, torch, torch.nn as nn\n",
        "from einops import rearrange\n",
        "\n",
        "# ===== 1) RoPE (Rotary Positional Embedding) =====\n",
        "def apply_rope(q,k):\n",
        "    B,H,T,D = q.shape\n",
        "    pos = torch.arange(T, device=q.device).float()\n",
        "    inv = 1.0/(10000**(torch.arange(0,D,2,device=q.device).float()/D))\n",
        "    ang = torch.einsum('t,d->td', pos, inv)\n",
        "    sin,cos = ang.sin()[None,None], ang.cos()[None,None]\n",
        "    def rot(x):\n",
        "        x1,x2=x[...,::2],x[...,1::2]\n",
        "        return torch.stack([x1*cos - x2*sin, x1*sin + x2*cos], dim=-1).flatten(-2)\n",
        "    return rot(q), rot(k)\n",
        "\n",
        "# ===== 2) Self-Attention =====\n",
        "class CausalSelfAttn(nn.Module):\n",
        "    def __init__(self,d_model=512,n_head=8,p=0.1):\n",
        "        super().__init__()\n",
        "        assert d_model% n_head==0\n",
        "        self.nh=n_head; self.dk=d_model//n_head\n",
        "        self.qkv=nn.Linear(d_model, d_model*3)\n",
        "        self.proj=nn.Linear(d_model, d_model)\n",
        "        self.drop=nn.Dropout(p)\n",
        "    def forward(self,x):\n",
        "        B,T,C=x.shape\n",
        "        q,k,v = self.qkv(x).chunk(3,-1)\n",
        "        q=rearrange(q,'b t (h d)->b h t d',h=self.nh)\n",
        "        k=rearrange(k,'b t (h d)->b h t d',h=self.nh)\n",
        "        v=rearrange(v,'b t (h d)->b h t d',h=self.nh)\n",
        "        q,k=apply_rope(q,k)\n",
        "        att=(q@k.transpose(-1,-2))/math.sqrt(self.dk)\n",
        "        mask=torch.triu(torch.ones(T,T,device=x.device),1).bool()\n",
        "        att=att.masked_fill(mask,float('-inf')).softmax(-1)\n",
        "        att=self.drop(att)\n",
        "        y=att@v\n",
        "        y=rearrange(y,'b h t d->b t (h d)')\n",
        "        return self.proj(y)\n",
        "\n",
        "# ===== 3) Transformer Block =====\n",
        "class Block(nn.Module):\n",
        "    def __init__(self,d=512,h=8,p=0.1,mlp=4):\n",
        "        super().__init__()\n",
        "        self.ln1=nn.LayerNorm(d); self.att=CausalSelfAttn(d,h,p)\n",
        "        self.ln2=nn.LayerNorm(d)\n",
        "        self.mlp=nn.Sequential(\n",
        "            nn.Linear(d,d*mlp), nn.GELU(), nn.Dropout(p), nn.Linear(d*mlp,d)\n",
        "        )\n",
        "        self.drop=nn.Dropout(p)\n",
        "    def forward(self,x):\n",
        "        x=x+self.drop(self.att(self.ln1(x)))\n",
        "        x=x+self.drop(self.mlp(self.ln2(x)))\n",
        "        return x\n",
        "\n",
        "# ===== 4) MiniGPT Model =====\n",
        "class MiniGPT(nn.Module):\n",
        "    def __init__(self,vocab_size, d=512, L=8, H=8, p=0.1):\n",
        "        super().__init__()\n",
        "        self.emb=nn.Embedding(vocab_size, d)\n",
        "        self.pos=nn.Parameter(torch.zeros(1, SEQ_LEN-1, d))  # 절대 위치 (RoPE와 병용)\n",
        "        self.blocks=nn.ModuleList([Block(d,H,p) for _ in range(L)])\n",
        "        self.ln=nn.LayerNorm(d)\n",
        "        self.head=nn.Linear(d, vocab_size, bias=False)\n",
        "    def forward(self,idx):\n",
        "        x=self.emb(idx) + self.pos[:, :idx.size(1), :]\n",
        "        for b in self.blocks: x=b(x)\n",
        "        return self.head(self.ln(x))\n",
        "\n",
        "# ===== 5) 모델 초기화 =====\n",
        "model = MiniGPT(VOCAB_SIZE).to(DEVICE)\n",
        "opt   = torch.optim.AdamW(model.parameters(), lr=3e-4, betas=(0.9,0.95), weight_decay=0.1)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=VOCAB[\"[PAD]\"], label_smoothing=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWRsoGe7apIg"
      },
      "outputs": [],
      "source": [
        "import pretty_midi as pm\n",
        "from pathlib import Path\n",
        "\n",
        "def detokenize_to_midi(tokens, out_path, ts_div=16, default_time_sig=(4,4), default_tempo=120,\n",
        "                       program=0, safe_pitch=(36,96)):\n",
        "    \"\"\"\n",
        "    REMI류 토큰 시퀀스를 MIDI로 복원합니다.\n",
        "    - tokens 예시: [\"TSig_4_4\",\"TEMPO_112\",\"BAR\",\"POS_0\",\"NOTE_ON_60\",\"DUR_4\",\"VEL_80\", ...]\n",
        "    - KEY_*, CHORD_* 토큰은 MIDI에 직접 반영하지 않고 건너뜁니다.\n",
        "    - ts_div는 토큰화 때 쓴 TS_DIV와 동일해야 합니다(기본 16).\n",
        "    \"\"\"\n",
        "    out_path = Path(out_path) if isinstance(out_path, str) else out_path\n",
        "\n",
        "    # 초기 메타\n",
        "    num, den = default_time_sig\n",
        "    tempo = default_tempo\n",
        "    beat_len = 60.0 / tempo\n",
        "    bar_sec = (4/den) * num * beat_len\n",
        "\n",
        "    cur_bar = -1\n",
        "    pos = 0\n",
        "\n",
        "    pm_out = pm.PrettyMIDI()\n",
        "    inst = pm.Instrument(program=program)\n",
        "    SAFE_LOW, SAFE_HIGH = safe_pitch\n",
        "\n",
        "    i = 0\n",
        "    N = len(tokens)\n",
        "    while i < N:\n",
        "        t = tokens[i]\n",
        "\n",
        "        # 메타 토큰\n",
        "        if t.startswith(\"TSig_\"):\n",
        "            try:\n",
        "                _, a, b = t.split(\"_\")\n",
        "                num, den = int(a), int(b)\n",
        "                beat_len = 60.0 / tempo\n",
        "                bar_sec = (4/den) * num * beat_len\n",
        "            except Exception:\n",
        "                pass\n",
        "            i += 1; continue\n",
        "\n",
        "        if t.startswith(\"TEMPO_\"):\n",
        "            try:\n",
        "                tempo = int(t.split(\"_\")[1])\n",
        "                beat_len = 60.0 / tempo\n",
        "                bar_sec = (4/den) * num * beat_len\n",
        "            except Exception:\n",
        "                pass\n",
        "            i += 1; continue\n",
        "\n",
        "        if t.startswith(\"KEY_\") or t.startswith(\"CHORD_\"):\n",
        "            i += 1; continue  # 조성/화음 토큰은 MIDI에 직접 반영하지 않음\n",
        "\n",
        "        # 구조 토큰\n",
        "        if t == \"BAR\":\n",
        "            cur_bar += 1\n",
        "            pos = 0\n",
        "            i += 1; continue\n",
        "\n",
        "        if t.startswith(\"POS_\"):\n",
        "            try:\n",
        "                pos = int(t.split(\"_\")[1])\n",
        "                pos = max(0, min(ts_div-1, pos))\n",
        "            except Exception:\n",
        "                pos = max(0, min(ts_div-1, pos))\n",
        "            i += 1; continue\n",
        "\n",
        "        # 음표 이벤트\n",
        "        if t.startswith(\"NOTE_ON_\"):\n",
        "            # NOTE_ON_p\n",
        "            try:\n",
        "                pitch = int(t.split(\"_\")[2])\n",
        "            except Exception:\n",
        "                i += 1; continue\n",
        "            i += 1\n",
        "\n",
        "            # DUR_d (기본 4), VEL_v (기본 80)\n",
        "            dur = 4\n",
        "            vel = 80\n",
        "            if i < N and tokens[i].startswith(\"DUR_\"):\n",
        "                try: dur = int(tokens[i].split(\"_\")[1])\n",
        "                except Exception: pass\n",
        "                i += 1\n",
        "            if i < N and (tokens[i].startswith(\"VEL_\") or tokens[i].startswith(\"VELOCITY_\")):\n",
        "                try: vel = int(tokens[i].split(\"_\")[1])\n",
        "                except Exception: pass\n",
        "                i += 1\n",
        "\n",
        "            pitch = max(SAFE_LOW, min(SAFE_HIGH, pitch))\n",
        "            start = (cur_bar * bar_sec) + (pos / ts_div) * bar_sec\n",
        "            end   = start + (dur / ts_div) * bar_sec\n",
        "            if end <= start:\n",
        "                end = start + (1 / ts_div) * bar_sec  # 최소 1틱\n",
        "\n",
        "            inst.notes.append(pm.Note(velocity=vel, pitch=pitch, start=start, end=end))\n",
        "            continue\n",
        "\n",
        "        # 알 수 없는 토큰은 무시\n",
        "        i += 1\n",
        "\n",
        "    pm_out.instruments.append(inst)\n",
        "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    pm_out.write(str(out_path))\n",
        "    return out_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbeE1fjcZg71",
        "outputId": "c79f7734-836c-4751-9ff8-dd79ba734ff5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/50] train 6.3653 | val 6.3803 | best 6.3803 | lr 0.000003\n",
            "[2/50] train 6.3194 | val 6.3728 | best 6.3728 | lr 0.000006\n",
            "[3/50] train 6.2248 | val 6.3799 | best 6.3728 | lr 0.000009\n",
            "[4/50] train 6.0734 | val 6.3722 | best 6.3722 | lr 0.000012\n",
            "[5/50] train 5.8805 | val 6.3636 | best 6.3636 | lr 0.000015\n",
            "[6/50] train 5.6667 | val 6.3607 | best 6.3607 | lr 0.000018\n",
            "[7/50] train 5.4336 | val 6.3488 | best 6.3488 | lr 0.000021\n",
            "[8/50] train 5.2518 | val 6.3348 | best 6.3348 | lr 0.000024\n",
            "[9/50] train 5.0532 | val 6.3199 | best 6.3199 | lr 0.000027\n",
            "[10/50] train 4.8896 | val 6.3068 | best 6.3068 | lr 0.000030\n",
            "[11/50] train 4.7120 | val 6.2826 | best 6.2826 | lr 0.000033\n",
            "[12/50] train 4.5868 | val 6.2588 | best 6.2588 | lr 0.000036\n",
            "[13/50] train 4.4825 | val 6.2335 | best 6.2335 | lr 0.000039\n",
            "[14/50] train 4.3387 | val 6.2103 | best 6.2103 | lr 0.000042\n",
            "[15/50] train 4.1987 | val 6.1779 | best 6.1779 | lr 0.000045\n",
            "[16/50] train 4.0673 | val 6.1568 | best 6.1568 | lr 0.000048\n",
            "[17/50] train 3.9405 | val 6.1265 | best 6.1265 | lr 0.000051\n",
            "[18/50] train 3.8288 | val 6.0947 | best 6.0947 | lr 0.000054\n",
            "[19/50] train 3.7023 | val 6.0727 | best 6.0727 | lr 0.000057\n",
            "[20/50] train 3.5815 | val 6.0352 | best 6.0352 | lr 0.000060\n",
            "[21/50] train 3.4842 | val 6.0055 | best 6.0055 | lr 0.000063\n",
            "[22/50] train 3.4117 | val 5.9679 | best 5.9679 | lr 0.000066\n",
            "[23/50] train 3.3309 | val 5.9402 | best 5.9402 | lr 0.000069\n",
            "[24/50] train 3.2740 | val 5.8938 | best 5.8938 | lr 0.000072\n",
            "[25/50] train 3.2291 | val 5.8695 | best 5.8695 | lr 0.000075\n",
            "[26/50] train 3.1990 | val 5.8200 | best 5.8200 | lr 0.000078\n",
            "[27/50] train 3.1681 | val 5.8075 | best 5.8075 | lr 0.000081\n",
            "[28/50] train 3.1540 | val 5.7512 | best 5.7512 | lr 0.000084\n",
            "[29/50] train 3.1289 | val 5.7042 | best 5.7042 | lr 0.000087\n",
            "[30/50] train 3.1168 | val 5.6647 | best 5.6647 | lr 0.000090\n",
            "[31/50] train 3.0955 | val 5.6200 | best 5.6200 | lr 0.000093\n",
            "[32/50] train 3.0922 | val 5.5956 | best 5.5956 | lr 0.000096\n",
            "[33/50] train 3.0902 | val 5.5521 | best 5.5521 | lr 0.000099\n",
            "[34/50] train 3.0626 | val 5.5201 | best 5.5201 | lr 0.000102\n",
            "[35/50] train 3.0272 | val 5.4711 | best 5.4711 | lr 0.000105\n",
            "[36/50] train 3.0556 | val 5.4277 | best 5.4277 | lr 0.000108\n",
            "[37/50] train 3.0486 | val 5.3725 | best 5.3725 | lr 0.000111\n",
            "[38/50] train 3.0342 | val 5.3561 | best 5.3561 | lr 0.000114\n",
            "[39/50] train 3.0183 | val 5.2979 | best 5.2979 | lr 0.000117\n",
            "[40/50] train 3.0139 | val 5.2499 | best 5.2499 | lr 0.000120\n",
            "[41/50] train 3.0085 | val 5.2123 | best 5.2123 | lr 0.000123\n",
            "[42/50] train 3.0150 | val 5.1704 | best 5.1704 | lr 0.000126\n",
            "[43/50] train 2.9995 | val 5.1407 | best 5.1407 | lr 0.000129\n",
            "[44/50] train 3.0045 | val 5.0975 | best 5.0975 | lr 0.000132\n",
            "[45/50] train 2.9980 | val 5.0645 | best 5.0645 | lr 0.000135\n",
            "[46/50] train 2.9760 | val 5.0083 | best 5.0083 | lr 0.000138\n",
            "[47/50] train 2.9795 | val 4.9892 | best 4.9892 | lr 0.000141\n",
            "[48/50] train 2.9704 | val 4.9184 | best 4.9184 | lr 0.000144\n",
            "[49/50] train 2.9645 | val 4.8820 | best 4.8820 | lr 0.000147\n",
            "[50/50] train 2.9601 | val 4.8705 | best 4.8705 | lr 0.000150\n",
            "Saved → /content/drive/MyDrive/Deep_Learning_project/mozart_dataset_TF/sample_beethoven_long_v1.mid\n",
            "Best val loss: 4.870522499084473 | approx PPL: 130.3890272484736\n"
          ]
        }
      ],
      "source": [
        "# ====== 0) 준비 ======\n",
        "import math, torch\n",
        "import torch.nn as nn\n",
        "from torch.amp import GradScaler, autocast  # ✅ AMP 최신 API\n",
        "\n",
        "VOCAB_SIZE = len(VOCAB)\n",
        "\n",
        "# ====== EMA 유틸 ======\n",
        "class EMA:\n",
        "    def __init__(self, model, decay=0.999):\n",
        "        self.decay = decay\n",
        "        self.shadow = {k: p.detach().clone() for k, p in model.state_dict().items()}\n",
        "        self.backup = None\n",
        "    @torch.no_grad()\n",
        "    def update(self, model):\n",
        "        for k, p in model.state_dict().items():\n",
        "            self.shadow[k].mul_(self.decay).add_(p.detach(), alpha=1 - self.decay)\n",
        "    def store(self, model):\n",
        "        self.backup = {k: p.detach().clone() for k, p in model.state_dict().items()}\n",
        "    def copy_to(self, model):\n",
        "        model.load_state_dict(self.shadow, strict=False)\n",
        "    def restore(self, model):\n",
        "        if self.backup is not None:\n",
        "            model.load_state_dict(self.backup, strict=False)\n",
        "            self.backup = None\n",
        "\n",
        "ema = EMA(model, decay=0.999)\n",
        "\n",
        "# ====== 1) 손실, 옵티마이저, 스케줄러, 체크포인트 ======\n",
        "criterion = nn.CrossEntropyLoss(\n",
        "    ignore_index=VOCAB[\"[PAD]\"],\n",
        "    label_smoothing=0.05,    # ✅ 0.05로 미세조정\n",
        ")\n",
        "\n",
        "opt = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=3e-4,\n",
        "    betas=(0.9, 0.95),\n",
        "    weight_decay=0.03,       # ✅ 과규제 완화\n",
        ")\n",
        "\n",
        "EPOCHS = 50\n",
        "warmup_steps = 1000\n",
        "total_steps  = max(1, len(train_dl) * EPOCHS)\n",
        "\n",
        "def lr_lambda(step):\n",
        "    if step < warmup_steps:\n",
        "        return step / max(1, warmup_steps)\n",
        "    progress = (step - warmup_steps) / max(1, total_steps - warmup_steps)\n",
        "    progress = min(1.0, max(0.0, progress))\n",
        "    return 0.5 * (1 + math.cos(math.pi * progress))\n",
        "\n",
        "sched = torch.optim.lr_scheduler.LambdaLR(opt, lr_lambda)\n",
        "\n",
        "use_cuda_amp = (DEVICE.type == 'cuda')\n",
        "scaler = GradScaler('cuda' if use_cuda_amp else 'cpu')\n",
        "\n",
        "# ====== 2) 학습/검증 함수 (ACC=2) ======\n",
        "ACC = 2  # ✅ 유효 배치 x2\n",
        "\n",
        "def run_epoch(dl, train=True, grad_clip=1.0):\n",
        "    model.train(train)\n",
        "    total, n = 0.0, 0\n",
        "    if train:\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "    for step, (x, y) in enumerate(dl, 1):\n",
        "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "        with torch.set_grad_enabled(train):\n",
        "            with autocast('cuda' if use_cuda_amp else 'cpu'):\n",
        "                logits = model(x)\n",
        "                loss = criterion(logits.view(-1, VOCAB_SIZE), y.view(-1))\n",
        "                if train and ACC > 1:\n",
        "                    loss = loss / ACC\n",
        "        if train:\n",
        "            scaler.scale(loss).backward()\n",
        "            if step % ACC == 0:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "                scaler.step(opt)\n",
        "                scaler.update()\n",
        "                sched.step()\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                ema.update(model)  # ✅ step 뒤 EMA 업데이트\n",
        "        total += loss.item() * (ACC if train and ACC > 1 else 1.0)\n",
        "        n += 1\n",
        "    return total / max(1, n)\n",
        "\n",
        "# ====== 3) 학습 루프 + EMA 검증 + 베스트 저장 ======\n",
        "best_val = float('inf')\n",
        "ckpt_path = SPLIT_ROOT / \"minigpt_best.pt\"\n",
        "\n",
        "for ep in range(1, EPOCHS+1):\n",
        "    tr = run_epoch(train_dl, train=True)\n",
        "\n",
        "    # ✅ EMA 가중치로 검증\n",
        "    ema.store(model); ema.copy_to(model)\n",
        "    vl = run_epoch(val_dl, train=False)\n",
        "    ema.restore(model)\n",
        "\n",
        "    if vl < best_val:\n",
        "        best_val = vl\n",
        "        torch.save(model.state_dict(), str(ckpt_path))\n",
        "    print(f\"[{ep}/{EPOCHS}] train {tr:.4f} | val {vl:.4f} | best {best_val:.4f} | lr {sched.get_last_lr()[0]:.6f}\")\n",
        "\n",
        "# ====== 4) 베스트 가중치 로드(안전) ======\n",
        "_ = model.load_state_dict(torch.load(str(ckpt_path), map_location=DEVICE))\n",
        "\n",
        "# ====== 5) 기본 generate (윈도우 자동 적용: pos 임베딩 길이에 맞춰 crop) ======\n",
        "@torch.no_grad()\n",
        "def generate(prompt_tokens, max_new=700, top_k=50, top_p=0.95, temp=0.9):\n",
        "    model.eval()\n",
        "    unk_id = VOCAB.get(\"[UNK]\", None)\n",
        "    if unk_id is None:\n",
        "        raise ValueError(\"Vocab must contain [UNK] token.\")\n",
        "    pos_len = getattr(getattr(model, 'pos', None), 'shape', [1, 100000, 0])[1]\n",
        "    ids = torch.tensor([[VOCAB.get(t, unk_id) for t in prompt_tokens]], device=DEVICE)\n",
        "    for _ in range(max_new):\n",
        "        ids_win = ids[:, -pos_len:] if ids.size(1) > pos_len else ids\n",
        "        logits = model(ids_win)[:, -1, :] / max(temp, 1e-6)\n",
        "        probs = torch.softmax(logits, dim=-1)[0]\n",
        "        if top_k > 0:\n",
        "            topk = torch.topk(probs, top_k)\n",
        "            mask = torch.ones_like(probs, dtype=torch.bool); mask[topk.indices] = False\n",
        "            probs = probs.masked_fill(mask, 0)\n",
        "        if top_p < 1.0:\n",
        "            sprob, sidx = torch.sort(probs, descending=True)\n",
        "            keep = torch.cumsum(sprob, dim=-1) <= top_p\n",
        "            keep[0] = True\n",
        "            mask = torch.ones_like(probs, dtype=torch.bool); mask[sidx[keep]] = False\n",
        "            probs = probs.masked_fill(mask, 0)\n",
        "        probs = probs / probs.sum()\n",
        "        nxt = torch.multinomial(probs, 1)\n",
        "        ids = torch.cat([ids, nxt.view(1,1)], dim=1)\n",
        "        if nxt.item() == VOCAB[\"[EOS]\"]:\n",
        "            break\n",
        "    return [IVOCAB[i.item()] for i in ids[0]]\n",
        "\n",
        "# ====== 6) 길게 생성: 청크 스티칭(모델 수정 없음) ======\n",
        "def stitch_generate(prompt_tokens, total_new=512, chunk_new=700, context=480,\n",
        "                    top_k=50, top_p=0.95, temp=0.9, stop_on_eos=False):\n",
        "    all_tokens = list(prompt_tokens)\n",
        "    made = 0\n",
        "    while made < total_new:\n",
        "        this_new = min(chunk_new, total_new - made)\n",
        "        cur_prompt = all_tokens[-context:] if len(all_tokens) > context else all_tokens\n",
        "        chunk = generate(cur_prompt, max_new=this_new, top_k=top_k, top_p=top_p, temp=temp)\n",
        "        new_part = chunk[len(cur_prompt):] if len(chunk) > len(cur_prompt) else []\n",
        "        if stop_on_eos and (\"[EOS]\" in new_part):\n",
        "            eos_idx = new_part.index(\"[EOS]\"); all_tokens += new_part[:eos_idx]; break\n",
        "        all_tokens += new_part\n",
        "        made += len(new_part)\n",
        "        if len(new_part) == 0:\n",
        "            break\n",
        "    return all_tokens\n",
        "\n",
        "# ====== 7) 프롬프트 설정 & 길게 생성 & 저장 ======\n",
        "prompt = [\"[BOS]\",\"COMPOSER_Mozart\",\"PERIOD_Middle\",\"GENRE_Sonata\",\"KEY_Cmin\",\n",
        "          \"TSig_4_4\",\"TEMPO_112\",\"BAR\",\"POS_0\",\"BAR\",\"POS_0\",\"BAR\",\"POS_0\"]\n",
        "\n",
        "tokens_long = stitch_generate(\n",
        "    prompt_tokens=prompt,\n",
        "    total_new=512,     # 길이는 유지\n",
        "    chunk_new=700,\n",
        "    context=480,\n",
        "    top_k=50, top_p=0.95, temp=0.9,\n",
        "    stop_on_eos=False\n",
        ")\n",
        "\n",
        "out_mid_long = SPLIT_ROOT / \"sample_beethoven_long_v1.mid\"\n",
        "detokenize_to_midi(tokens_long, out_mid_long)\n",
        "print(\"Saved →\", out_mid_long)\n",
        "\n",
        "# ====== 8) (선택) 퍼플렉서티로 상태 확인 ======\n",
        "print(\"Best val loss:\", best_val, \"| approx PPL:\", math.exp(best_val))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejD7vA-HgOS0",
        "outputId": "9fa09cdb-9481-4651-fcd7-99f4616bfcb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/50] train 3.1018 | val 2.9482 | best 2.9482 | lr 0.000003\n",
            "[2/50] train 3.0835 | val 2.9442 | best 2.9442 | lr 0.000006\n",
            "[3/50] train 3.0633 | val 2.9568 | best 2.9442 | lr 0.000009\n",
            "[4/50] train 3.0389 | val 2.9537 | best 2.9442 | lr 0.000012\n",
            "[5/50] train 3.0170 | val 2.9465 | best 2.9442 | lr 0.000015\n",
            "[6/50] train 3.0054 | val 2.9490 | best 2.9442 | lr 0.000018\n",
            "[7/50] train 2.9993 | val 2.9420 | best 2.9420 | lr 0.000021\n",
            "[8/50] train 2.9986 | val 2.9555 | best 2.9420 | lr 0.000024\n",
            "[9/50] train 2.9865 | val 2.9406 | best 2.9406 | lr 0.000027\n",
            "[10/50] train 2.9873 | val 2.9527 | best 2.9406 | lr 0.000030\n",
            "[11/50] train 2.9921 | val 2.9548 | best 2.9406 | lr 0.000033\n",
            "[12/50] train 2.9947 | val 2.9597 | best 2.9406 | lr 0.000036\n",
            "[13/50] train 2.9844 | val 2.9508 | best 2.9406 | lr 0.000039\n",
            "[14/50] train 2.9849 | val 2.9557 | best 2.9406 | lr 0.000042\n",
            "[15/50] train 2.9740 | val 2.9500 | best 2.9406 | lr 0.000045\n",
            "[16/50] train 2.9781 | val 2.9574 | best 2.9406 | lr 0.000048\n",
            "[17/50] train 2.9642 | val 2.9438 | best 2.9406 | lr 0.000051\n",
            "[18/50] train 2.9673 | val 2.9573 | best 2.9406 | lr 0.000054\n",
            "[19/50] train 2.9630 | val 2.9538 | best 2.9406 | lr 0.000057\n",
            "[20/50] train 2.9637 | val 2.9532 | best 2.9406 | lr 0.000060\n",
            "[21/50] train 2.9417 | val 2.9467 | best 2.9406 | lr 0.000063\n",
            "[22/50] train 2.9350 | val 2.9649 | best 2.9406 | lr 0.000066\n",
            "[23/50] train 2.9306 | val 2.9702 | best 2.9406 | lr 0.000069\n",
            "[24/50] train 2.9035 | val 2.9514 | best 2.9406 | lr 0.000072\n",
            "[25/50] train 2.8737 | val 2.9400 | best 2.9400 | lr 0.000075\n",
            "[26/50] train 2.8484 | val 2.9554 | best 2.9400 | lr 0.000078\n",
            "[27/50] train 2.8161 | val 2.9479 | best 2.9400 | lr 0.000081\n",
            "[28/50] train 2.7889 | val 2.9478 | best 2.9400 | lr 0.000084\n",
            "[29/50] train 2.7708 | val 2.9256 | best 2.9256 | lr 0.000087\n",
            "[30/50] train 2.7533 | val 2.9354 | best 2.9256 | lr 0.000090\n",
            "[31/50] train 2.7335 | val 2.9170 | best 2.9170 | lr 0.000093\n",
            "[32/50] train 2.7352 | val 2.9556 | best 2.9170 | lr 0.000096\n",
            "[33/50] train 2.7125 | val 2.9615 | best 2.9170 | lr 0.000099\n",
            "[34/50] train 2.7062 | val 2.9294 | best 2.9170 | lr 0.000102\n",
            "[35/50] train 2.6925 | val 2.9423 | best 2.9170 | lr 0.000105\n",
            "[36/50] train 2.6830 | val 2.9428 | best 2.9170 | lr 0.000108\n",
            "[37/50] train 2.6728 | val 2.9594 | best 2.9170 | lr 0.000111\n",
            "[38/50] train 2.6552 | val 2.9329 | best 2.9170 | lr 0.000114\n",
            "[39/50] train 2.6571 | val 2.9399 | best 2.9170 | lr 0.000117\n",
            "[40/50] train 2.6465 | val 2.9272 | best 2.9170 | lr 0.000120\n",
            "[41/50] train 2.6568 | val 2.9208 | best 2.9170 | lr 0.000123\n",
            "[42/50] train 2.6414 | val 2.9323 | best 2.9170 | lr 0.000126\n",
            "[43/50] train 2.6422 | val 2.9331 | best 2.9170 | lr 0.000129\n",
            "[44/50] train 2.6232 | val 2.9393 | best 2.9170 | lr 0.000132\n",
            "[45/50] train 2.6168 | val 2.9353 | best 2.9170 | lr 0.000135\n",
            "[46/50] train 2.6130 | val 2.9405 | best 2.9170 | lr 0.000138\n",
            "[47/50] train 2.6143 | val 2.9390 | best 2.9170 | lr 0.000141\n",
            "[48/50] train 2.6087 | val 2.9201 | best 2.9170 | lr 0.000144\n",
            "[49/50] train 2.5892 | val 2.9343 | best 2.9170 | lr 0.000147\n",
            "[50/50] train 2.5953 | val 2.9172 | best 2.9170 | lr 0.000150\n",
            "[SWA] val 2.6301\n",
            "SWA checkpoint saved (better than EMA-best).\n",
            "Saved → /content/drive/MyDrive/Deep_Learning_project/mozart_dataset_TF/sample_mozart_long_v2.mid\n",
            "Best val loss (EMA): 2.917028018406459 | approx PPL: 18.486264898215694\n"
          ]
        }
      ],
      "source": [
        "# ====== 0) 준비 ======\n",
        "import math, torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.amp import GradScaler, autocast  # AMP 최신 API\n",
        "from torch.optim.swa_utils import AveragedModel  # SWA\n",
        "\n",
        "VOCAB_SIZE = len(VOCAB)\n",
        "PAD_ID = VOCAB[\"[PAD]\"]\n",
        "UNK_ID = VOCAB.get(\"[UNK]\", None)\n",
        "assert UNK_ID is not None, \"[UNK] 토큰이 vocab에 필요합니다.\"\n",
        "\n",
        "# ----- (선택) 토큰 드롭아웃: VEL_/DUR_ 소량 마스킹 -----\n",
        "DROP_PROB = 0.05  # 3~7% 권장\n",
        "VEL_IDS = {tid for tok, tid in VOCAB.items() if tok.startswith(\"VEL_\")}\n",
        "DUR_IDS = {tid for tok, tid in VOCAB.items() if tok.startswith(\"DUR_\")}\n",
        "DROP_SET = VEL_IDS | DUR_IDS\n",
        "\n",
        "def token_dropout(batch_ids, drop_prob=DROP_PROB):\n",
        "    # batch_ids: LongTensor [B, T]\n",
        "    if drop_prob <= 0 or not DROP_SET:\n",
        "        return batch_ids\n",
        "    dev = batch_ids.device\n",
        "    drop_ids = torch.tensor(list(DROP_SET), device=dev)\n",
        "    mask = torch.rand_like(batch_ids.float()) < drop_prob\n",
        "    sel = mask & torch.isin(batch_ids, drop_ids)\n",
        "    return batch_ids.masked_fill(sel, PAD_ID)\n",
        "\n",
        "# ====== EMA 유틸 ======\n",
        "class EMA:\n",
        "    def __init__(self, model, decay=0.999):\n",
        "        self.decay = decay\n",
        "        self.shadow = {k: p.detach().clone() for k, p in model.state_dict().items()}\n",
        "        self.backup = None\n",
        "    @torch.no_grad()\n",
        "    def update(self, model):\n",
        "        for k, p in model.state_dict().items():\n",
        "            self.shadow[k].mul_(self.decay).add_(p.detach(), alpha=1 - self.decay)\n",
        "    def store(self, model):\n",
        "        self.backup = {k: p.detach().clone() for k, p in model.state_dict().items()}\n",
        "    def copy_to(self, model):\n",
        "        model.load_state_dict(self.shadow, strict=False)\n",
        "    def restore(self, model):\n",
        "        if self.backup is not None:\n",
        "            model.load_state_dict(self.backup, strict=False)\n",
        "            self.backup = None\n",
        "\n",
        "ema = EMA(model, decay=0.999)\n",
        "\n",
        "# ====== 1) 손실, 옵티마이저, 스케줄러 ======\n",
        "criterion = nn.CrossEntropyLoss(\n",
        "    ignore_index=PAD_ID,\n",
        "    label_smoothing=0.05,\n",
        ")\n",
        "\n",
        "opt = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=3e-4,\n",
        "    betas=(0.9, 0.95),\n",
        "    weight_decay=0.03,\n",
        ")\n",
        "\n",
        "EPOCHS = 50\n",
        "warmup_steps = 1000\n",
        "total_steps  = max(1, len(train_dl) * EPOCHS)\n",
        "\n",
        "def lr_lambda(step):\n",
        "    if step < warmup_steps:\n",
        "        return step / max(1, warmup_steps)\n",
        "    progress = (step - warmup_steps) / max(1, total_steps - warmup_steps)\n",
        "    progress = min(1.0, max(0.0, progress))\n",
        "    return 0.5 * (1 + math.cos(math.pi * progress))\n",
        "\n",
        "sched = torch.optim.lr_scheduler.LambdaLR(opt, lr_lambda)\n",
        "\n",
        "use_cuda_amp = (DEVICE.type == 'cuda')\n",
        "scaler = GradScaler('cuda' if use_cuda_amp else 'cpu')\n",
        "\n",
        "# ====== R-Drop 설정 ======\n",
        "kl_factor = 1.0  # 0.5~2.0 사이 탐색 추천\n",
        "\n",
        "def sym_kl(logits1, logits2, mask=None):\n",
        "    # logits: [B, T, V]; mask: [B, T] (1=valid, 0=ignore)\n",
        "    p = F.log_softmax(logits1, dim=-1)\n",
        "    q = F.log_softmax(logits2, dim=-1)\n",
        "    p_exp = p.exp(); q_exp = q.exp()\n",
        "    kl = (p_exp * (p - q)).sum(-1) + (q_exp * (q - p)).sum(-1)  # [B, T]\n",
        "    if mask is not None:\n",
        "        kl = kl * mask\n",
        "        denom = mask.sum().clamp_min(1)\n",
        "        return kl.sum() / denom\n",
        "    return kl.mean()\n",
        "\n",
        "# ====== 2) 학습/검증 함수 (ACC=2 + R-Drop + TokenDropout) ======\n",
        "ACC = 2  # 유효 배치 x2\n",
        "\n",
        "def run_epoch(dl, train=True, grad_clip=1.0):\n",
        "    model.train(train)\n",
        "    total, n = 0.0, 0\n",
        "    if train:\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "    for step, (x, y) in enumerate(dl, 1):\n",
        "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "        if train:\n",
        "            x = token_dropout(x)  # 입력 노이즈(소량)로 강건성 ↑\n",
        "\n",
        "        with torch.set_grad_enabled(train):\n",
        "            if train:\n",
        "                with autocast('cuda' if use_cuda_amp else 'cpu'):\n",
        "                    # R-Drop: dropout 활성 상태에서 두 번 forward\n",
        "                    logits1 = model(x)\n",
        "                    logits2 = model(x)\n",
        "                    ce1 = criterion(logits1.view(-1, VOCAB_SIZE), y.view(-1))\n",
        "                    ce2 = criterion(logits2.view(-1, VOCAB_SIZE), y.view(-1))\n",
        "                    y_mask = (y != PAD_ID).float()\n",
        "                    kl = sym_kl(logits1, logits2, y_mask)\n",
        "                    loss = 0.5*(ce1+ce2) + kl_factor*kl\n",
        "                    if ACC > 1:\n",
        "                        loss = loss / ACC\n",
        "            else:\n",
        "                with autocast('cuda' if use_cuda_amp else 'cpu'):\n",
        "                    logits = model(x)\n",
        "                    loss = criterion(logits.view(-1, VOCAB_SIZE), y.view(-1))\n",
        "\n",
        "        if train:\n",
        "            scaler.scale(loss).backward()\n",
        "            if step % ACC == 0:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "                scaler.step(opt)\n",
        "                scaler.update()\n",
        "                sched.step()\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                ema.update(model)\n",
        "\n",
        "        total += loss.item() * (ACC if train and ACC > 1 else 1.0)\n",
        "        n += 1\n",
        "    return total / max(1, n)\n",
        "\n",
        "# ====== 3) SWA(막판 평균) + EMA 검증 + 베스트 저장 ======\n",
        "best_val = float('inf')\n",
        "ckpt_path = SPLIT_ROOT / \"minigpt_best.pt\"\n",
        "\n",
        "swa_start_epoch = max(5, EPOCHS - 5)  # 마지막 5에폭 평균\n",
        "swa_model = AveragedModel(model)\n",
        "\n",
        "for ep in range(1, EPOCHS+1):\n",
        "    tr = run_epoch(train_dl, train=True)\n",
        "\n",
        "    # SWA 평균 누적(에폭 단위)\n",
        "    if ep >= swa_start_epoch:\n",
        "        swa_model.update_parameters(model)\n",
        "\n",
        "    # EMA 가중치로 검증\n",
        "    ema.store(model); ema.copy_to(model)\n",
        "    vl = run_epoch(val_dl, train=False)\n",
        "    ema.restore(model)\n",
        "\n",
        "    if vl < best_val:\n",
        "        best_val = vl\n",
        "        torch.save(model.state_dict(), str(ckpt_path))\n",
        "    print(f\"[{ep}/{EPOCHS}] train {tr:.4f} | val {vl:.4f} | best {best_val:.4f} | lr {sched.get_last_lr()[0]:.6f}\")\n",
        "\n",
        "# ====== 4) 베스트 가중치 로드(안전) + (선택) SWA 평가/저장 ======\n",
        "_ = model.load_state_dict(torch.load(str(ckpt_path), map_location=DEVICE))\n",
        "\n",
        "# SWA 가중치로도 한 번 평가해보고, 더 좋으면 SWA로 저장\n",
        "try:\n",
        "    ema.store(model)\n",
        "    model.load_state_dict(swa_model.state_dict(), strict=False)\n",
        "    vl_swa = run_epoch(val_dl, train=False)\n",
        "    print(f\"[SWA] val {vl_swa:.4f}\")\n",
        "    if vl_swa < best_val:\n",
        "        torch.save(model.state_dict(), str(SPLIT_ROOT / \"minigpt_best_swa.pt\"))\n",
        "        print(\"SWA checkpoint saved (better than EMA-best).\")\n",
        "    ema.restore(model)\n",
        "except Exception as e:\n",
        "    print(\"SWA eval skipped:\", e)\n",
        "\n",
        "# ====== 5) 기본 generate (윈도우 자동 crop + 경량 반복 페널티/온도 스케줄) ======\n",
        "def temp_schedule(step, t_max, t0=0.9, t1=0.8):\n",
        "    a = min(1.0, max(0.0, step / max(1, t_max)))\n",
        "    return t0*(1-a) + t1*a\n",
        "\n",
        "@torch.no_grad()\n",
        "def generate(prompt_tokens, max_new=700, top_k=50, top_p=0.95, temp=0.9, rep_penalty=1.05):\n",
        "    model.eval()\n",
        "    pos_len = getattr(getattr(model, 'pos', None), 'shape', [1, 100000, 0])[1]\n",
        "    ids = torch.tensor([[VOCAB.get(t, UNK_ID) for t in prompt_tokens]], device=DEVICE)\n",
        "    for step in range(max_new):\n",
        "        ids_win = ids[:, -pos_len:] if ids.size(1) > pos_len else ids\n",
        "        cur_temp = temp_schedule(step, max_new, t0=temp, t1=max(0.6, temp-0.1))\n",
        "        logits = model(ids_win)[:, -1, :] / max(cur_temp, 1e-6)\n",
        "        probs = torch.softmax(logits, dim=-1)[0]\n",
        "\n",
        "        # 미세 반복 페널티(직전 토큰만 약하게)\n",
        "        last_tok = ids[0, -1]\n",
        "        probs[last_tok] = probs[last_tok] / rep_penalty\n",
        "\n",
        "        if top_k > 0:\n",
        "            topk = torch.topk(probs, top_k)\n",
        "            mask = torch.ones_like(probs, dtype=torch.bool); mask[topk.indices] = False\n",
        "            probs = probs.masked_fill(mask, 0)\n",
        "        if top_p < 1.0:\n",
        "            sprob, sidx = torch.sort(probs, descending=True)\n",
        "            keep = torch.cumsum(sprob, dim=-1) <= top_p\n",
        "            keep[0] = True\n",
        "            mask = torch.ones_like(probs, dtype=torch.bool); mask[sidx[keep]] = False\n",
        "            probs = probs.masked_fill(mask, 0)\n",
        "        probs = probs / probs.sum()\n",
        "\n",
        "        nxt = torch.multinomial(probs, 1)\n",
        "        ids = torch.cat([ids, nxt.view(1,1)], dim=1)\n",
        "        if nxt.item() == VOCAB[\"[EOS]\"]:\n",
        "            break\n",
        "    return [IVOCAB[i.item()] for i in ids[0]]\n",
        "\n",
        "# ====== 6) 길게 생성: 청크 스티칭(모델 수정 없음) ======\n",
        "def stitch_generate(prompt_tokens, total_new=512, chunk_new=700, context=480,\n",
        "                    top_k=50, top_p=0.95, temp=0.9, stop_on_eos=False):\n",
        "    all_tokens = list(prompt_tokens); made = 0\n",
        "    while made < total_new:\n",
        "        this_new = min(chunk_new, total_new - made)\n",
        "        cur_prompt = all_tokens[-context:] if len(all_tokens) > context else all_tokens\n",
        "        chunk = generate(cur_prompt, max_new=this_new, top_k=top_k, top_p=top_p, temp=temp)\n",
        "        new_part = chunk[len(cur_prompt):] if len(chunk) > len(cur_prompt) else []\n",
        "        if stop_on_eos and (\"[EOS]\" in new_part):\n",
        "            eos_idx = new_part.index(\"[EOS]\"); all_tokens += new_part[:eos_idx]; break\n",
        "        all_tokens += new_part; made += len(new_part)\n",
        "        if len(new_part) == 0: break\n",
        "    return all_tokens\n",
        "\n",
        "# ====== 7) 프롬프트 설정 & 길게 생성 & 저장 ======\n",
        "prompt = [\"[BOS]\",\"COMPOSER_Mozart\",\"PERIOD_Middle\",\"GENRE_Sonata\",\"KEY_Cmin\",\n",
        "          \"TSig_4_4\",\"TEMPO_112\",\"BAR\",\"POS_0\",\"BAR\",\"POS_0\",\"BAR\",\"POS_0\"]\n",
        "\n",
        "tokens_long = stitch_generate(\n",
        "    prompt_tokens=prompt,\n",
        "    total_new=512,   # 길이는 유지\n",
        "    chunk_new=700,\n",
        "    context=480,\n",
        "    top_k=50, top_p=0.95, temp=0.9,\n",
        "    stop_on_eos=False\n",
        ")\n",
        "\n",
        "out_mid_long = SPLIT_ROOT / \"sample_mozart_long_v2.mid\"\n",
        "detokenize_to_midi(tokens_long, out_mid_long)\n",
        "print(\"Saved →\", out_mid_long)\n",
        "\n",
        "# ====== 8) (선택) 퍼플렉서티로 상태 확인 ======\n",
        "print(\"Best val loss (EMA):\", best_val, \"| approx PPL:\", math.exp(best_val))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pJYE9E3T3rL"
      },
      "outputs": [],
      "source": [
        "!pip install pyFluidSynth==1.3.4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVm3SK1wkHaa"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nApGl8Ek05d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rx7y1bEBWUSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aaMtQ6ylXAiJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}